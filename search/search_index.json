{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introducing SanPy","text":"<p>SanPy is software to perform analysis of whole-cell curent clamp recordings. It is designed to work on a range of excitable cells including cardiac myocytes and neurons. Historically, it was originally designed for spontaneous cardiac action potentials from whole-cell current-clamp recordings of cardiac myocytes.</p> <p>If you find the code in this repository interesting, please email Robert Cudmore at UC Davis (rhcudmore@ucdavis.edu) and we can get you started. We are looking for users and collaborators.</p>"},{"location":"#key-features","title":"Key features:","text":"<p>1) Easy to use desktop application with a growing number of built in plugins.</p> <p>2) An API for full control of all aspects of file loading and analysis.</p> <p>3) SanPy has a plugin architecture and provides a wide range of pre-built plugins. We invite the community to build their own.</p> <p>4) SanPy has a file loader architecture so any type of raw data can be opened. We provide file loaders for Molecular Devices (Axon Instruments) abf and atf file formats (using pyAbf), as well as general purpose comma-seperated-value files (csv).</p> <p>5) SanPY implements a rich range of analysis results such as spike threshold detection, interval statistics, and spike shape analysis. Like the plugin and file loading architecures, SanPy also provide a software architecute to add new analysis measurements.</p>"},{"location":"#sanpy-preprint-on-biorxiv","title":"SanPy preprint on bioRxiv","text":"<p>Guarina L, Johnson TL, Griffith T, Santana LF, Cudmore RH (2023) SanPy: A whole-cell electrophysiology analysis pipeline. bioRxiv 2023.05.06.539660; doi: https://doi.org/10.1101/2023.05.06.539660]</p>"},{"location":"#desktop-application","title":"Desktop Application","text":""},{"location":"#plugins","title":"Plugins","text":""},{"location":"about/","title":"About SanPy","text":"<p>If you find the code in this repository interesting, please email Robert Cudmore at UC Davis (rhcudmore@ucdavis.edu) and we can get you started. We are looking for users and collaborators. Please visit the Cudmore lab website for more information.</p>"},{"location":"about/#why-is-this-useful","title":"Why is this useful?","text":"<p>We provide a Python package that can load, analyze, plot, and save eletropysiology recordings. This package is then accessed through a desktop application with a simple to use graphical user interface (GUI). Finally, the same code that drives the GUI  can be scripted. In just a few lines of code, the exact same loading, analysis, plotting, and saving can be performed as is done with the GUI.</p>"},{"location":"about/#why-is-this-important","title":"Why is this important?","text":"<p>When you publish a paper, you need to ensure your primary data is available for interogation and that your analysis can be reproduced. This software facilitates that by allowing you to share the raw data, provide the code that was used to analyze it, and explicity show how it was analyzed such that it can be verified and reproduced.</p>"},{"location":"desktop-application/","title":"Desktop Application","text":"<p>The SanPy deskop application is an easy to use and powerful GUI designed to satisfy all your analysis needs. You can download the desktop appication or build from source.</p>"},{"location":"desktop-application/#getting-started","title":"Getting Started","text":"<p>Load a folder of raw data files with the <code>Load Folder</code> button, or use the <code>File - Load Folder ...</code> menu, or drag and drop a folder from your hard-drive. Once a folder of raw data is loaded, each file in the folder will be shown in a list, one row per raw data file. Selecting a file will display the raw data recording.</p> <p>Spike detection is then performed by specifying a threshold in either the derivative of the membrane potential (Detect dV/dt) or the membrane potential (Detect mV).</p> <p>Once spikes are detected, the analysis results are overlaid over the plots of the raw data. Finally, plugins can be used to inspect the analysis results.</p> <p></p>"},{"location":"desktop-application/#file-list-table","title":"File List Table","text":"<p>A list of files in a loaded folder, each row is a file and columns are information on the file including a subset of the detection parameters and analysis results. The file list table can be toggled on and off with the <code>View - File Panel</code> menu or keyboard <code>f</code>. </p> <ul> <li>L - Indicates if the file is loaded. Use the right-click menu <code>Unload Data</code> to unload a loaded file. This can save memory.</li> <li>A - Indicates if the file has been analyzed.</li> <li>S - Indicates if the analysis has been saved.</li> <li>N - Once analyzed, indicates the number of spikes detected.</li> <li>File - The name of the raw data file.</li> <li>Dur(s) - The duration of the recording (this is the duration of each sweep).</li> <li>Sweeps - The number of sweeps.</li> <li>Epochs - The number of epochs per sweep. Epochs correspond to different current clamp steps/amplitudes within each sweep.</li> <li>KHz - The sampling rate of the recording.</li> <li>Mode - The mode of the recording, either V-Clamp or I-Clamp. Currently, SanPy will only analyze I-Clamp.</li> <li>Start(s) - Once analyzed, indicates the start second of the analysis.</li> <li>Stop(s) - Once analyzed, indicates the stop second of the analysis.</li> <li>dvdtTheshold - Once analyzed, indicates the dV/dt used for detection.</li> <li>mvThreshold - Once analyzed, indicates the mV used for detection.</li> </ul> <p></p> <p>Right-click in the file list table for a popup menu.</p> <ul> <li>Unload Data - Unload the raw data from the selected row. Useful to conserve memory if the folder has lots of files.</li> <li>Synch With Folder - Synchronize the contents of the folder with SanPy. Useful if you are acquiring new data on an electrophysiology setup.</li> <li>Save All Analysis - Save all the analysis for a folder to a single hdf5 file. This file is then used to load all the analysis the next time SanPy is run. See also, menu <code>File - Save Folder Analysis</code>.</li> <li>Copy Table - Copy the contents of the file list table. Useful to paste into a spreadsheet.</li> </ul>"},{"location":"desktop-application/#detection-panel","title":"Detection panel","text":"<p>The detection panel has subcategories to detect spikes and to control the display of the raw data and analysis results. The detection panel can be toggled on and off using the <code>View - Detection Panel</code> menu or with keyboard <code>d</code>.</p>"},{"location":"desktop-application/#detection","title":"Detection","text":"<p>Set detection parameters, finer control of all detection parameters is provided with the Detection Parameters Plugin.</p> <ul> <li>Presets - A popup to set a pre-defined set of detection parameters.</li> <li>Detect dV/dt - Detect spikes with the specified value in the first derivative (dV/dt). The first derivative can be plotted with menu <code>View - Derivative</code>.</li> <li>Detect mV - Detect spikes with the specified value in mV.</li> </ul> <ul> <li>Export Spike Report - Export all analysis for the selected file to a CSV file. This file includes all detection parameters and analysis results.</li> </ul>"},{"location":"desktop-application/#display","title":"Display","text":"<p>Control the display of SanPy.</p> <ul> <li>Sweep - Set the displayed sweep. This includes a popup menu to select a sweep and controls to go to the previous <code>&lt;</code> and next <code>&gt;</code> sweep.</li> </ul> <ul> <li> <p>Spike - Select individual spikes by spike number and scroll to the previous <code>&lt;&lt;</code> and next <code>&gt;&gt;</code> spike.</p> </li> <li> <p>[] - A button to set the raw data plots to full scale/zoom. This can also be done with keyboard <code>enter</code> or <code>return</code>.</p> </li> </ul>"},{"location":"desktop-application/#set-spikes","title":"Set Spikes","text":"<ul> <li>Set parameters for the currently selected spike(s) like: Condition, User Type, and include.</li> </ul>"},{"location":"desktop-application/#plot-options","title":"Plot Options","text":"<ul> <li>Control the analysis results that are overlayed over the raw data. See below for a detailed description.</li> </ul>"},{"location":"desktop-application/#raw-data-plots","title":"Raw data plots","text":"<p>There are four different plots of the raw data. These can be toggled on and off using the view menu entries: <code>full recording</code>, <code>derivative</code>, and <code>DAC</code>. Note, the raw data (bottom plot) is always shown and cannot be toggled.</p> <p>Click+drag with the mouse to zoom in on the time-axis.</p> <ul> <li>Full Recording - An overview of the total recording. This plot also shows the current zoom as a gray box.</li> <li>Derivative - The first derivative (dV/dt) of the raw recording. Used for spike detection by setting a value in the detection panel.</li> <li>DAC - A plot of the stimulation output. Please note, in this example it is 0 (no stimulation).</li> <li>Recording - A plot of the actual recording with analysis results overlaid. Here is shown spike threshold (mV, red circle) and spike peak (mV, green circle).</li> </ul> <p> </p>"},{"location":"desktop-application/#raw-data-overlayed-with-analysis-results","title":"Raw data overlayed with analysis results","text":"<p>A number of analysis results can be overlaid using the Plot Options checkboxes  in the detection panel. For a full list of analysis results, see Methods - Analysis Results</p> <ul> <li>Global Threshold - Plot the spike threshold in the 'Full Recording' plot.</li> <li>Threshold (dV/dt) - Plot the spike threshold in the 'Derivative' plot (red circle)</li> </ul> <p>The other plot options are displayed on the main recording (bottom most plot).</p> <ul> <li>Half-Widths - Spike half with for 10, 20, 50, 80, and 90 percent (yellow lines).</li> <li>Pre AP Min - Minimum mV before a spike (mV).</li> <li>EDD Rate - The early Diatolic Duation Rate (mV/s).</li> <li>Threshold (mV) - Spike threshold (mV). Also used as the time of a spike.</li> <li>AP Peak (mV) - Spike peak (mV).</li> <li>Epoch Lines - Epochs represent different DAC steps within a sweep (gray vertical lines).</li> <li>EDD - The early diastolic duration.</li> </ul> <p> </p>"},{"location":"desktop-application/#mouse-and-keyboard","title":"Mouse and Keyboard","text":""},{"location":"desktop-application/#mouse","title":"Mouse","text":"<ul> <li>Mouse click - Select individual spikes.</li> <li>Mouse wheel - Zoom in and out on x-axis (time).</li> <li>Mouse click+drag - Pan the x-axis (time).</li> <li>Mouse option+click+drag to zoom into the recording (y-axis).</li> </ul>"},{"location":"desktop-application/#keyboard","title":"Keyboard","text":"<ul> <li>\"return\" or \"enter\" - Set plot of recordings to full scale.</li> <li>\"esc\" - Canel spike selection.</li> <li>[coming soon] \"b\" - Toggle selected spike(s) bad.</li> </ul>"},{"location":"desktop-application/#menus","title":"Menus","text":""},{"location":"desktop-application/#file-menu","title":"File menu","text":"<ul> <li>Load Folder ... - Load a folder of raw data. A loaded folder will be shown in the File List Table.</li> <li>Load Recent ... - Load recently loaded folders.</li> <li>Save Folder Analysis ... - Save all the analysis for the loaded folder.</li> <li>Save Preferences - Save the SanPy preferences. This includes mostly information about the GUI like window position and opened plugins.</li> <li>Show Log - Show the SanPy log. A log is kept as a user interacts with SanPy. This is useful to send to the developers if there are problems. The logs can also be viewed with the SanPy Log Plugin.</li> </ul>"},{"location":"desktop-application/#view-menu","title":"View menu","text":"<p>A menu that allows different pieces of the interface to be shown or hidden.</p> <ul> <li>File Panel - Toggle the visibility of the file list panel.</li> <li>Detection Panel - Toggle the visibility of the detection panel.</li> <li>Detection - Toggle detection in the Detection Panel</li> <li>Display - Toggle display in the Detection Panel</li> <li>Plot Options - Toggle plot options in the Detection Panel. This is a panel with checkboxes to show/hide analysis results over the raw data.</li> <li>Set Spikes - Toggle set spikes in the Detection Panel. This is a panel to allow selected spike parameters to be set. For example, to set spikes as good/bad, user type, and condition.</li> <li>Full Recording - Toggle the display of the full recording.</li> <li>Derivative - Toggle the display of the membrane potential derivate (dV/dt). This is useful for detecting spikes with dV/dt.</li> <li>DAC - Toggle the display of the current clamp stimulus.</li> <li>Plugins - Toggle the display of a plugins dock. A right-click in the plugins dock will insert a plugin. Plugins can also be opened as seperate windows with the main Plugins menu.</li> <li>Dark Theme - Toggle dark and light themes. If checked, SanPy will use a dark theme, otherwise it will use a light theme. Please note that switching themes while SanPy is running will give sub-optimal results. To fully switch themes, select a theme then save preferences with the main <code>File - Save Preferences</code> menu, and restart SanPy.</li> </ul> <p> </p>"},{"location":"desktop-application/#plugins-menu","title":"Plugins menu","text":"<p>A menu to open a SanPy plugin. Plugins opened with this menu will be displayed in their own window.</p> <p>To open a plugin within the main SanPy window, use the <code>View - Plugins</code> menu to show the plugins dock and then right-click to select a plugin to display.</p> <p>All open plugins can be saved and re-opened with the next run of SanPy by saving the SanPy preferences with the <code>File - Save Preferences</code> menu.</p> <p> </p>"},{"location":"desktop-application/#plugins","title":"Plugins","text":"<p>There is a dedicated plugin documentaion page. Here we want to highlight a few key plugins.</p>"},{"location":"desktop-application/#plot-scatter","title":"Plot Scatter","text":"<p>The <code>plot scatter</code> plugin is designed to plot any analysis results. Spike selections are bi-directional between the plot scatter widget and the main interface. The markers symbols and colors can be used to specify detailed results per spike. For example, coloring based on time or sweep, if the spike is marked bad, and if the spike has a specified user type. These types of things can be set in the main interface <code>Detection Panel - Set Spikes</code>.</p> <p></p> <p> </p>"},{"location":"desktop-application/#plot-fi","title":"Plot FI","text":"<p>The <code>plot fi</code> plugin is designed to visualize the raw data and analysis of a current-clamp experiment where a range of hyperpolarizing and depolarizing current steps are delivered.</p> <p></p> <p> </p>"},{"location":"desktop-application/#summarize-results","title":"Summarize Results","text":"<p>The <code>summarize results</code> plugin shows a number of different tables to review the analysis results. Here, we focus on errors that occured during spike detection. Each row represents an error in an individual spike. Selecting the error will select the spike in the main interface. This should be used in a curation feedback loop. Once spikes are detected, check for errors and adjust the detection parameters until the errors are acceptable. Alternatively, you can set a tag in individual spikes to 'reject' them.</p> <p></p> <p> </p>"},{"location":"desktop-application/#user-files","title":"User Files","text":"<p>When the SanPy desktop application is first run, it creates a folder to contain user files in <code>&lt;username&gt;/Documents/SanPy-User-Files</code>. This is where you drop in your custom code to extend the capabilities of SanPy. This includes:</p> <ul> <li>Writing a file loader</li> <li>Writing new analysis</li> <li>Writing a plugin</li> </ul>"},{"location":"download/","title":"Download","text":"<p>These desktop applications are meant to work out of the box. If there are any issues, please email Robert Cudmore (rhcudmore@ucdavis.edu) and we will fix it.</p>"},{"location":"download/#mac-download","title":"Mac download","text":"<p>If you have an older Mac with an Intel/x86 chip or if you are unsure then download the <code>x86</code> version. If you have a newer Mac with an M1/M2 chip then download the <code>arm</code> version.</p> <p>Download macOS x86  Download macOS arm </p>"},{"location":"download/#windows-download","title":"Windows download","text":"<p>We are waiting for our Microsoft Developer Certificate and will provide a direct download as soon as we can. Please check back later. You can always clone the repository and run from source, see Install.</p>"},{"location":"download/#current-version","title":"Current Version","text":"<ul> <li>Version 0.1.11, Released on May 7, 2023</li> </ul>"},{"location":"download/#current-and-previous-releases-on-github","title":"Current and previous releases (on GitHub)","text":"<p>Go To Current Release</p>"},{"location":"file-loaders/","title":"File loaders","text":"<p>We provide a simple to use API for users to create their own file loaders.</p>"},{"location":"install/","title":"Install","text":"<p>SanPy is designed to run on: macOS, Microsoft Windows, and Linux.</p>"},{"location":"install/#download-the-sanpy-app","title":"Download the SanPy app.","text":"<p>We are building SanPy desktop applications so users can download a single file and get working with just a double-click. This does not require anything special on our users end. No programming, no installing Python, and no command line. See our download page.</p>"},{"location":"install/#install-from-the-command-line","title":"Install from the command line","text":"<p>Create and activate a virtual environment with either <code>conda</code> or <code>venv</code>.</p> <p>Important</p> <p>M1/2 Mac users need to use a Conda environment as the arm64 versions of a number of Python packages are not available on PyPi (e.g. with pip install).</p>"},{"location":"install/#either-create-a-conda-environment","title":"Either create a <code>conda</code> environment","text":"<pre><code>conda create -y -n sanpy-env python=3.9\nconda activate sanpy-env\n</code></pre>"},{"location":"install/#or-create-a-venv-environment","title":"Or create a <code>venv</code> environment","text":"<pre><code>python -m venv sanpy-env\n\n# macOS activate the environment\nsource sanpy-env/bin/activate\n\n# Windows activate the environment\nsanpy-env\\Scripts\\activate\n</code></pre>"},{"location":"install/#install-sanpy-from-pypi","title":"Install SanPy from PyPi","text":"<p>Important</p> <p>The SanPy package is named <code>sanpy-ephys</code>.</p> <pre><code>pip install \"sanpy-ephys[gui]\"\n</code></pre>"},{"location":"install/#run-the-gui","title":"Run the GUI","text":"<pre><code>sanpy\n</code></pre>"},{"location":"install/#install-from-a-local-source","title":"Install from a local source","text":"<p>For users interested in modifying the source code, you can clone the GitHub repository and install from local source.</p> <p>Be sure to create and activate a virtual environment (See above).</p> <p>Assuming you have the following</p> <ul> <li>Python &gt; 3.8</li> <li>pip</li> <li>git</li> </ul> <p>1) Clone the repository</p> <pre><code>git clone https://github.com/cudmore/SanPy.git\n</code></pre> <p>2) Install SanPy</p> <pre><code>cd SanPy\npip install -e \".[gui]\"\n</code></pre> <p>4) Run <code>sanpy</code></p> <pre><code>sanpy\n</code></pre> <p>5) Have fun</p>"},{"location":"methods/","title":"Methods","text":""},{"location":"methods/#detection-parameters","title":"Detection Parameters","text":"<p>To detect action potentials, SanPy uses a number of parameters. These can all be configured using the detection parameter plugin or programmatically with the API sanpy/detectionParams.</p> <p>Note: To update this table use sanpy/bDetection.py</p> Parameter Default Value Units Human Readable Description 0 dvdtThreshold 100 dVdt dV/dt Threshold dV/dt threshold for a spike, will be backed up to dvdt_percentOfMax and have xxx error when this fails 1 mvThreshold -20 mV mV Threshold mV threshold for spike AND minimum spike mV when detecting with dV/dt 2 dvdt_percentOfMax 0.1 Percent dV/dt Percent of max For dV/dt detection, the final TOP is when dV/dt drops to this percent from dV/dt AP peak 3 onlyPeaksAbove_mV mV Accept Peaks Above (mV) For dV/dt detection, only accept APs above this value (mV) 4 doBackupSpikeVm True Boolean Backup Vm Spikes If true, APs detected with just mV will be backed up until Vm falls to xxx 5 refractory_ms 170 ms Minimum AP interval (ms) APs with interval (with respect to previous AP) less than this will be removed 6 peakWindow_ms 100 ms Peak Window (ms) Window after TOP (ms) to seach for AP peak (mV) 7 dvdtPreWindow_ms 10 ms dV/dt Pre Window (ms) Window (ms) to search before each TOP for real threshold crossing 8 mdp_ms 250 ms Pre AP MDP window (ms) Window (ms) before an AP to look for MDP 9 avgWindow_ms 5 ms Window (ms) to calculate MDP (mV) as a mean rather than mV at single point for MDP 10 halfHeights [10, 20, 50, 80, 90] AP Durations (%) AP Durations as percent of AP height (AP Peak (mV) - TOP (mV)) 11 halfWidthWindow_ms 200 ms Half Width Window (ms) Window (ms) after TOP to look for AP Durations 12 medianFilter 0 points Median Filter Points Number of points in median filter, must be odd, 0 for no filter 13 SavitzkyGolay_pnts 5 points SavitzkyGolay Filter Points Number of points in SavitzkyGolay filter, must be odd, 0 for no filter 14 SavitzkyGolay_poly 2 Savitzky-Golay Filter Polynomial Degree The degree of the polynomial for Savitzky-Golay filter 15 spikeClipWidth_ms 500 ms AP Clip Width (ms) The width/duration of generated AP clips"},{"location":"methods/#detection-errors","title":"Detection Errors","text":"<p>When SanPy encounters errors during spike detection, they are stored for each spike in ['errors']. Each error has a name like 'dvdtPercent' as follows</p> <ul> <li>dvdtPercent: Error searching for percent (10%) of dvdt max. When this occurs, the TOP (mV) of a spike will be more depolarized than it should be.</li> <li>preMin: Error searching for spike pre min, the MDP before a spike. This can occur on the first spike if it is close to the beginning of the recording.</li> <li>postMin:</li> <li>fitEDD: Error while fitting slope of EDD.</li> <li>preSpikeDvDt: Error while searching for peak in max ap upstroke (dV/dt) between spike threshold (TOP) and the peak in the first derivative of Vm (dV/dt).</li> <li>cycleLength: Usually occurs on last spike when looking for next MDP.</li> <li>spikeWidth: Error finding a particular spike with (AP_Dur). Usually occurs when spikes are too broad, can increase detection parameter <code>hwWindow_ms</code>.</li> </ul>"},{"location":"methods/#analysis-results","title":"Analysis results","text":"<p>Once spike are detected, SanPy has the following analysis results.</p> Stat name units yStat yStatUnits xStat xStatUnits 0 Take Off Potential (s) thresholdSec s thresholdVal mV thresholdSec s 1 Take Off Potential (mV) thresholdVal mV thresholdVal mV thresholdPnt Points 2 Spike Frequency (Hz) spikeFreq_hz Hz spikeFreq_hz Hz thresholdPnt Points 3 Cycle Length (ms) cycleLength_ms ms cycleLength_ms ms thresholdPnt Points 4 AP Peak (mV) peakVal mV peakVal mV peakPnt Points 5 AP Height (mV) peakHeight mV peakHeight mV peakPnt Points 6 Pre AP Min (mV) preMinVal mV preMinVal mV preMinPnt Points 7 Post AP Min (mV) postMinVal mV postMinVal mV postMinPnt Points 8 Early Diastolic Depol Rate (dV/s) earlyDiastolicDurationRate dV/s earlyDiastolicDurationRate dV/s 9 Early Diastolic Duration (ms) earlyDiastolicDuration_ms ms earlyDiastolicDuration_ms dV/s thresholdPnt Points 10 Diastolic Duration (ms) diastolicDuration_ms ms diastolicDuration_ms dV/s thresholdPnt Points 11 Max AP Upstroke (mV) preSpike_dvdt_max_val mV preSpike_dvdt_max_val dV/s preSpike_dvdt_max_pnt Points 12 Max AP Upstroke (dV/dt) preSpike_dvdt_max_val2 dV/dt preSpike_dvdt_max_val2 dV/dt preSpike_dvdt_max_pnt Points 13 Max AP Repolarization (mV) postSpike_dvdt_min_val mV postSpike_dvdt_min_val mV postSpike_dvdt_min_pnt Points 14 AP Duration (ms) apDuration_ms ms apDuration_ms ms thresholdPnt Points 15 Half Width 10 (ms) nan nan widths_10 ms 16 Half Width 20 (ms) nan nan widths_20 ms 17 Half Width 50 (ms) nan nan widths_50 ms 18 Half Width 80 (ms) nan nan widths_80 ms 19 Half Width 90 (ms) nan nan widths_90 ms 20 Ca++ Delay (s) nan nan caDelay_sec s 21 Ca++ Width (ms) nan nan caWidth_ms ms"},{"location":"methods/#analysis-results-full","title":"Analysis results (full)","text":"<p>Generated 2023-03-24 with sanpy.analysisVersion 20230324a</p> <p>Note: To update this table use sanpy/bAnalysisResults.py</p> Name type default units depends on detection error description 0 analysisDate str Date of analysis in yyyymmdd format. 1 analysisTime str Time of analysis in hh:mm:ss 24 hours format. 2 modDate str Modification date if AP is modified after detection. 3 modTime str Modification time if AP is modified after detection. 4 analysisVersion str Analysis version when analysis was run. See sanpy.analysisVersion 5 interfaceVersion str Interface version string when analysis was run. See sanpy.interfaceVersion 6 file str Name of raw data file analyzed 7 detectionType None Type of detection, either vm or dvdt. See enum sanpy.bDetection.detectionTypes 8 cellType str User specified cell type 9 sex str User specified sex 10 condition str User specified condition 11 sweep int 0 Sweep number of analyzed sweep. Zero based. 12 epoch int NaN Stimulus epoch number the spike occured in. Zero based. 13 epochLevel float NaN Epoch level (DAC) stimulus during the spike. 14 sweepSpikeNumber int None Spike number within the sweep. Zero based. 15 spikeNumber int None Spike number across all sweeps. Zero based. 16 include bool True Boolean indication include or not. Can be set by user/programmatically  after analysis. 17 userType int 0 Integer indication user type. Can be set by user/programmatically  after analysis. 18 errors list [] List of dictionary to hold detection errors for this spike 19 dvdtThreshold float NaN dvdt dvdtThreshold AP Threshold in derivative dv/dt 20 mvThreshold float NaN mV mvThreshold AP Threshold in primary recording mV 21 medianFilter int 0 medianFilter Median filter to generate filtered vm and dvdt. Value 0 indicates no filter. 22 halfHeights list [] halfHeights List of int to specify half-heights like [10, 20, 50, 80, 90]. 23 thresholdPnt int NaN point AP threshold point 24 thresholdSec float NaN sec AP threshold seconds 25 thresholdVal float NaN mV Value of Vm at AP threshold point. 26 thresholdVal_dvdt float NaN dvdt Value of dvdt at AP threshold point. 27 dacCommand float NaN mV Value of DAC command at AP threshold point. 28 peakPnt int NaN point (onlyPeaksAbove_mV, peakWindow_ms) AP peak point. 29 peakSec float NaN sec AP peak seconds. 30 peakVal float NaN mV Value of Vm at AP peak point. 31 peakHeight float NaN mV Difference between peakVal minus thresholdVal. 32 timeToPeak_ms float NaN ms Time to peak (ms) after TOP. 33 preMinPnt int NaN point mdp_ms Minimum before an AP taken from predefined window. 34 preMinVal float NaN mV Minimum before an AP taken from predefined window. 35 preLinearFitPnt0 int NaN point Point where pre linear fit starts. Used for EDD Rate 36 preLinearFitPnt1 int NaN point Point where pre linear fit stops. Used for EDD Rate 37 earlyDiastolicDuration_ms float NaN ms Time (ms) between start/stop of EDD. 38 preLinearFitVal0 float NaN mv 39 preLinearFitVal1 float NaN mv 40 earlyDiastolicDurationRate float NaN mv/S Early diastolic duration rate, the slope of the linear fit between start/stop of EDD. 41 lateDiastolicDuration float NaN Depreciated 42 preSpike_dvdt_max_pnt int NaN point Point corresponding to peak in dv/dt before an AP. 43 preSpike_dvdt_max_val float NaN mV Value of Vm at peak of dv/dt before an AP. 44 preSpike_dvdt_max_val2 float NaN dv/dt Value of dv/dt at peak of dv/dt before an AP. 45 postSpike_dvdt_min_pnt int NaN point dvdtPostWindow_ms Point corresponding to min in dv/dt after an AP. 46 postSpike_dvdt_min_val float NaN mV Value of Vm at minimum of dv/dt after an AP. 47 postSpike_dvdt_min_val2 float NaN dvdt Value of dv/dt at minimum of dv/dt after an AP. 48 isi_pnts int NaN point refractory_ms Inter-Spike-Interval (points) with respect to previous AP. 49 isi_ms float NaN ms Inter-Spike-Interval (ms) with respect to previous AP. 50 spikeFreq_hz float NaN Hz AP frequency with respect to previous AP. 51 cycleLength_pnts int NaN point Points between APs with respect to previous AP. 52 cycleLength_ms int NaN point Time (ms) between APs with respect to previous AP. 53 diastolicDuration_ms float NaN ms Time (ms) between minimum before AP (preMinPnt) and AP time (thresholdPnt). 54 widths list [] A list of dict to hold half-height information for each half-height in detection halfHeights. 55 widths_10 int NaN percent halfWidthWindow_ms Width (ms) at half-height 10 %. 56 widths_20 int NaN percent halfWidthWindow_ms Width (ms) at half-height 20 %. 57 widths_50 int NaN percent halfWidthWindow_ms Width (ms) at half-height 50 %. 58 widths_80 int NaN percent halfWidthWindow_ms Width (ms) at half-height 80 %. 59 widths_90 int NaN percent halfWidthWindow_ms Width (ms) at half-height 90 %. <p></p>"},{"location":"methods/#what-spike-parameters-are-detected","title":"What spike parameters are detected?","text":"<p>For cardiac myocyte analysis, SanPy follows the nomenclature from this paper:</p> <p>Larson, et al (2013) Depressed pacemaker activity of sinoatrial node myocytes contributes to the age-dependent decline in maximum heart rate. PNAS 110(44):18011-18016</p> <ul> <li>MDP and Vmax were defined as the most negative and positive membrane potentials, respectively</li> <li>Take-off potential (TOP) was defined as the membrane potential when the first derivative of voltage with respect to time (dV/dt) reached 10% of its maximum value</li> <li>Cycle length was defined as the interval between MDPs in successive APs</li> <li>The maximum rates of the AP upstroke and repolarization were taken as the maximum and minimum values of the first derivative (dV/dtmax and dV/dtmin, respectively)</li> <li>[[[REMOVED 20210501]]] Action potential duration (APD) was defined as the interval between the TOP and the subsequent MDP</li> <li>APD_50 and APD_90 were defined as the interval between the TOP and 50% and 90% repolarization, respectively</li> <li>The diastolic duration was defined as the interval between MDP and TOP</li> <li>The early diastolic depolarization rate was estimated as the slope of a linear fit between 10% and 50% of the diastolic duration and the early diastolic duration was the corresponding time interval</li> <li>The nonlinear late diastolic depolarization phase was estimated as the duration between 1% and 10% dV/dt</li> </ul>"},{"location":"open-source/","title":"Open source","text":"<p>As all open-source projects are, we are indebted to an enormous number of underlying open-source projects, countless contributors, and even more person hours. Without these projects and all who have contributed, SanPy would not be possible.</p> <p>To contribute to the open-source community, we are following the FAIR principles of software development to promote: (F)indability, (A)ccessibility, (I)nteroperability, and (R)eusability.</p> <p>With this, our software is designed to be flexible in how it is used.</p> <ul> <li>From a desktop</li> <li>As a downloaded app</li> <li>On an existing cloud server</li> <li>Deployed by our users as their own cloud server</li> </ul>"},{"location":"open-source/#core","title":"Core","text":"<ul> <li>Python - A programming language that lets you work quickly and integrate systems more effectively.</li> <li>SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering.</li> <li>NumPy - The fundamental package for scientific computing with Python.</li> <li>Pandas - A data analysis and manipulation tool.</li> <li>pyABF - Package to open Axon Binary Format (ABF) files.</li> <li>heka_reader - To read Heka Data files. Not currently used.</li> <li>XlsxWriter - To read and write Microsoft Excel files.</li> </ul>"},{"location":"open-source/#desktop-application","title":"Desktop Application","text":"<ul> <li>PyQt - Python bindings for The Qt Company's Qt application framework.</li> <li>PyQtGraph - Scientific Graphics and GUI Library for Python (built on PyQt and PySide).</li> <li>Matplotlib - A comprehensive library for creating static, animated, and interactive visualizations in Python.</li> </ul>"},{"location":"open-source/#web-application-v1","title":"Web application v1","text":"<ul> <li>Plotly Python - Open Source Graphing Library.</li> <li>Plotly Dash - A low-code platform for ML &amp; data science apps.</li> <li>Dash Bootstrap components - A a library of Bootstrap components for Plotly Dash.</li> </ul>"},{"location":"open-source/#web-application-v2","title":"Web application v2","text":"<ul> <li>Docker - Empowering App Development for Developers</li> <li>NGINX - High Performance Load Balancer, Web Server ...</li> <li>Flask - Web development, one drop at a time.</li> <li>Vue - The progressive Javascript framework.</li> <li>Bootstrap - The world's most popular framework for building responsive, mobile-first sites.</li> </ul>"},{"location":"open-source/#development","title":"Development","text":"<ul> <li>pyenv - Python version management.</li> <li>mkdocs - Static site generator geared towards building project documentation.</li> <li>mkdocs-material - Standardized theme for MkDocs</li> <li>mkdocstrings - Automatic documentation from sources, for MkDocs.</li> </ul>"},{"location":"open-source/#other-existing-analysis-software","title":"Other existing analysis software","text":"<p>These is of course other software to do similar things. This is not a complete list.</p> <ul> <li>ParamAP - Standardized parameterization of sinoatrial node myocyte action potentials</li> <li>stimfit - A program for viewing and analyzing electrophysiological data</li> </ul> <p>C++ libraries</p> <ul> <li>biosig - A C/C++ library providing reading and writing routines for biosignal data formats</li> <li>sigviewer - SigViewer is a viewing application for biosignals.</li> </ul>"},{"location":"plugins/","title":"Plugins","text":""},{"location":"plugins/#overview","title":"Overview","text":"<p>SanPy supports user plugins. These are Python classes that tap into the underlying API architecture of the SanPy desktop GUI.</p> <p>With Plugins, the core funtionality of SanPy can easily be extended, including:</p> <ul> <li>Plotting raw data</li> <li>Plotting analysis</li> <li>Tabular reports</li> <li>Extend analysis in new ways</li> </ul> <p>For a tutorial on writing your own plugin, please see our writing-a-plugin guide.</p>"},{"location":"plugins/#common-plugin-interface","title":"Common plugin interface","text":"<p>All plugins are linked into the SanPy interface to respond to file and sweep selections, changes to the analysis, spike selection, and changes in the zooming of a recording.</p> <p>Each plugin shares a common interface to turn these actions on and off. This interface can be toggled with a right-mouse-click and selecting <code>Toggle Top Toolbar</code>.</p> <p></p>"},{"location":"plugins/#built-in-plugins","title":"Built-in plugins.","text":""},{"location":"plugins/#plot-recording","title":"Plot Recording","text":"<p>Plot a recording with an overlay of spike detection parameters.</p> <p></p>"},{"location":"plugins/#spike-clips","title":"Spike Clips","text":"<p>Plot all spikes aligned to their threshold. Also has waterfall and phase plots.</p>"},{"location":"plugins/#plot-scatter","title":"Plot Scatter","text":"<p>A plugin to explore scatter plots of analysis results. Possibly the most useful plugin!</p> <p></p>"},{"location":"plugins/#plot-fi","title":"Plot FI","text":"<p>Analyze and plot analysis results versus current steps.</p> <p></p>"},{"location":"plugins/#plot-analysis","title":"Plot Analysis","text":"<p>Visualize a number of plot types including: Scatter, Histograms, Mean , etc. Basically 'Plot Scatter' on steroids.</p> <p></p>"},{"location":"plugins/#detection-parameters","title":"Detection Parameters","text":"<p>Allows setting of all detection parameters, includes a description of each as well as presets for different types of cells and recordings.</p> <p></p>"},{"location":"plugins/#export-trace","title":"Export Trace","text":"<p>Plot a trace, set some display parameters and export to a file. File formats include Png, Pdf, and SVG.</p> <p></p>"},{"location":"plugins/#summarize-results","title":"Summarize Results","text":"<p>This plugin will display a table of analysis results with four different views including:</p> <ul> <li>Full Export - The same table saved as <code>Export Spike Report</code>.</li> <li>Human Readable - A nicer looking table with human readable column names.</li> <li>Sweep Summary - A summary of spike statistics for one sweep. Useful if your recordings have just one sweep.</li> <li>Detection Errors - A list of spike detection errors. Usefull while searching for the correct detection parameters.</li> </ul> <p>Each row in the tble represents one spike. On selecting a spike, the corresponding spike will be selected in the main interface. Double-click on a spike to zoom into one spike.</p> <p>All reports can be copied to the clipboard and then pasted into a spreadsheet.</p>"},{"location":"plugins/#full-export","title":"Full Export","text":"<p>Export all spikes like saving csv.</p> <p></p>"},{"location":"plugins/#human-readable","title":"Human Readable","text":"<p>A slightly nicer table where column names are human readable.</p> <p></p>"},{"location":"plugins/#sweep-summary","title":"Sweep Summary","text":"<p>A summary of a single sweep. This is particularly usefull if a recording uses just one sweep..</p> <p></p>"},{"location":"plugins/#detection-errors","title":"Detection Errors","text":"<p>A summary of all detection errors.</p> <p>Important</p> <p>This plugin allows the browsing of <code>Detection Errors</code> and is critical for the curation of data analysis! Browe through these errors and adjust detection parameters as neccessary.</p> <p></p>"},{"location":"plugins/#sanpy-log","title":"Sanpy Log","text":"<p>Display the SanPy log. As a user interacts with SanPy, most actions are logged to a file. This is useful for debugging and communicating with developers :)</p> <p></p>"},{"location":"plugins/#fft","title":"FFT","text":"<p>Calculate and plot the Power-Spectral-Density (PSD) of any recording using the Fast-Fourier-Transform (FFT).</p> <p></p>"},{"location":"plugins/#stim-gen","title":"Stim Gen","text":"<p>A plugin to generate stimuli and save them as csv or Axon Text Files (ATF). Optimized to generate noisy sin waves! These files can then be presented as a stimulus during an ePhys recording.</p> <p></p>"},{"location":"scripting/","title":"Getting Started","text":"<p>This notebook is a general overview of how to load a raw data file, detect spikes, and plot the results.</p> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport matplotlib.pyplot as plt\n\nfrom IPython.display import display\n</pre> %load_ext autoreload %autoreload 2  import matplotlib.pyplot as plt  from IPython.display import display In\u00a0[2]: Copied! <pre>import sanpy\n\npath = '../../data/19114001.abf'\nba = sanpy.bAnalysis(path);\n\n# print info on the file and analysis\nprint(ba)\n</pre> import sanpy  path = '../../data/19114001.abf' ba = sanpy.bAnalysis(path);  # print info on the file and analysis print(ba) <pre>WARNING sanpy.fileloaders.fileLoader_base  fileLoader_base.py getFileLoaders() line:54 -- Did not load \"epochTable\", no \"filetype\" attribute\n</pre> <pre>fileLoader: file: 19114001.abf sweeps: 1 dur (Sec):60.0 spikes:0\n</pre> In\u00a0[3]: Copied! <pre>bp = sanpy.analysisPlot.bAnalysisPlot(ba)\n\nbp.plotDerivAndRaw();\n</pre> bp = sanpy.analysisPlot.bAnalysisPlot(ba)  bp.plotDerivAndRaw(); In\u00a0[4]: Copied! <pre>dDict = sanpy.bDetection().getDetectionDict('SA Node')\n\ndDict['dvdtThreshold'] = 50\n\nba.spikeDetect(dDict)\nprint(ba)\n</pre> dDict = sanpy.bDetection().getDetectionDict('SA Node')  dDict['dvdtThreshold'] = 50  ba.spikeDetect(dDict) print(ba) <pre> INFO sanpy.bAnalysis_  bAnalysis_.py getErrorReport() line:2247 -- Generating error report for 103 spikes\n</pre> <pre>fileLoader: file: 19114001.abf sweeps: 1 dur (Sec):60.0 spikes:103\n</pre> <p>All the named preset detection parameters are available using <code>getDetectionPresetList()</code></p> In\u00a0[5]: Copied! <pre>print(sanpy.bDetection().getDetectionPresetList())\n</pre> print(sanpy.bDetection().getDetectionPresetList()) <pre>['SA Node', 'Ventricular', 'Neuron', 'Fast Neuron', 'Sub Threshold', 'Ca Spikes', 'Ca Kymograph']\n</pre> In\u00a0[6]: Copied! <pre>bp = sanpy.bAnalysisPlot(ba)\nax = bp.plotSpikes(plotThreshold=True, plotPeak=True);\n\n# zoom in on x-axis\nax.set_xlim([22,26]);\n</pre> bp = sanpy.bAnalysisPlot(ba) ax = bp.plotSpikes(plotThreshold=True, plotPeak=True);  # zoom in on x-axis ax.set_xlim([22,26]); <p>The analysis results can easily be pulled from the bAnalysis object and manipulated in any number of ways.</p> <p>First, as a Pandas DataFrame.</p> In\u00a0[7]: Copied! <pre>df =ba.asDataFrame()\ndisplay(df.head())\n</pre> df =ba.asDataFrame() display(df.head()) spikeNumber include detectionType sweep epoch epochLevel sweepSpikeNumber userType errors analysisDate ... cycleLength_pnts cycleLength_ms diastolicDuration_ms widths widths_10 widths_20 widths_50 widths_80 widths_90 user_timeToPeak_ms 0 0 True dvdt 0 0 0.0 0 0 [] 20230430 ... NaN NaN 59.30 [{'halfHeight': 10, 'risingPnt': 5138, 'fallin... 59.05 42.15 16.30 4.00 2.10 1.45 1 1 True dvdt 0 0 0.0 1 0 [] 20230430 ... 12284.0 614.20 70.40 [{'halfHeight': 10, 'risingPnt': 17646, 'falli... 65.65 48.95 18.40 4.15 2.25 1.30 2 2 True dvdt 0 1 0.0 2 0 [] 20230430 ... 13023.0 651.15 60.95 [{'halfHeight': 10, 'risingPnt': 30479, 'falli... 64.30 45.70 14.85 4.00 2.20 1.35 3 3 True dvdt 0 1 0.0 3 0 [] 20230430 ... 14660.0 733.00 40.55 [{'halfHeight': 10, 'risingPnt': 44732, 'falli... 67.45 49.65 18.70 4.30 2.30 1.40 4 4 True dvdt 0 1 0.0 4 0 [] 20230430 ... 12455.0 622.75 90.95 [{'halfHeight': 10, 'risingPnt': 58196, 'falli... 73.95 51.00 18.30 4.80 2.40 1.80 <p>5 rows \u00d7 61 columns</p> <p>Second, as a numpy array and plotted with matplotlib.</p> <p>Here we are pulling the time of AP threshold and the instantaneous frequency of all spikes.</p> <p>See our documentation for all the available analysis results.</p> In\u00a0[8]: Copied! <pre>thresholdSec = ba.getStat('thresholdSec')\ninstFeq = ba.getStat('spikeFreq_hz')\n\nimport matplotlib.pyplot as plt\nplt.plot(thresholdSec, instFeq, 'o')\nplt.show()\n</pre> thresholdSec = ba.getStat('thresholdSec') instFeq = ba.getStat('spikeFreq_hz')  import matplotlib.pyplot as plt plt.plot(thresholdSec, instFeq, 'o') plt.show() <p>Finally, we will manually plot the raw data with an overlay of the spike peak (mV).</p> <p>The bAnalysis <code>fileLoader</code> contains all the raw data for the file including the recording and acquisition parameters such as sampling rate.</p> In\u00a0[9]: Copied! <pre># sweepX is the time of a recording\nsweepX = ba.fileLoader.sweepX\n# sweepY is the actual recording\nsweepY = ba.fileLoader.sweepY\n\n# plot the raw data\nfig, ax = plt.subplots(1,1)\n\nax.plot(sweepX, sweepY, 'k');\n\n# overlay spike peak\nthresholdSec = ba.getStat('thresholdSec')\npeakVal = ba.getStat('peakVal')\nax.plot(thresholdSec, peakVal, 'or');\n\n# zoom the x-axis\nax.set_xlim([20, 30]);\n</pre> # sweepX is the time of a recording sweepX = ba.fileLoader.sweepX # sweepY is the actual recording sweepY = ba.fileLoader.sweepY  # plot the raw data fig, ax = plt.subplots(1,1)  ax.plot(sweepX, sweepY, 'k');  # overlay spike peak thresholdSec = ba.getStat('thresholdSec') peakVal = ba.getStat('peakVal') ax.plot(thresholdSec, peakVal, 'or');  # zoom the x-axis ax.set_xlim([20, 30]); In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"scripting/#load-raw-data","title":"Load raw data\u00b6","text":"<p>SanPy is built with file loaders for pClamp files (using pyAbf), csv files, and matplab files.</p>"},{"location":"scripting/#plot-raw-data","title":"Plot Raw Data.\u00b6","text":"<p>Here we are plotting the raw data membrane potential (mV) and the first derivative (dV/dt). The first derivative is critical for accurate spike detection.</p>"},{"location":"scripting/#detect-spikes","title":"Detect spikes\u00b6","text":"<p>Spike detection requires a number of parameters. SanPy provides built in presets for common cell types including ventricular myocytes, slow and fast neurons.</p> <p>Here, we grab the detection presets for a sino-atrial node cardiac myocyte named 'SA Node' and then detect spikes with <code>spikeDetect(dDict)</code>.</p> <p><code>dDict</code> is a Python dictionary with keys being the detection parameters and the value is, well, the value of that parameter key. In this example we set the <code>dvdtThreshold</code> to 50, this was arrived at by inspecting our plot of the raw data (above).</p>"},{"location":"scripting/#plot-results","title":"Plot results\u00b6","text":"<p>Once analyzed, the analysis results can be plotted over the raw data. Here we are using <code>bAnalysisPlot</code> to make simple plots.</p>"},{"location":"user-analysis/","title":"User analysis","text":"<p>We provide a simple to use API for users to extend the analysis of SanPy.</p>"},{"location":"web-application/","title":"Web application","text":"<p>Please note, this is experimental and under active development.</p> <p>The browser based web application uses the same backend code as the desktop interface. The web interface itself is a seperate set of code. We will move more and more interface to the web version, for now it is sufficient to browse, analyse, and save results.</p> <p>Local files can also be dragged and dropped to the web interface.</p> <p></p> <p>Once data is analyzed, Pooling allows browsing detection parameters across any number of files.</p> <p></p>"},{"location":"web-application/#install-the-web-application","title":"Install the web application","text":"<p>Please note, this is experimental and does not have all functions implemented. Please use the desktop version instead.</p> <pre><code>cd SanPy/dash\n\npython3 -m venv sanpy_dash\nsource sanpy_dash/bin/activate\n\npip install -r requirements.txt\n\n# install sanpy from local copy of repository\npip install -e ../.\n</code></pre>"},{"location":"web-application/#running-the-web-applications","title":"Running the web applications","text":"<p>Run the web application to analyze raw data</p> <pre><code>cd SanPy/dash\nsource sanpy_dash/bin/activate\npython dash_app.py\n</code></pre> <p>The web application for analysis is available at</p> <pre><code>http://localhost:8000\n</code></pre> <p>Run the web application to browse and pool saved analysis</p> <pre><code>cd SanPy/dash\npython bBrowser_app.py\n</code></pre> <p>The web application for browsing and pooling saved analysis is available at</p> <pre><code>http://localhost:8050\n</code></pre>"},{"location":"api/analysisDir/","title":"analysisDir","text":"<p>Class to manage a list of files loaded from a folder.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>class analysisDir:\n\"\"\"\n    Class to manage a list of files loaded from a folder.\n    \"\"\"\n\n    sanpyColumns = _sanpyColumns\n\"\"\"Dict of dict of column names and bookkeeping info.\n    \"\"\"\n\n    theseFileTypes = [\".abf\", \".atf\", \".csv\", \".tif\"]\n\"\"\"File types to load.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: str = None,\n        myApp=None,\n        autoLoad: bool = False,\n        folderDepth: Optional[int] = None,\n    ):\n\"\"\"Load and manage a list of files in a folder path.\n\n        Use this as the main pandasModel for file list myTableView.\n\n        TODO: extend to link to folder in cloud (start with box and/or github)\n\n        Args:\n            path (str): Path to folder\n            myApp (sanpy.interface.sanpy_app): Optional\n            autoLoad (bool):\n            folderDepth (int):\n            #cloudDict (dict): To load from cloud, for now  just github\n\n        Notes:\n            - Some functions are so self can mimic a pandas dataframe used by pandasModel.\n                (shape, loc, loc_setter, iloc, iLoc_setter, columns, append, drop, sort_values, copy)\n        \"\"\"\n        self.path: str = path\n        self.myApp = myApp  # used to signal on building initial db\n        self.autoLoad = autoLoad  # not used\n\n        self.folderDepth = folderDepth  # specify int\n\n        self._isDirty = False\n\n        self._poolDf = None\n\"\"\"See pool_ functions\"\"\"\n\n        # keys are full path to file, if from cloud, key is 'cloud/&lt;filename&gt;'\n        # holds bAnalysisObjects\n        # needs to be a list so we can have files more than one\n        # self.fileList = [] #OrderedDict()\n\n        # TODO: refactor, we are not using the csv parth of this, just the filename\n        # name of database file created/loaded from folder path\n        self.dbFile = \"sanpy_recording_db.csv\"\n\n        self._df = None\n        # if autoLoad:\n        if 1:\n            self._df = self.loadHdf()\n            if self._df is None:\n                self._df = self.loadFolder(loadData=autoLoad)  # only used if no h5 file\n                self._updateLoadedAnalyzed()\n\n        # self._df = self.loadFolder(loadData=autoLoad)\n\n        #\n        self._checkColumns()\n        self._updateLoadedAnalyzed()\n\n\"\"\"\n        logger.warning('remember: temporary fix with _fixRelPath()\\n')\n        tmpFileList = self.getFileList()\n        _fixRelPath(self.path, self._df, tmpFileList)\n        \"\"\"\n\n    def __iter__(self):\n        self._iterIdx = 0\n        return self\n\n    def __next__(self):\n        if self._iterIdx &lt; self.numFiles:\n            x = self._df.loc[self._iterIdx][\"_ba\"]\n            self._iterIdx += 1\n            return x\n        else:\n            raise StopIteration\n\n    def __str__(self):\n        totalDurSec = self._df[\"Dur(s)\"].sum()\n        theStr = f\"analysisDir Num Files: {len(self)} Total Dur(s): {totalDurSec}\"\n        return theStr\n\n    @property\n    def isDirty(self):\n        return self._isDirty\n\n    def __len__(self):\n        return len(self._df)\n\n    @property\n    def numFiles(self):\n        return len(self._df)\n\n    @property\n    def shape(self):\n\"\"\"\n        Can't just return shape of _df, columns (like 'ba') may have been added\n        Number of columns is based on self.columns\n        \"\"\"\n        # return self._df.shape\n        numRows = self._df.shape[0]\n        numCols = len(self.columns)\n        return (numRows, numCols)\n\n    @property\n    def loc(self):\n\"\"\"Mimic pandas df.loc[]\"\"\"\n        return self._df.loc\n\n    @loc.setter\n    def loc_setter(self, rowIdx, colStr, value):\n        self._df.loc[rowIdx, colStr] = value\n\n    @property\n    def iloc(self):\n        # mimic pandas df.iloc[]\n        return self._df.iloc\n\n    @iloc.setter\n    def iLoc_setter(self, rowIdx, colIdx, value):\n        self._df.iloc[rowIdx, colIdx] = value\n        self._isDirty = True\n\n    @property\n    def at(self):\n        # mimic pandas df.at[]\n        return self._df.at\n\n    @at.setter\n    def at_setter(self, rowIdx, colStr, value):\n        self._df.at[rowIdx, colStr] = value\n        self._isDirty = True\n\n\"\"\"\n    @property\n    def iat(self):\n        # mimic pandas df.iat[]\n        return self._df.iat\n\n    @iat.setter\n    def iat_setter(self, rowIdx, colStr, value):\n        self._df.iat[rowIdx, colStr] = value\n        self._isDirty = True\n    \"\"\"\n\n    @property\n    def index(self):\n        return self._df.index\n\n    @property\n    def columns(self):\n        # return list of column names\n        return list(self.sanpyColumns.keys())\n\n    def copy(self):\n        return self._df.copy()\n\n    def sort_values(self, Ncol, order):\n        logger.info(f\"sorting by column {self.columns[Ncol]} with order:{order}\")\n        self._df = self._df.sort_values(self.columns[Ncol], ascending=not order)\n        # print(self._df)\n\n    @property\n    def columnsDict(self):\n        return self.sanpyColumns\n\n    def columnIsEditable(self, colName):\n        return self.sanpyColumns[colName][\"isEditable\"]\n\n    def columnIsCheckBox(self, colName):\n\"\"\"All bool columns are checkbox\n\n        TODO: problems with using type=bool and isinstance(). Kust using str 'bool'\n        \"\"\"\n        type = self.sanpyColumns[colName][\"type\"]\n        # isBool = isinstance(type, bool)\n        isBool = type == \"bool\"\n        # logger.info(f'{colName} {type(type)}, type:{type} {isBool}')\n        return isBool\n\n    def getDataFrame(self):\n\"\"\"Get the underlying pandas DataFrame.\"\"\"\n        return self._df\n\n    @property\n    def numFiles(self):\n\"\"\"Get the number of files. same as len().\"\"\"\n        return len(self._df)\n\n    def copyToClipboard(self):\n\"\"\"\n        TODO: Is this used or is copy to clipboard in pandas model?\n        \"\"\"\n        if self.getDataFrame() is not None:\n            self.getDataFrame().to_clipboard(sep=\"\\t\", index=False)\n            logger.info(\"Copied to clipboard\")\n\n    def old_saveDatabase(self):\n\"\"\"save dbFile .csv and hdf .gzip\"\"\"\n        dbPath = os.path.join(self.path, self.dbFile)\n        if self.getDataFrame() is not None:\n            #\n            logger.info(f'Saving \"{dbPath}\"')\n            self.getDataFrame().to_csv(dbPath, index=False)\n            self._isDirty = False\n\n            #\n\"\"\"\n            hdfFile = os.path.splitext(self.dbFile)[0] + '.h5'\n            hdfPath = os.path.join(self.path, hdfFile)\n            logger.info(f'Saving \"{hdfPath}\"')\n            #hdfStore = pd.HDFStore(hdfPath)\n            start = time.time()\n            complevel = 9\n            complib = 'blosc:blosclz'\n            with pd.HDFStore(hdfPath, mode='w', complevel=complevel, complib=complib) as hdfStore:\n                hdfStore['df'] = self.getDataFrame()  # save it\n            stop = time.time()\n            logger.info(f'Saving took {round(stop-start,2)} seconds')\n            \"\"\"\n\n    def old_getFrozenPath(self):\n        if getattr(sys, \"frozen\", False):\n            # running in a bundle (frozen)\n            myPath = sys._MEIPASS\n        else:\n            # running in a normal Python environment\n            # myPath = os.path.dirname(os.path.abspath(__file__))\n            myPath = pathlib.Path(__file__).parent.absolute()\n        return myPath\n\n    def old_rebuildHdf(self):\n        #\n        # rebuild the file to remove old changes and reduce size\n        tmpHdfFile = os.path.splitext(self.dbFile)[0] + \"_tmp.h5\"\n        # tmpHdfPath = os.path.join(self.path, tmpHdfFile)\n        tmpHdfPath = pathlib.Path(self.path) / tmpHdfFile\n\n        hdfFile = os.path.splitext(self.dbFile)[0] + \".h5\"\n        # hdfPath = os.path.join(self.path, hdfFile)\n        hdfPath = pathlib.Path(self.path) / hdfFile\n        logger.info(f\"Rebuilding h5 to {hdfPath}\")\n\n        # can't pass sys.argv a 'PosixPath' from pathlib.Path, needs to be a string\n        tmpHdfPath = str(tmpHdfPath)\n        hdfPath = str(hdfPath)\n\n        # when calling ptrepack, we need trailing ':' on each src/dst path\n        # without this Windows fails to find the file\n        _tmpHdfPath = tmpHdfPath + \":\"\n        _hdfPath = hdfPath + \":\"\n\n        # The first item is normally the command line command name (not used)\n        sys.argv = [\"\", \"--overwrite\", \"--chunkshape=auto\", _tmpHdfPath, _hdfPath]\n\n        logger.info(\"running tables.scripts.ptrepack.main()\")\n        logger.info(f\"sys.argv: {sys.argv}\")\n        try:\n            tables.scripts.ptrepack.main()  # noqa\n\n            # delete the temporary (large file)\n            logger.info(f\"Deleting tmp file: {tmpHdfPath}\")\n            os.remove(tmpHdfPath)\n\n            self.signalApp(\n                f\"Saved compressed folder analysis with tables.scripts.ptrepack.main()\"\n            )\n\n        except FileNotFoundError as e:\n            logger.error(\"tables.scripts.ptrepack.main() failed ... file was not saved\")\n            logger.error(e)\n            self.signalApp(f\"ERROR in tables.scripts.ptrepack.main(): {e}\")\n\n    def _not_used_save(self):\n\"\"\"Save all analysis as csv.\"\"\"\n        logger.info(\"\")\n        for ba in self:\n            if ba is not None:\n                # save detection and analysis to json\n                # ba.saveAnalysis(forceSave=True)\n\n                # save analysis to csv\n                ba.saveAnalysis_tocsv()\n\n    def old_getTmpHdfFile(self):\n\"\"\"Get temporary h5 file to write to.\n\n        We will always then compress with _rebuildHdf.\n        \"\"\"\n        logger.info(\"\")\n\n        tmpHdfFile = os.path.splitext(self.dbFile)[0] + \"_tmp.h5\"\n        tmpHdfPath = pathlib.Path(self.path) / tmpHdfFile\n\n        # the compressed version from the last save\n        hdfFile = os.path.splitext(self.dbFile)[0] + \".h5\"\n        hdfFilePath = pathlib.Path(self.path) / hdfFile\n\n        # hdfMode = 'w'\n        if os.path.isfile(hdfFilePath):\n            logger.info(f\"    copying existing hdf file to tmp \")\n            logger.info(f\"    hdfFilePath {hdfFilePath}\")\n            logger.info(f\"    tmpHdfPath {tmpHdfPath}\")\n            shutil.copyfile(hdfFilePath, tmpHdfPath)  # noqa\n        else:\n            pass\n            # compressed file does not exist, just use tmp path\n            # print('   does not exist:', hdfFilePath)\n\n        return tmpHdfPath\n\n    def getPathFromRelPath(self, relPath):\n\"\"\"Get full path to file (usually an abf file.\"\"\"\n        if relPath.startswith(\"/\"):\n            relPath = relPath[1:]\n\n        fullFilePath = os.path.join(self.path, relPath)\n\n\"\"\"\n        print('xxx', self.path)\n        print('xxx', relPath)\n        print('xxx', fullFilePath)\n        \"\"\"\n\n        return fullFilePath\n\n    def saveHdf(self):\n\"\"\"\n        Save file table and any number of loaded and analyzed bAnalysis.\n\n        Set file table 'uuid' column when we actually save a bAnalysis\n\n        Important: Order matters\n                (1) Save bAnalysis first, it updates uuid in file table.\n                (2) Save file table with updated uuid\n        \"\"\"\n        start = time.time()\n\n        df = self.getDataFrame()\n\n        # the compressed version from the last save\n        hdfFile = os.path.splitext(self.dbFile)[0] + \".h5\"\n        hdfFilePath = pathlib.Path(self.path) / hdfFile\n\n        logger.info(f\"Saving db (will be compressed) {hdfFilePath}\")\n\n        # save each bAnalysis\n        for row in range(len(df)):\n            ba = df.at[row, \"_ba\"]\n            if ba is not None:\n                didSave = ba._saveHdf_pytables(hdfFilePath)\n                if didSave:\n                    # we are now saved into h5 file, remember uuid to load\n                    # print('xxx SETTING dir uuid')\n                    df.at[row, \"uuid\"] = ba.uuid\n\n        # rebuild (L, A, S) columns\n        self._updateLoadedAnalyzed()\n\n        #\n        # save file database\n        logger.info(f\"    saving file db with {len(df)} rows\")\n        print(df)\n\n        dbKey = os.path.splitext(self.dbFile)[0]\n        df = df.drop(\"_ba\", axis=1)  # don't ever save _ba, use it for runtime\n\n        # hdfStore[dbKey] = df  # save it\n        df.to_hdf(hdfFilePath, dbKey)\n\n        #\n        self._isDirty = False  # if true, prompt to save on quit\n\n        # rebuild the file to remove old changes and reduce size\n        # self._rebuildHdf()\n        sanpy.h5Util._repackHdf(hdfFilePath)\n\n        # list the keys in the file\n        sanpy.h5Util.listKeys(hdfFilePath)\n\n        stop = time.time()\n        logger.info(f\"Saving took {round(stop-start,2)} seconds\")\n\n    def loadHdf(self, path=None):\n\"\"\"\n        Load the database key from an h5 file.\n\n        We do not load analy anlysis until user clicks on row, see loadOneAnalysis()\n        \"\"\"\n        if path is None:\n            path = self.path\n        self.path = path\n\n        df = None\n        hdfFile = os.path.splitext(self.dbFile)[0] + \".h5\"\n        hdfPath = pathlib.Path(self.path) / hdfFile\n        if not hdfPath.is_file():\n            return\n\n        logger.info(f\"Loading existing folder h5 file {hdfPath}\")\n        sanpy.h5Util.listKeys(hdfPath)\n\n        _start = time.time()\n        dbKey = os.path.splitext(self.dbFile)[0]\n\n        try:\n            df = pd.read_hdf(hdfPath, dbKey)\n        except KeyError as e:\n            # file is corrupt !!!\n            logger.error(f'    Load h5 failed, did not find dbKey:\"{dbKey}\" {e}')\n\n        if df is not None:\n            # _ba is for runtime, assign after loading from either (abf or h5)\n            df[\"_ba\"] = None\n\n            logger.info(\"    loaded db df\")\n            logger.info(f\"{df[['File', 'uuid']]}\")\n\n            # do not load anything until user clicks rows, see loadOneAnalysis()\n\n            _stop = time.time()\n            logger.info(f\"Loading took {round(_stop-_start,2)} seconds\")\n        #\n        return df\n\n    def loadOneAnalysis(self, path, uuid=None, allowAutoLoad=True, verbose=True):\n\"\"\"Load one bAnalysis either from original file path or uuid of h5 file.\n\n        If from h5, we still need to reload sweeps !!!\n        They are binary and fast, saving to h5 (in this case) is slow.\n        \"\"\"\n        if verbose:\n            logger.info(f'path:\"{path}\" uuid:\"{uuid}\" allowAutoLoad:\"{allowAutoLoad}\"')\n\n        hdfPath = self._getHdfFile()\n\n        # grab the fileLoaderDict from our app\n        # if it is None then bAnalysis will load this (from disk)\n        if self.myApp is not None:\n            _fileLoaderDict = self.myApp.getFileLoaderDict()\n        else:\n            _fileLoaderDict = None\n\n        ba = None\n        if uuid is not None and uuid:\n            # load from h5\n            if verbose:\n                logger.info(f\"    Retreiving uuid from hdf file {uuid}\")\n\n            # load from abf\n            ba = sanpy.bAnalysis(path, fileLoaderDict=_fileLoaderDict, verbose=verbose)\n\n            # load analysis from h5 file, will fail if uuid is not in file\n            ba._loadHdf_pytables(hdfPath, uuid)\n\n        if allowAutoLoad and ba is None:\n            # load from path\n            ba = sanpy.bAnalysis(path, fileLoaderDict=_fileLoaderDict, verbose=verbose)\n            if verbose:\n                logger.info(f\"    Loaded ba from path {path} and now ba:{ba}\")\n        #\n        return ba\n\n    def _getHdfFile(self):\n        hdfFile = os.path.splitext(self.dbFile)[0] + \".h5\"\n        hdfPath = os.path.join(self.path, hdfFile)\n        return hdfPath\n\n    def _deleteFromHdf(self, uuid):\n\"\"\"Delete uuid from h5 file.\n\n        Each bAnalysis detection get a unique uuid.\n        \"\"\"\n        if uuid is None or not uuid:\n            return\n        logger.info(f\"deleting from h5 file uuid:{uuid}\")\n\n        _hdfFile = os.path.splitext(self.dbFile)[0] + \".h5\"\n        hdfPath = pathlib.Path(self.path) / _hdfFile\n\n        # tmpHdfPath = self._getTmpHdfFile()\n\n        removed = False\n        with pd.HDFStore(hdfPath) as hdfStore:\n            try:\n                hdfStore.remove(uuid)\n                removed = True\n            except KeyError:\n                logger.error(f\"Did not find uuid {uuid} in h5 file {hdfPath}\")\n\n        #\n        if removed:\n            # will rebuild on next save\n            # self._rebuildHdf()\n            self._updateLoadedAnalyzed()\n            self._isDirty = True  # if true, prompt to save on quit\n\n    def loadFolder(self, path=None, loadData=False):\n\"\"\"\n        Parse a folder and load all (abf, csv, ...). Only called if no h5 file.\n\n        TODO: get rid of loading database from .csv (it is replaced by .h5 file)\n        TODO: extend the logic to load from cloud (after we were instantiated)\n        \"\"\"\n        logger.info(\"Loading folder from scratch (no hdf file)\")\n\n        start = time.time()\n        if path is None:\n            path = self.path\n        self.path = path\n\n        loadedDatabase = False\n\n        # load an existing folder db or create a new one\n        # abb 20220612 turned off loading from self.dbFile .csv file\n        dbPath = os.path.join(path, self.dbFile)\n        if 0 and os.path.isfile(dbPath):\n            # load from .csv\n            logger.info(f\"Loading existing folder db: {dbPath}\")\n            df = pd.read_csv(dbPath, header=0, index_col=False)\n            # df[\"Idx\"] = pd.to_numeric(df[\"Idx\"])\n            df = self._setColumnType(df)\n            loadedDatabase = True\n            # logger.info(f'  shape is {df.shape}')\n        else:\n            # logger.info(f'No existing db file, making {dbPath}')\n            logger.info(f\"No existing db file, making default dataframe\")\n            df = pd.DataFrame(columns=self.sanpyColumns.keys())\n            df = self._setColumnType(df)\n\n        if loadedDatabase:\n            # check columns with sanpyColumns\n            loadedColumns = df.columns\n            for col in loadedColumns:\n                if not col in self.sanpyColumns.keys():\n                    logger.error(\n                        f'error: bAnalysisDir did not find loaded col: \"{col}\" in sanpyColumns.keys()'\n                    )\n            for col in self.sanpyColumns.keys():\n                if not col in loadedColumns:\n                    logger.error(\n                        f'error: bAnalysisDir did not find sanpyColumns.keys() col: \"{col}\" in loadedColumns'\n                    )\n\n        if loadedDatabase:\n            # seach existing db for missing abf files\n            pass\n        else:\n            # get list of all abf/csv/tif files\n            fileList = self.getFileList(path)\n            _numFilesToLoad = len(fileList)\n            start = time.time()\n            # build new db dataframe\n            listOfDict = []\n            for rowIdx, fullFilePath in enumerate(fileList):\n                self.signalApp(\n                    f'Loading file {rowIdx+1} of {_numFilesToLoad} \"{fullFilePath}\"'\n                )\n\n                # rowDict is what we are showing in the file table\n                # abb debug vue, set loadData=True\n                # loads bAnalysis\n                ba, rowDict = self.getFileRow(fullFilePath, loadData=loadData)\n\n                if rowDict is None:\n                    logger.warning(f'error loading file {fullFilePath}')\n                    continue\n\n                # TODO: calculating time, remove this\n                # This is 2x faster than loading from pandas gzip ???\n                # dDict = sanpy.bAnalysis.getDefaultDetection()\n                # dDict['dvdtThreshold'] = 2\n                # ba.spikeDetect(dDict)\n\n                # as we parse the folder, don't load ALL files (will run out of memory)\n                if loadData:\n                    rowDict[\"_ba\"] = ba\n                else:\n                    rowDict[\"_ba\"] = None  # ba\n\n                # do not assign uuid until bAnalysis is saved in h5 file\n                # rowDict['uuid'] = ''\n\n                # 20230313 moved into getFileRow()\n                # relPath = fullFilePath.replace(path, '')\n                # if relPath.startswith('/'):\n                #     # so we can use os.path.join()\n                #     relPath = relPath[1:]\n                # rowDict['relPath'] = relPath\n\n                # logger.info(f'    row:{rowIdx} relPath:{relPath} fullFilePath:{fullFilePath}')\n\n                listOfDict.append(rowDict)\n\n            stop = time.time()\n            logger.info(f\"Load took {round(stop-start,3)} seconds.\")\n\n            #\n            df = pd.DataFrame(listOfDict)\n            # print('=== built new db df:')\n            # print(df)\n            df = self._setColumnType(df)\n        #\n\n        # expand each to into self.fileList\n        # df['_ba'] = None\n\n        stop = time.time()\n        logger.info(f\"Load took {round(stop-start,2)} seconds.\")\n        return df\n\n    def _checkColumns(self):\n\"\"\"Check columns in loaded vs sanpyColumns (and vica versa).\n        \"\"\"\n        if self._df is None:\n            return\n        loadedColumns = self._df.columns\n        for col in loadedColumns:\n            if not col in self.sanpyColumns.keys():\n                # loaded has unexpected column, leave it\n                logger.info(\n                    f'did not find loaded col: \"{col}\" in sanpyColumns.keys() ... ignore it'\n                )\n        for col in self.sanpyColumns.keys():\n            if not col in loadedColumns:\n                # loaded is missing expected, add it\n                logger.info(\n                    f'did not find sanpyColumns.keys() col: \"{col}\" in loadedColumns ... adding col'\n                )\n                self._df[col] = \"\"\n\n    def _updateLoadedAnalyzed(self, theRowIdx=None):\n\"\"\"Refresh Loaded (L) and Analyzed (A) columns.\n\n        Arguments:\n            theRowIdx (int): Update just one row\n\n        TODO: For kymograph, add rows (left, top, right, bottom) and update\n        \"\"\"\n        if self._df is None:\n            return\n        for rowIdx in range(len(self._df)):\n            if theRowIdx is not None and theRowIdx != rowIdx:\n                continue\n\n            ba = self._df.loc[rowIdx, \"_ba\"]  # Can be None\n\n            # uuid = self._df.at[rowIdx, 'uuid']\n            #\n            # loaded\n            if self.isLoaded(rowIdx):\n                theChar = \"\\u2022\"  # FILLED BULLET\n            # elif uuid:\n            #    #theChar = '\\u25CB'  # open circle\n            #    theChar = '\\u25e6'  # white bullet\n            else:\n                theChar = \"\"\n            # self._df.iloc[rowIdx, loadedCol] = theChar\n            self._df.loc[rowIdx, \"L\"] = theChar\n            #\n            # analyzed\n            if self.isAnalyzed(rowIdx):\n                theChar = \"\\u2022\"  # FILLED BULLET\n                self._df.loc[rowIdx, \"N\"] = ba.numSpikes\n                _numErrors = ba.numErrors\n                if _numErrors is None:\n                    _numErrors = ''\n                logger.warning(f'setting E to _numErrors {_numErrors}')\n                self._df.loc[rowIdx, \"E\"] = _numErrors\n            # elif uuid:\n            #    #theChar = '\\u25CB'\n            #    theChar = '\\u25e6'  # white bullet\n            else:\n                theChar = \"\"\n                self._df.loc[rowIdx, \"A\"] = \"\"\n            # self._df.iloc[rowIdx, analyzedCol] = theChar\n            self._df.loc[rowIdx, \"A\"] = theChar\n            #\n            # saved\n            if self.isSaved(rowIdx):\n                theChar = \"\\u2022\"  # FILLED BULLET\n            else:\n                theChar = \"\"\n            # self._df.iloc[rowIdx, savedCol] = theChar\n            self._df.loc[rowIdx, \"S\"] = theChar\n            #\n            # start(s) and stop(s) from ba detectionDict\n            if self.isAnalyzed(rowIdx):\n                # set table to values we just detected with\n                startSec = ba.getDetectionDict()[\"startSeconds\"]\n                stopSec = ba.getDetectionDict()[\"stopSeconds\"]\n                self._df.loc[rowIdx, \"Start(s)\"] = startSec\n                self._df.loc[rowIdx, \"Stop(s)\"] = stopSec\n\n                dvdtThreshold = ba.getDetectionDict()[\"dvdtThreshold\"]\n                mvThreshold = ba.getDetectionDict()[\"mvThreshold\"]\n                self._df.loc[rowIdx, \"dvdtThreshold\"] = dvdtThreshold\n                self._df.loc[rowIdx, \"mvThreshold\"] = mvThreshold\n\n                #\n                # TODO: remove start of ba._path that corresponds to our current folder path\n                # will allow our save db to be modular\n\n                # relPth should usually be filled in ???\n\"\"\"\n                relPath = self.getPathFromRelPath(ba._path)\n                self._df.loc[rowIdx, 'relPath'] = relPath\n                \"\"\"\n\n                # logger.info('maybe put back in')\n                # print(f'    self._df.loc[rowIdx, \"relPath\"] is \"{self._df.loc[rowIdx, \"relPath\"]}\"')\n\n            # kymograph interface\n            # if ba is not None and ba.isKymograph():\n            # if ba is not None and isinstance(ba, sanpy.fileloaders.fileLoader_tif):\n            if ba is not None and ba.fileLoader.isKymograph():\n                kRect = ba.fileLoader.getKymographRect()\n\n                # print(kRect)\n                # sys.exit(1)\n\n                if kRect is None:\n                    logger.error(f\"Got None kymograph rect\")\n                else:\n                    self._df.loc[rowIdx, \"kLeft\"] = kRect[0]\n                    self._df.loc[rowIdx, \"kTop\"] = kRect[1]\n                    self._df.loc[rowIdx, \"kRight\"] = kRect[2]\n                    self._df.loc[rowIdx, \"kBottom\"] = kRect[3]\n                #\n                # TODO: remove start of ba._path that corresponds to our current folder path\n                # will allow our save db to be modular\n                # self._df.loc[rowIdx, 'path'] = ba._path\n\n\"\"\"\n    def setCellValue(self, rowIdx, colStr, value):\n        self._df.loc[rowIdx, colStr] = value\n    \"\"\"\n\n    def isLoaded(self, rowIdx):\n        isLoaded = self._df.loc[rowIdx, \"_ba\"] is not None\n        return isLoaded\n\n    def isAnalyzed(self, rowIdx):\n        isAnalyzed = False\n        ba = self._df.loc[rowIdx, \"_ba\"]\n        # print('isAnalyzed()', rowIdx, ba)\n        # if ba is not None:\n        # print('qqq', rowIdx, ba, type(ba))\n        # sanpy.bAnalysis_.bAnalysis\n        # if isinstance(ba, sanpy.bAnalysis):\n        if ba is not None:\n            isAnalyzed = ba.isAnalyzed()\n        return isAnalyzed\n\n    def analysisIsDirty(self, rowIdx):\n\"\"\"Analysis is dirty when there has been detection but not saved to h5.\"\"\"\n        isDirty = False\n        ba = self._df.loc[rowIdx, \"_ba\"]\n        if isinstance(ba, sanpy.bAnalysis):\n            isDirty = ba.isDirty()\n        return isDirty\n\n    def hasDirty(self):\n\"\"\"Return true if any bAnalysis in list has been analyzed but not saved (e.g. is dirty)\"\"\"\n        haveDirty = False\n        numRows = len(self._df)\n        for rowIdx in range(numRows):\n            if self.analysisIsDirty(rowIdx):\n                haveDirty = True\n\n        return haveDirty\n\n    def isSaved(self, rowIdx):\n        uuid = self._df.at[rowIdx, \"uuid\"]\n        return len(uuid) &gt; 0\n\n    def getAnalysis(self, rowIdx, allowAutoLoad=True, verbose=True) -&gt; sanpy.bAnalysis:\n\"\"\"Get bAnalysis object, will load if necc.\n\n        Args:\n            rowIdx (int): Row index from table, corresponds to row in self._df\n            allowAutoLoad (bool)\n        Return:\n            bAnalysis\n        \"\"\"\n        file = self._df.loc[rowIdx, \"File\"]\n        ba = self._df.loc[rowIdx, \"_ba\"]\n        uuid = self._df.loc[\n            rowIdx, \"uuid\"\n        ]  # if we have a uuid bAnalysis is saved in h5f\n        # filePath = os.path.join(self.path, file)\n        # logger.info(f'Found _ba in file db with ba:\"{ba}\" {type(ba)}')\n        # logger.info(f'rowIdx: {rowIdx} ba:{ba}')\n\n        if ba is None or ba == \"\":\n            # logger.info('did not find _ba ... loading from abf file ...')\n            # working on kymograph\n            #                 relPath = self.getPathFromRelPath(ba._path)\n            relPath = self._df.loc[rowIdx, \"relPath\"]\n            filePath = self.getPathFromRelPath(relPath)\n\n            ba = self.loadOneAnalysis(\n                filePath, uuid, allowAutoLoad=allowAutoLoad, verbose=verbose\n            )\n            # load\n\"\"\"\n            logger.info(f'Loading bAnalysis from row {rowIdx} \"{filePath}\"')\n            ba = sanpy.bAnalysis(filePath)\n            \"\"\"\n            if ba is None:\n                logger.warning(\n                    f'Did not load row {rowIdx} path: \"{filePath}\". Analysis was probably not saved'\n                )\n            else:\n                self._df.at[rowIdx, \"_ba\"] = ba\n                # does not get a uuid until save into h5\n                if uuid:\n                    # there was an original uuid (in table), means we are saved into h5\n                    self._df.at[rowIdx, \"uuid\"] = uuid\n                    if uuid != ba.uuid:\n                        logger.error(\n                            \"Loaded uuid does not match existing in file table\"\n                        )\n                        logger.error(f\"  Loaded {ba.uuid}\")\n                        logger.error(f\"  Existing {uuid}\")\n\n                # kymograph, set ba rect from table\n                # if ba.isKymograph():\n                # if ba is not None and isinstance(ba, sanpy.fileloaders.fileLoader_tif):\n                if ba is not None and ba.fileLoader.isKymograph():\n                    left = self._df.loc[rowIdx, \"kLeft\"]\n                    top = self._df.loc[rowIdx, \"kTop\"]\n                    right = self._df.loc[rowIdx, \"kRight\"]\n                    bottom = self._df.loc[rowIdx, \"kBottom\"]\n\n                    # on first load, these will be empty\n                    # grab rect from ba (in _updateLoadedAnalyzed())\n                    if left == \"\" or top == \"\" or right == \"\" or bottom == \"\":\n                        pass\n                    else:\n                        theRect = [left, top, right, bottom]\n                        logger.info(f\"  theRect:{theRect}\")\n                        ba.fileLoader._updateTifRoi(theRect)\n\n                #\n                # update stats of table load/analyzed columns\n                self._updateLoadedAnalyzed()\n\n        return ba\n\n    def _setColumnType(self, df):\n\"\"\"Needs to be called every time a df is created.\n        Ensures proper type of columns following sanpyColumns[key]['type']\n        \"\"\"\n        # print('columns are:', df.columns)\n        for col in df.columns:\n            # when loading from csv, 'col' may not be in sanpyColumns\n            if not col in self.sanpyColumns:\n                logger.warning(f'Column \"{col}\" is not in sanpyColumns --&gt;&gt; ignoring')\n                continue\n            colType = self.sanpyColumns[col][\"type\"]\n            # print(f'  _setColumnType() for \"{col}\" is type \"{colType}\"')\n            # print(f'    df[col]:', 'len:', len(df[col]))\n            # print(df[col])\n            if colType == str:\n                df[col] = df[col].replace(np.nan, \"\", regex=True)\n                df[col] = df[col].astype(str)\n            elif colType == int:\n                pass\n                # print('!!! df[col]:', df[col])\n                # df[col] = df[col].astype(int)\n            elif colType == float:\n                # error if ''\n                df[col] = df[col].astype(float)\n            elif colType == bool:\n                df[col] = df[col].astype(bool)\n            else:\n                logger.warning(f'Did not parse col \"{col}\" with type \"{colType}\"')\n        #\n        return df\n\n    def getFileRow(self, path, loadData=False):\n\"\"\"Get dict representing one file (row in table). Loads bAnalysis to get headers.\n\n        On load error of proper file type (abf, csv), ba.loadError==True\n\n        Args:\n            path (Str): Full path to file.\n            #rowIdx (int): Optional row index to assign in column 'Idx'\n\n        Return:\n            (tuple): tuple containing:\n\n            - ba (bAnalysis): [sanpy.bAnalysis](/api/bAnalysis).\n            - rowDict (dict): On success, otherwise None.\n                    fails when path does not lead to valid bAnalysis file.\n        \"\"\"\n        if not os.path.isfile(path):\n            logger.warning(f'Did not find file \"{path}\"')\n            return None, None\n        fileType = os.path.splitext(path)[1]\n        if fileType not in self.theseFileTypes:\n            logger.warning(f'Did not load file type \"{fileType}\"')\n            return None, None\n\n        # grab the fileLoaderDict from our app\n        # if it is None then bAnalysis will load this (from disk)\n        if self.myApp is not None:\n            _fileLoaderDict = self.myApp.getFileLoaderDict()\n        else:\n            _fileLoaderDict = None\n\n        # load bAnalysis\n        # logger.info(f'Loading bAnalysis \"{path}\"')\n        # loadData is false, load header\n        ba = sanpy.bAnalysis(path, loadData=loadData, fileLoaderDict=_fileLoaderDict)\n\n        if ba.loadError:\n            logger.error(f'Error loading bAnalysis file \"{path}\"')\n            # return None, None\n\n        # not sufficient to default everything to empty str ''\n        # sanpyColumns can only have type in ('float', 'str')\n        rowDict = dict.fromkeys(self.sanpyColumns.keys(), \"\")\n        for k in rowDict.keys():\n            if self.sanpyColumns[k][\"type\"] == str:\n                rowDict[k] = \"\"\n            elif self.sanpyColumns[k][\"type\"] == float:\n                rowDict[k] = np.nan\n\n        # if rowIdx is not None:\n        #    rowDict['Idx'] = rowIdx\n\n\"\"\"\n        if ba.loadError:\n            rowDict['I'] = 0\n        else:\n            rowDict['I'] = 2 # need 2 because checkbox value is in (0,2)\n        \"\"\"\n\n        if ba.loadError:\n            return None, None\n\n        rowDict[\"File\"] = ba.fileLoader.filename  # os.path.split(ba.path)[1]\n        rowDict[\"Dur(s)\"] = ba.fileLoader.recordingDur\n\n        rowDict[\"Channels\"] = ba.fileLoader.numChannels  # Theanne\n\n        rowDict[\"Sweeps\"] = ba.fileLoader.numSweeps\n\n        # TODO: here, we do not get an epoch table until the file is loaded !!!\n        rowDict[\"Epochs\"] = ba.fileLoader.numEpochs  # Theanne, data has to be loaded\n\n        rowDict[\"kHz\"] = ba.fileLoader.recordingFrequency\n        rowDict[\"Mode\"] = ba.fileLoader.recordingMode.value\n\n        # rowDict['dvdtThreshold'] = 20\n        # rowDict['mvThreshold'] = -20\n        if ba.isAnalyzed():\n            dDict = ba.getDetectionDict()\n            # rowDict['I'] = dDict.getValue('include')\n            rowDict[\"dvdtThreshold\"] = dDict.getValue(\"dvdtThreshold\")\n            rowDict[\"mvThreshold\"] = dDict.getValue(\"mvThreshold\")\n            rowDict[\"Start(s)\"] = dDict.getValue(\"startSeconds\")\n            rowDict[\"Stop(s)\"] = dDict.getValue(\"stopSeconds\")\n\n        # remove the path to the folder we have loaded\n        relPath = path.replace(self.path, \"\")\n\n        # logger.info(f'xxx self.path: \"{self.path}\"')\n        # logger.info(f'xxx path: \"{path}\"')\n        # logger.info(f'xxx relPath: \"{relPath}\"')\n\n        if relPath.startswith(\"/\"):\n            # so we can use os.path.join()\n            relPath = relPath[1:]\n        # added 20230505 working with johnson in 1313 to fix windows bug ???\n        if relPath.startswith(\"\\\\\"):\n            # so we can use os.path.join()\n            relPath = relPath[1:]\n\n        rowDict[\"relPath\"] = relPath\n\n        #logger.info(f'2) xxx relPath: \"{relPath}\"')\n\n        return ba, rowDict\n\n    def getFileList(self, path: str = None) -&gt; List[str]:\n\"\"\"Get file paths from path.\n\n        Uses self.theseFileTypes\n        \"\"\"\n        if path is None:\n            path = self.path\n\n        logger.warning(\"Remember: MODIFIED TO LOAD TIF FILES IN SUBFOLDERS\")\n        count = 1\n        tmpFileList = []\n        folderDepth = self.folderDepth  # if none then all depths\n        excludeFolders = [\"analysis\", \"hide\"]\n        for root, subdirs, files in os.walk(path):\n            subdirs[:] = [d for d in subdirs if d not in excludeFolders]\n\n            # print('folderDepth:', folderDepth)\n            # print('  root:', root, 'subdirs:', subdirs, 'files:', files)\n\n            # strip out folders that start with __\n            # _parentFolder = os.path.split(root)[1]\n            # print('root:', root)\n            # print('  parentFolder:', _parentFolder)\n            # if _parentFolder.startswith('__'):\n            if \"__\" in root:\n                logger.info(f\"SKIPPING based on path root:{root}\")\n                continue\n\n            if os.path.split(root)[1] == \"analysis\":\n                # don't load from analysis/ folder, we save analysis there\n                continue\n\n            # if os.path.split(root)[1] == 'hide':\n            #     # special case/convention, don't load from 'hide' folders\n            #     continue\n\n            for file in files:\n                # TODO (cudmore) parse all our fileLoader(s) for a list\n                _, _ext = os.path.splitext(file)\n                if _ext in self.theseFileTypes:\n                    oneFile = os.path.join(root, file)\n                    tmpFileList.append(oneFile)\n\n            count += 1\n            if folderDepth is not None and count &gt; folderDepth:\n                break\n\n        fileList = []\n        for file in sorted(tmpFileList):\n            if file.startswith(\".\"):\n                continue\n            # ignore our database file\n            if file == self.dbFile:\n                continue\n\n            # tmpExt is like .abf, .csv, etc\n            tmpFileName, tmpExt = os.path.splitext(file)\n            if tmpExt in self.theseFileTypes:\n                # if getFullPath:\n                #     #file = os.path.join(path, file)\n                #     file = pathlib.Path(path) / file\n                #     file = str(file)  # return List[str] NOT List[PosixPath]\n                fileList.append(file)\n        #\n        logger.info(f\"found {len(fileList)} files ...\")\n        return fileList\n\n    def getRowDict(self, rowIdx):\n\"\"\"\n        Return a dict with selected row as dict (includes detection parameters).\n\n        Important to return a copy as our '_ba' is a pointer to bAnalysis.\n\n        Returns:\n            theRet (dict): Be sure to make a deep copy of ['_ba'] if neccessary.\n        \"\"\"\n        theRet = {}\n        # use columns in main sanpyColumns, not in df\n        # for colStr in self.columns:\n        for colStr in self._df.columns:\n            # theRet[colStr] = self._df.loc[rowIdx, colStr]\n            theRet[colStr] = self._df.loc[rowIdx, colStr]\n        # theRet['_ba'] = theRet['_ba'].copy()\n        return theRet\n\n    def appendRow(self, rowDict=None, ba=None):\n\"\"\"Append an empty row.\"\"\"\n\n        # logger.info('')\n        # print('    rowDict:', rowDict)\n        # print('    ba:', ba)\n\n        rowSeries = pd.Series()\n        if rowDict is not None:\n            rowSeries = pd.Series(rowDict)\n            # self._data.iloc[row] = rowSeries\n            # self._data = self._data.reset_index(drop=True)\n\n        newRowIdx = len(self._df)\n        df = self._df\n        logger.warning(f\"need to replace append with concat\")\n        df = df.append(rowSeries, ignore_index=True)\n        # df = pd.concat([df,rowSeries], ignore_index=True, axis=1)\n        df = df.reset_index(drop=True)\n\n        if ba is not None:\n            df.loc[newRowIdx, \"_ba\"] = ba\n\n        #\n        self._df = df\n\n    def unloadRow(self, rowIdx):\n        self._df.loc[rowIdx, \"_ba\"] = None\n        self._updateLoadedAnalyzed()\n\n    def removeRowFromDatabase(self, rowIdx):\n        # delete from h5 file\n        uuid = self._df.at[rowIdx, \"uuid\"]\n        self._deleteFromHdf(uuid)\n\n        # clear uuid\n        self._df.at[rowIdx, \"uuid\"] = \"\"\n\n        self._updateLoadedAnalyzed()\n\n    def deleteRow(self, rowIdx):\n        df = self._df\n\n        # delete from h5 file\n        uuid = df.at[rowIdx, \"uuid\"]\n        self._deleteFromHdf(uuid)\n\n        # delete from df/model\n        df = df.drop([rowIdx])\n        df = df.reset_index(drop=True)\n        self._df = df\n\n        self._updateLoadedAnalyzed()\n\n    def old_duplicateRow(self, rowIdx):\n\"\"\"Depreciated, Was used to have different ocnditions within a recording,\n        this is now handled by condiiton column.\n        \"\"\"\n        # duplicate rowIdx\n        newIdx = rowIdx + 0.5\n\n        rowDict = self.getRowDict(rowIdx)\n\n        # CRITICAL: Need to make a deep copy of the _ba pointer to bAnalysis object\n        logger.info(f\"copying {type(rowDict['_ba'])} {rowDict['_ba']}\")\n        baNew = copy.deepcopy(rowDict[\"_ba\"])\n\n        # copy of bAnalysis needs a new uuid\n        new_uuid = (\n            sanpy._util.getNewUuid()\n        )  # 't' + str(uuid.uuid4())   #.replace('-', '_')\n        logger.info(f\"assigning new uuid {new_uuid} to {baNew}\")\n\n        if baNew.uuid == new_uuid:\n            logger.error(\"!!!!!!!!!!!!!!!!!!!!!!!!!CRITICAL, new uuid is same as old\")\n\n        baNew.uuid = new_uuid\n\n        rowDict[\"_ba\"] = baNew\n        rowDict[\"uuid\"] = baNew.uuid  # new row can never have same uuid as old\n\n        dfRow = pd.DataFrame(rowDict, index=[newIdx])\n\n        df = self._df\n        df = df.append(dfRow, ignore_index=True)\n        df = df.sort_values(by=[\"File\"], axis=\"index\", ascending=True, inplace=False)\n        df = df.reset_index(drop=True)\n        self._df = df\n\n        self._updateLoadedAnalyzed()\n\n    def syncDfWithPath(self):\n\"\"\"Sync path with existing df. Used to detect new/removed files.\"\"\"\n\n        pathFileList = self.getFileList()  # always full path\n        dfFileList = self._df[\"File\"].tolist()\n\n        logger.info(\"\")\n        # print('    === pathFileList (on drive):')\n        # print('    ', pathFileList)\n        # print('    === dfFileList (in table):')\n        # print('    ', dfFileList)\n\n        addedToDf = False\n\n        # look for files in path not in df\n        for pathFile in pathFileList:\n            fileName = os.path.split(pathFile)[1]\n            if fileName not in dfFileList:\n                logger.info(f'Found file in path \"{fileName}\" not in df')\n                # load bAnalysis and get df column values\n                addedToDf = True\n                # fullPathFile = os.path.join(self.path, pathFile)\n                ba, rowDict = self.getFileRow(pathFile)  # loads bAnalysis\n                if rowDict is not None:\n                    # listOfDict.append(rowDict)\n\n                    # TODO: get this into getFileROw()\n                    logger.warning(\"20220718, not sure we need this ???\")\n                    # rowDict['relPath'] = pathFile\n                    rowDict[\"_ba\"] = None\n\n                    self.appendRow(rowDict=rowDict, ba=None)\n\n        # look for files in df not in path\n        # for dfFile in dfFileList:\n        #     if not dfFile in pathFileList:\n        #         logger.info(f'Found file in df \"{dfFile}\" not in path')\n\n        if addedToDf:\n            df = self._df\n            df = df.sort_values(\n                by=[\"File\"], axis=\"index\", ascending=True, inplace=False\n            )\n            df = df.reset_index(drop=True)\n            self._df = df\n\n        self._updateLoadedAnalyzed()\n\n    def pool_build(self):\n\"\"\"Build one df with all analysis. Use this in plot tool plugin.\"\"\"\n        logger.info(\"\")\n        masterDf = None\n        for row in range(self.numFiles):\n            if not self.isAnalyzed(row):\n                logger.info(f\"  row:{row} not analyzed\")\n                continue\n            ba = self.getAnalysis(row)\n            oneDf = ba.asDataFrame()\n            if oneDf is not None:\n                self.signalApp(f'  adding \"{ba.fileLoader.filename}\"')\n                oneDf[\"File Number\"] = int(row)\n                if masterDf is None:\n                    masterDf = oneDf\n                else:\n                    masterDf = pd.concat([masterDf, oneDf])\n        #\n        if masterDf is None:\n            logger.error(\"Did not find any analysis.\")\n        else:\n            logger.info(f\"final num spikes {len(masterDf)}\")\n        # print(masterDf.head())\n        self._poolDf = masterDf\n\n        return self._poolDf\n\n    def signalApp(self, str):\n\"\"\"Update status bar of SanPy app.\n\n        TODO make this a signal and connect app to it.\n            Will not be able to do this, we need to run outside Qt\n        \"\"\"\n        if self.myApp is not None:\n            self.myApp.slot_updateStatus(str)\n        else:\n            logger.info(str)\n\n    def api_getFileHeaders(self):\n        headerList = []\n        df = self.getDataFrame()\n        for row in range(len(df)):\n            # ba = self.getAnalysis(row)  # do not call this, it will load\n            ba = df.at[row, \"_ba\"]\n            if ba is not None:\n                headerDict = ba.api_getHeader()\n                headerList.append(headerDict)\n        #\n        return headerList\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir-attributes","title":"Attributes","text":""},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.loc","title":"<code>loc</code>  <code>property</code> <code>writable</code>","text":"<p>Mimic pandas df.loc[]</p>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.numFiles","title":"<code>numFiles</code>  <code>property</code>","text":"<p>Get the number of files. same as len().</p>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.sanpyColumns","title":"<code>sanpyColumns = _sanpyColumns</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Dict of dict of column names and bookkeeping info.</p>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Can't just return shape of _df, columns (like 'ba') may have been added Number of columns is based on self.columns</p>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.theseFileTypes","title":"<code>theseFileTypes = ['.abf', '.atf', '.csv', '.tif']</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>File types to load.</p>"},{"location":"api/analysisDir/#sanpy.analysisDir-functions","title":"Functions","text":""},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.__init__","title":"<code>__init__(path=None, myApp=None, autoLoad=False, folderDepth=None)</code>","text":"<p>Load and manage a list of files in a folder path.</p> <p>Use this as the main pandasModel for file list myTableView.</p> <p>TODO: extend to link to folder in cloud (start with box and/or github)</p> <p>Args:     path (str): Path to folder     myApp (sanpy.interface.sanpy_app): Optional     autoLoad (bool):     folderDepth (int):     #cloudDict (dict): To load from cloud, for now  just github</p> <p>Notes:     - Some functions are so self can mimic a pandas dataframe used by pandasModel.         (shape, loc, loc_setter, iloc, iLoc_setter, columns, append, drop, sort_values, copy)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def __init__(\n    self,\n    path: str = None,\n    myApp=None,\n    autoLoad: bool = False,\n    folderDepth: Optional[int] = None,\n):\n\"\"\"Load and manage a list of files in a folder path.\n\n    Use this as the main pandasModel for file list myTableView.\n\n    TODO: extend to link to folder in cloud (start with box and/or github)\n\n    Args:\n        path (str): Path to folder\n        myApp (sanpy.interface.sanpy_app): Optional\n        autoLoad (bool):\n        folderDepth (int):\n        #cloudDict (dict): To load from cloud, for now  just github\n\n    Notes:\n        - Some functions are so self can mimic a pandas dataframe used by pandasModel.\n            (shape, loc, loc_setter, iloc, iLoc_setter, columns, append, drop, sort_values, copy)\n    \"\"\"\n    self.path: str = path\n    self.myApp = myApp  # used to signal on building initial db\n    self.autoLoad = autoLoad  # not used\n\n    self.folderDepth = folderDepth  # specify int\n\n    self._isDirty = False\n\n    self._poolDf = None\n\"\"\"See pool_ functions\"\"\"\n\n    # keys are full path to file, if from cloud, key is 'cloud/&lt;filename&gt;'\n    # holds bAnalysisObjects\n    # needs to be a list so we can have files more than one\n    # self.fileList = [] #OrderedDict()\n\n    # TODO: refactor, we are not using the csv parth of this, just the filename\n    # name of database file created/loaded from folder path\n    self.dbFile = \"sanpy_recording_db.csv\"\n\n    self._df = None\n    # if autoLoad:\n    if 1:\n        self._df = self.loadHdf()\n        if self._df is None:\n            self._df = self.loadFolder(loadData=autoLoad)  # only used if no h5 file\n            self._updateLoadedAnalyzed()\n\n    # self._df = self.loadFolder(loadData=autoLoad)\n\n    #\n    self._checkColumns()\n    self._updateLoadedAnalyzed()\n\n\"\"\"\n    logger.warning('remember: temporary fix with _fixRelPath()\\n')\n    tmpFileList = self.getFileList()\n    _fixRelPath(self.path, self._df, tmpFileList)\n    \"\"\"\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.analysisIsDirty","title":"<code>analysisIsDirty(rowIdx)</code>","text":"<p>Analysis is dirty when there has been detection but not saved to h5.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def analysisIsDirty(self, rowIdx):\n\"\"\"Analysis is dirty when there has been detection but not saved to h5.\"\"\"\n    isDirty = False\n    ba = self._df.loc[rowIdx, \"_ba\"]\n    if isinstance(ba, sanpy.bAnalysis):\n        isDirty = ba.isDirty()\n    return isDirty\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.appendRow","title":"<code>appendRow(rowDict=None, ba=None)</code>","text":"<p>Append an empty row.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def appendRow(self, rowDict=None, ba=None):\n\"\"\"Append an empty row.\"\"\"\n\n    # logger.info('')\n    # print('    rowDict:', rowDict)\n    # print('    ba:', ba)\n\n    rowSeries = pd.Series()\n    if rowDict is not None:\n        rowSeries = pd.Series(rowDict)\n        # self._data.iloc[row] = rowSeries\n        # self._data = self._data.reset_index(drop=True)\n\n    newRowIdx = len(self._df)\n    df = self._df\n    logger.warning(f\"need to replace append with concat\")\n    df = df.append(rowSeries, ignore_index=True)\n    # df = pd.concat([df,rowSeries], ignore_index=True, axis=1)\n    df = df.reset_index(drop=True)\n\n    if ba is not None:\n        df.loc[newRowIdx, \"_ba\"] = ba\n\n    #\n    self._df = df\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.columnIsCheckBox","title":"<code>columnIsCheckBox(colName)</code>","text":"<p>All bool columns are checkbox</p> <p>TODO: problems with using type=bool and isinstance(). Kust using str 'bool'</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def columnIsCheckBox(self, colName):\n\"\"\"All bool columns are checkbox\n\n    TODO: problems with using type=bool and isinstance(). Kust using str 'bool'\n    \"\"\"\n    type = self.sanpyColumns[colName][\"type\"]\n    # isBool = isinstance(type, bool)\n    isBool = type == \"bool\"\n    # logger.info(f'{colName} {type(type)}, type:{type} {isBool}')\n    return isBool\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.copyToClipboard","title":"<code>copyToClipboard()</code>","text":"<p>TODO: Is this used or is copy to clipboard in pandas model?</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def copyToClipboard(self):\n\"\"\"\n    TODO: Is this used or is copy to clipboard in pandas model?\n    \"\"\"\n    if self.getDataFrame() is not None:\n        self.getDataFrame().to_clipboard(sep=\"\\t\", index=False)\n        logger.info(\"Copied to clipboard\")\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.getAnalysis","title":"<code>getAnalysis(rowIdx, allowAutoLoad=True, verbose=True)</code>","text":"<p>Get bAnalysis object, will load if necc.</p> <p>Args:     rowIdx (int): Row index from table, corresponds to row in self._df     allowAutoLoad (bool) Return:     bAnalysis</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def getAnalysis(self, rowIdx, allowAutoLoad=True, verbose=True) -&gt; sanpy.bAnalysis:\n\"\"\"Get bAnalysis object, will load if necc.\n\n    Args:\n        rowIdx (int): Row index from table, corresponds to row in self._df\n        allowAutoLoad (bool)\n    Return:\n        bAnalysis\n    \"\"\"\n    file = self._df.loc[rowIdx, \"File\"]\n    ba = self._df.loc[rowIdx, \"_ba\"]\n    uuid = self._df.loc[\n        rowIdx, \"uuid\"\n    ]  # if we have a uuid bAnalysis is saved in h5f\n    # filePath = os.path.join(self.path, file)\n    # logger.info(f'Found _ba in file db with ba:\"{ba}\" {type(ba)}')\n    # logger.info(f'rowIdx: {rowIdx} ba:{ba}')\n\n    if ba is None or ba == \"\":\n        # logger.info('did not find _ba ... loading from abf file ...')\n        # working on kymograph\n        #                 relPath = self.getPathFromRelPath(ba._path)\n        relPath = self._df.loc[rowIdx, \"relPath\"]\n        filePath = self.getPathFromRelPath(relPath)\n\n        ba = self.loadOneAnalysis(\n            filePath, uuid, allowAutoLoad=allowAutoLoad, verbose=verbose\n        )\n        # load\n\"\"\"\n        logger.info(f'Loading bAnalysis from row {rowIdx} \"{filePath}\"')\n        ba = sanpy.bAnalysis(filePath)\n        \"\"\"\n        if ba is None:\n            logger.warning(\n                f'Did not load row {rowIdx} path: \"{filePath}\". Analysis was probably not saved'\n            )\n        else:\n            self._df.at[rowIdx, \"_ba\"] = ba\n            # does not get a uuid until save into h5\n            if uuid:\n                # there was an original uuid (in table), means we are saved into h5\n                self._df.at[rowIdx, \"uuid\"] = uuid\n                if uuid != ba.uuid:\n                    logger.error(\n                        \"Loaded uuid does not match existing in file table\"\n                    )\n                    logger.error(f\"  Loaded {ba.uuid}\")\n                    logger.error(f\"  Existing {uuid}\")\n\n            # kymograph, set ba rect from table\n            # if ba.isKymograph():\n            # if ba is not None and isinstance(ba, sanpy.fileloaders.fileLoader_tif):\n            if ba is not None and ba.fileLoader.isKymograph():\n                left = self._df.loc[rowIdx, \"kLeft\"]\n                top = self._df.loc[rowIdx, \"kTop\"]\n                right = self._df.loc[rowIdx, \"kRight\"]\n                bottom = self._df.loc[rowIdx, \"kBottom\"]\n\n                # on first load, these will be empty\n                # grab rect from ba (in _updateLoadedAnalyzed())\n                if left == \"\" or top == \"\" or right == \"\" or bottom == \"\":\n                    pass\n                else:\n                    theRect = [left, top, right, bottom]\n                    logger.info(f\"  theRect:{theRect}\")\n                    ba.fileLoader._updateTifRoi(theRect)\n\n            #\n            # update stats of table load/analyzed columns\n            self._updateLoadedAnalyzed()\n\n    return ba\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.getDataFrame","title":"<code>getDataFrame()</code>","text":"<p>Get the underlying pandas DataFrame.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def getDataFrame(self):\n\"\"\"Get the underlying pandas DataFrame.\"\"\"\n    return self._df\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.getFileList","title":"<code>getFileList(path=None)</code>","text":"<p>Get file paths from path.</p> <p>Uses self.theseFileTypes</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def getFileList(self, path: str = None) -&gt; List[str]:\n\"\"\"Get file paths from path.\n\n    Uses self.theseFileTypes\n    \"\"\"\n    if path is None:\n        path = self.path\n\n    logger.warning(\"Remember: MODIFIED TO LOAD TIF FILES IN SUBFOLDERS\")\n    count = 1\n    tmpFileList = []\n    folderDepth = self.folderDepth  # if none then all depths\n    excludeFolders = [\"analysis\", \"hide\"]\n    for root, subdirs, files in os.walk(path):\n        subdirs[:] = [d for d in subdirs if d not in excludeFolders]\n\n        # print('folderDepth:', folderDepth)\n        # print('  root:', root, 'subdirs:', subdirs, 'files:', files)\n\n        # strip out folders that start with __\n        # _parentFolder = os.path.split(root)[1]\n        # print('root:', root)\n        # print('  parentFolder:', _parentFolder)\n        # if _parentFolder.startswith('__'):\n        if \"__\" in root:\n            logger.info(f\"SKIPPING based on path root:{root}\")\n            continue\n\n        if os.path.split(root)[1] == \"analysis\":\n            # don't load from analysis/ folder, we save analysis there\n            continue\n\n        # if os.path.split(root)[1] == 'hide':\n        #     # special case/convention, don't load from 'hide' folders\n        #     continue\n\n        for file in files:\n            # TODO (cudmore) parse all our fileLoader(s) for a list\n            _, _ext = os.path.splitext(file)\n            if _ext in self.theseFileTypes:\n                oneFile = os.path.join(root, file)\n                tmpFileList.append(oneFile)\n\n        count += 1\n        if folderDepth is not None and count &gt; folderDepth:\n            break\n\n    fileList = []\n    for file in sorted(tmpFileList):\n        if file.startswith(\".\"):\n            continue\n        # ignore our database file\n        if file == self.dbFile:\n            continue\n\n        # tmpExt is like .abf, .csv, etc\n        tmpFileName, tmpExt = os.path.splitext(file)\n        if tmpExt in self.theseFileTypes:\n            # if getFullPath:\n            #     #file = os.path.join(path, file)\n            #     file = pathlib.Path(path) / file\n            #     file = str(file)  # return List[str] NOT List[PosixPath]\n            fileList.append(file)\n    #\n    logger.info(f\"found {len(fileList)} files ...\")\n    return fileList\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.getFileRow","title":"<code>getFileRow(path, loadData=False)</code>","text":"<p>Get dict representing one file (row in table). Loads bAnalysis to get headers.</p> <p>On load error of proper file type (abf, csv), ba.loadError==True</p> <p>Args:     path (Str): Full path to file.     #rowIdx (int): Optional row index to assign in column 'Idx'</p> <p>Return:     (tuple): tuple containing:</p> <pre><code>- ba (bAnalysis): [sanpy.bAnalysis](/api/bAnalysis).\n- rowDict (dict): On success, otherwise None.\n        fails when path does not lead to valid bAnalysis file.\n</code></pre> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def getFileRow(self, path, loadData=False):\n\"\"\"Get dict representing one file (row in table). Loads bAnalysis to get headers.\n\n    On load error of proper file type (abf, csv), ba.loadError==True\n\n    Args:\n        path (Str): Full path to file.\n        #rowIdx (int): Optional row index to assign in column 'Idx'\n\n    Return:\n        (tuple): tuple containing:\n\n        - ba (bAnalysis): [sanpy.bAnalysis](/api/bAnalysis).\n        - rowDict (dict): On success, otherwise None.\n                fails when path does not lead to valid bAnalysis file.\n    \"\"\"\n    if not os.path.isfile(path):\n        logger.warning(f'Did not find file \"{path}\"')\n        return None, None\n    fileType = os.path.splitext(path)[1]\n    if fileType not in self.theseFileTypes:\n        logger.warning(f'Did not load file type \"{fileType}\"')\n        return None, None\n\n    # grab the fileLoaderDict from our app\n    # if it is None then bAnalysis will load this (from disk)\n    if self.myApp is not None:\n        _fileLoaderDict = self.myApp.getFileLoaderDict()\n    else:\n        _fileLoaderDict = None\n\n    # load bAnalysis\n    # logger.info(f'Loading bAnalysis \"{path}\"')\n    # loadData is false, load header\n    ba = sanpy.bAnalysis(path, loadData=loadData, fileLoaderDict=_fileLoaderDict)\n\n    if ba.loadError:\n        logger.error(f'Error loading bAnalysis file \"{path}\"')\n        # return None, None\n\n    # not sufficient to default everything to empty str ''\n    # sanpyColumns can only have type in ('float', 'str')\n    rowDict = dict.fromkeys(self.sanpyColumns.keys(), \"\")\n    for k in rowDict.keys():\n        if self.sanpyColumns[k][\"type\"] == str:\n            rowDict[k] = \"\"\n        elif self.sanpyColumns[k][\"type\"] == float:\n            rowDict[k] = np.nan\n\n    # if rowIdx is not None:\n    #    rowDict['Idx'] = rowIdx\n\n\"\"\"\n    if ba.loadError:\n        rowDict['I'] = 0\n    else:\n        rowDict['I'] = 2 # need 2 because checkbox value is in (0,2)\n    \"\"\"\n\n    if ba.loadError:\n        return None, None\n\n    rowDict[\"File\"] = ba.fileLoader.filename  # os.path.split(ba.path)[1]\n    rowDict[\"Dur(s)\"] = ba.fileLoader.recordingDur\n\n    rowDict[\"Channels\"] = ba.fileLoader.numChannels  # Theanne\n\n    rowDict[\"Sweeps\"] = ba.fileLoader.numSweeps\n\n    # TODO: here, we do not get an epoch table until the file is loaded !!!\n    rowDict[\"Epochs\"] = ba.fileLoader.numEpochs  # Theanne, data has to be loaded\n\n    rowDict[\"kHz\"] = ba.fileLoader.recordingFrequency\n    rowDict[\"Mode\"] = ba.fileLoader.recordingMode.value\n\n    # rowDict['dvdtThreshold'] = 20\n    # rowDict['mvThreshold'] = -20\n    if ba.isAnalyzed():\n        dDict = ba.getDetectionDict()\n        # rowDict['I'] = dDict.getValue('include')\n        rowDict[\"dvdtThreshold\"] = dDict.getValue(\"dvdtThreshold\")\n        rowDict[\"mvThreshold\"] = dDict.getValue(\"mvThreshold\")\n        rowDict[\"Start(s)\"] = dDict.getValue(\"startSeconds\")\n        rowDict[\"Stop(s)\"] = dDict.getValue(\"stopSeconds\")\n\n    # remove the path to the folder we have loaded\n    relPath = path.replace(self.path, \"\")\n\n    # logger.info(f'xxx self.path: \"{self.path}\"')\n    # logger.info(f'xxx path: \"{path}\"')\n    # logger.info(f'xxx relPath: \"{relPath}\"')\n\n    if relPath.startswith(\"/\"):\n        # so we can use os.path.join()\n        relPath = relPath[1:]\n    # added 20230505 working with johnson in 1313 to fix windows bug ???\n    if relPath.startswith(\"\\\\\"):\n        # so we can use os.path.join()\n        relPath = relPath[1:]\n\n    rowDict[\"relPath\"] = relPath\n\n    #logger.info(f'2) xxx relPath: \"{relPath}\"')\n\n    return ba, rowDict\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.getPathFromRelPath","title":"<code>getPathFromRelPath(relPath)</code>","text":"<p>Get full path to file (usually an abf file.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def getPathFromRelPath(self, relPath):\n\"\"\"Get full path to file (usually an abf file.\"\"\"\n    if relPath.startswith(\"/\"):\n        relPath = relPath[1:]\n\n    fullFilePath = os.path.join(self.path, relPath)\n\n\"\"\"\n    print('xxx', self.path)\n    print('xxx', relPath)\n    print('xxx', fullFilePath)\n    \"\"\"\n\n    return fullFilePath\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.getRowDict","title":"<code>getRowDict(rowIdx)</code>","text":"<p>Return a dict with selected row as dict (includes detection parameters).</p> <p>Important to return a copy as our '_ba' is a pointer to bAnalysis.</p> <p>Returns:     theRet (dict): Be sure to make a deep copy of ['_ba'] if neccessary.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def getRowDict(self, rowIdx):\n\"\"\"\n    Return a dict with selected row as dict (includes detection parameters).\n\n    Important to return a copy as our '_ba' is a pointer to bAnalysis.\n\n    Returns:\n        theRet (dict): Be sure to make a deep copy of ['_ba'] if neccessary.\n    \"\"\"\n    theRet = {}\n    # use columns in main sanpyColumns, not in df\n    # for colStr in self.columns:\n    for colStr in self._df.columns:\n        # theRet[colStr] = self._df.loc[rowIdx, colStr]\n        theRet[colStr] = self._df.loc[rowIdx, colStr]\n    # theRet['_ba'] = theRet['_ba'].copy()\n    return theRet\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.hasDirty","title":"<code>hasDirty()</code>","text":"<p>Return true if any bAnalysis in list has been analyzed but not saved (e.g. is dirty)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def hasDirty(self):\n\"\"\"Return true if any bAnalysis in list has been analyzed but not saved (e.g. is dirty)\"\"\"\n    haveDirty = False\n    numRows = len(self._df)\n    for rowIdx in range(numRows):\n        if self.analysisIsDirty(rowIdx):\n            haveDirty = True\n\n    return haveDirty\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.loadFolder","title":"<code>loadFolder(path=None, loadData=False)</code>","text":"<p>Parse a folder and load all (abf, csv, ...). Only called if no h5 file.</p> <p>TODO: get rid of loading database from .csv (it is replaced by .h5 file) TODO: extend the logic to load from cloud (after we were instantiated)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def loadFolder(self, path=None, loadData=False):\n\"\"\"\n    Parse a folder and load all (abf, csv, ...). Only called if no h5 file.\n\n    TODO: get rid of loading database from .csv (it is replaced by .h5 file)\n    TODO: extend the logic to load from cloud (after we were instantiated)\n    \"\"\"\n    logger.info(\"Loading folder from scratch (no hdf file)\")\n\n    start = time.time()\n    if path is None:\n        path = self.path\n    self.path = path\n\n    loadedDatabase = False\n\n    # load an existing folder db or create a new one\n    # abb 20220612 turned off loading from self.dbFile .csv file\n    dbPath = os.path.join(path, self.dbFile)\n    if 0 and os.path.isfile(dbPath):\n        # load from .csv\n        logger.info(f\"Loading existing folder db: {dbPath}\")\n        df = pd.read_csv(dbPath, header=0, index_col=False)\n        # df[\"Idx\"] = pd.to_numeric(df[\"Idx\"])\n        df = self._setColumnType(df)\n        loadedDatabase = True\n        # logger.info(f'  shape is {df.shape}')\n    else:\n        # logger.info(f'No existing db file, making {dbPath}')\n        logger.info(f\"No existing db file, making default dataframe\")\n        df = pd.DataFrame(columns=self.sanpyColumns.keys())\n        df = self._setColumnType(df)\n\n    if loadedDatabase:\n        # check columns with sanpyColumns\n        loadedColumns = df.columns\n        for col in loadedColumns:\n            if not col in self.sanpyColumns.keys():\n                logger.error(\n                    f'error: bAnalysisDir did not find loaded col: \"{col}\" in sanpyColumns.keys()'\n                )\n        for col in self.sanpyColumns.keys():\n            if not col in loadedColumns:\n                logger.error(\n                    f'error: bAnalysisDir did not find sanpyColumns.keys() col: \"{col}\" in loadedColumns'\n                )\n\n    if loadedDatabase:\n        # seach existing db for missing abf files\n        pass\n    else:\n        # get list of all abf/csv/tif files\n        fileList = self.getFileList(path)\n        _numFilesToLoad = len(fileList)\n        start = time.time()\n        # build new db dataframe\n        listOfDict = []\n        for rowIdx, fullFilePath in enumerate(fileList):\n            self.signalApp(\n                f'Loading file {rowIdx+1} of {_numFilesToLoad} \"{fullFilePath}\"'\n            )\n\n            # rowDict is what we are showing in the file table\n            # abb debug vue, set loadData=True\n            # loads bAnalysis\n            ba, rowDict = self.getFileRow(fullFilePath, loadData=loadData)\n\n            if rowDict is None:\n                logger.warning(f'error loading file {fullFilePath}')\n                continue\n\n            # TODO: calculating time, remove this\n            # This is 2x faster than loading from pandas gzip ???\n            # dDict = sanpy.bAnalysis.getDefaultDetection()\n            # dDict['dvdtThreshold'] = 2\n            # ba.spikeDetect(dDict)\n\n            # as we parse the folder, don't load ALL files (will run out of memory)\n            if loadData:\n                rowDict[\"_ba\"] = ba\n            else:\n                rowDict[\"_ba\"] = None  # ba\n\n            # do not assign uuid until bAnalysis is saved in h5 file\n            # rowDict['uuid'] = ''\n\n            # 20230313 moved into getFileRow()\n            # relPath = fullFilePath.replace(path, '')\n            # if relPath.startswith('/'):\n            #     # so we can use os.path.join()\n            #     relPath = relPath[1:]\n            # rowDict['relPath'] = relPath\n\n            # logger.info(f'    row:{rowIdx} relPath:{relPath} fullFilePath:{fullFilePath}')\n\n            listOfDict.append(rowDict)\n\n        stop = time.time()\n        logger.info(f\"Load took {round(stop-start,3)} seconds.\")\n\n        #\n        df = pd.DataFrame(listOfDict)\n        # print('=== built new db df:')\n        # print(df)\n        df = self._setColumnType(df)\n    #\n\n    # expand each to into self.fileList\n    # df['_ba'] = None\n\n    stop = time.time()\n    logger.info(f\"Load took {round(stop-start,2)} seconds.\")\n    return df\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.loadHdf","title":"<code>loadHdf(path=None)</code>","text":"<p>Load the database key from an h5 file.</p> <p>We do not load analy anlysis until user clicks on row, see loadOneAnalysis()</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def loadHdf(self, path=None):\n\"\"\"\n    Load the database key from an h5 file.\n\n    We do not load analy anlysis until user clicks on row, see loadOneAnalysis()\n    \"\"\"\n    if path is None:\n        path = self.path\n    self.path = path\n\n    df = None\n    hdfFile = os.path.splitext(self.dbFile)[0] + \".h5\"\n    hdfPath = pathlib.Path(self.path) / hdfFile\n    if not hdfPath.is_file():\n        return\n\n    logger.info(f\"Loading existing folder h5 file {hdfPath}\")\n    sanpy.h5Util.listKeys(hdfPath)\n\n    _start = time.time()\n    dbKey = os.path.splitext(self.dbFile)[0]\n\n    try:\n        df = pd.read_hdf(hdfPath, dbKey)\n    except KeyError as e:\n        # file is corrupt !!!\n        logger.error(f'    Load h5 failed, did not find dbKey:\"{dbKey}\" {e}')\n\n    if df is not None:\n        # _ba is for runtime, assign after loading from either (abf or h5)\n        df[\"_ba\"] = None\n\n        logger.info(\"    loaded db df\")\n        logger.info(f\"{df[['File', 'uuid']]}\")\n\n        # do not load anything until user clicks rows, see loadOneAnalysis()\n\n        _stop = time.time()\n        logger.info(f\"Loading took {round(_stop-_start,2)} seconds\")\n    #\n    return df\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.loadOneAnalysis","title":"<code>loadOneAnalysis(path, uuid=None, allowAutoLoad=True, verbose=True)</code>","text":"<p>Load one bAnalysis either from original file path or uuid of h5 file.</p> <p>If from h5, we still need to reload sweeps !!! They are binary and fast, saving to h5 (in this case) is slow.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def loadOneAnalysis(self, path, uuid=None, allowAutoLoad=True, verbose=True):\n\"\"\"Load one bAnalysis either from original file path or uuid of h5 file.\n\n    If from h5, we still need to reload sweeps !!!\n    They are binary and fast, saving to h5 (in this case) is slow.\n    \"\"\"\n    if verbose:\n        logger.info(f'path:\"{path}\" uuid:\"{uuid}\" allowAutoLoad:\"{allowAutoLoad}\"')\n\n    hdfPath = self._getHdfFile()\n\n    # grab the fileLoaderDict from our app\n    # if it is None then bAnalysis will load this (from disk)\n    if self.myApp is not None:\n        _fileLoaderDict = self.myApp.getFileLoaderDict()\n    else:\n        _fileLoaderDict = None\n\n    ba = None\n    if uuid is not None and uuid:\n        # load from h5\n        if verbose:\n            logger.info(f\"    Retreiving uuid from hdf file {uuid}\")\n\n        # load from abf\n        ba = sanpy.bAnalysis(path, fileLoaderDict=_fileLoaderDict, verbose=verbose)\n\n        # load analysis from h5 file, will fail if uuid is not in file\n        ba._loadHdf_pytables(hdfPath, uuid)\n\n    if allowAutoLoad and ba is None:\n        # load from path\n        ba = sanpy.bAnalysis(path, fileLoaderDict=_fileLoaderDict, verbose=verbose)\n        if verbose:\n            logger.info(f\"    Loaded ba from path {path} and now ba:{ba}\")\n    #\n    return ba\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.old_duplicateRow","title":"<code>old_duplicateRow(rowIdx)</code>","text":"<p>Depreciated, Was used to have different ocnditions within a recording, this is now handled by condiiton column.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def old_duplicateRow(self, rowIdx):\n\"\"\"Depreciated, Was used to have different ocnditions within a recording,\n    this is now handled by condiiton column.\n    \"\"\"\n    # duplicate rowIdx\n    newIdx = rowIdx + 0.5\n\n    rowDict = self.getRowDict(rowIdx)\n\n    # CRITICAL: Need to make a deep copy of the _ba pointer to bAnalysis object\n    logger.info(f\"copying {type(rowDict['_ba'])} {rowDict['_ba']}\")\n    baNew = copy.deepcopy(rowDict[\"_ba\"])\n\n    # copy of bAnalysis needs a new uuid\n    new_uuid = (\n        sanpy._util.getNewUuid()\n    )  # 't' + str(uuid.uuid4())   #.replace('-', '_')\n    logger.info(f\"assigning new uuid {new_uuid} to {baNew}\")\n\n    if baNew.uuid == new_uuid:\n        logger.error(\"!!!!!!!!!!!!!!!!!!!!!!!!!CRITICAL, new uuid is same as old\")\n\n    baNew.uuid = new_uuid\n\n    rowDict[\"_ba\"] = baNew\n    rowDict[\"uuid\"] = baNew.uuid  # new row can never have same uuid as old\n\n    dfRow = pd.DataFrame(rowDict, index=[newIdx])\n\n    df = self._df\n    df = df.append(dfRow, ignore_index=True)\n    df = df.sort_values(by=[\"File\"], axis=\"index\", ascending=True, inplace=False)\n    df = df.reset_index(drop=True)\n    self._df = df\n\n    self._updateLoadedAnalyzed()\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.old_getTmpHdfFile","title":"<code>old_getTmpHdfFile()</code>","text":"<p>Get temporary h5 file to write to.</p> <p>We will always then compress with _rebuildHdf.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def old_getTmpHdfFile(self):\n\"\"\"Get temporary h5 file to write to.\n\n    We will always then compress with _rebuildHdf.\n    \"\"\"\n    logger.info(\"\")\n\n    tmpHdfFile = os.path.splitext(self.dbFile)[0] + \"_tmp.h5\"\n    tmpHdfPath = pathlib.Path(self.path) / tmpHdfFile\n\n    # the compressed version from the last save\n    hdfFile = os.path.splitext(self.dbFile)[0] + \".h5\"\n    hdfFilePath = pathlib.Path(self.path) / hdfFile\n\n    # hdfMode = 'w'\n    if os.path.isfile(hdfFilePath):\n        logger.info(f\"    copying existing hdf file to tmp \")\n        logger.info(f\"    hdfFilePath {hdfFilePath}\")\n        logger.info(f\"    tmpHdfPath {tmpHdfPath}\")\n        shutil.copyfile(hdfFilePath, tmpHdfPath)  # noqa\n    else:\n        pass\n        # compressed file does not exist, just use tmp path\n        # print('   does not exist:', hdfFilePath)\n\n    return tmpHdfPath\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.old_saveDatabase","title":"<code>old_saveDatabase()</code>","text":"<p>save dbFile .csv and hdf .gzip</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def old_saveDatabase(self):\n\"\"\"save dbFile .csv and hdf .gzip\"\"\"\n    dbPath = os.path.join(self.path, self.dbFile)\n    if self.getDataFrame() is not None:\n        #\n        logger.info(f'Saving \"{dbPath}\"')\n        self.getDataFrame().to_csv(dbPath, index=False)\n        self._isDirty = False\n\n        #\n\"\"\"\n        hdfFile = os.path.splitext(self.dbFile)[0] + '.h5'\n        hdfPath = os.path.join(self.path, hdfFile)\n        logger.info(f'Saving \"{hdfPath}\"')\n        #hdfStore = pd.HDFStore(hdfPath)\n        start = time.time()\n        complevel = 9\n        complib = 'blosc:blosclz'\n        with pd.HDFStore(hdfPath, mode='w', complevel=complevel, complib=complib) as hdfStore:\n            hdfStore['df'] = self.getDataFrame()  # save it\n        stop = time.time()\n        logger.info(f'Saving took {round(stop-start,2)} seconds')\n        \"\"\"\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.pool_build","title":"<code>pool_build()</code>","text":"<p>Build one df with all analysis. Use this in plot tool plugin.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def pool_build(self):\n\"\"\"Build one df with all analysis. Use this in plot tool plugin.\"\"\"\n    logger.info(\"\")\n    masterDf = None\n    for row in range(self.numFiles):\n        if not self.isAnalyzed(row):\n            logger.info(f\"  row:{row} not analyzed\")\n            continue\n        ba = self.getAnalysis(row)\n        oneDf = ba.asDataFrame()\n        if oneDf is not None:\n            self.signalApp(f'  adding \"{ba.fileLoader.filename}\"')\n            oneDf[\"File Number\"] = int(row)\n            if masterDf is None:\n                masterDf = oneDf\n            else:\n                masterDf = pd.concat([masterDf, oneDf])\n    #\n    if masterDf is None:\n        logger.error(\"Did not find any analysis.\")\n    else:\n        logger.info(f\"final num spikes {len(masterDf)}\")\n    # print(masterDf.head())\n    self._poolDf = masterDf\n\n    return self._poolDf\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.saveHdf","title":"<code>saveHdf()</code>","text":"<p>Save file table and any number of loaded and analyzed bAnalysis.</p> <p>Set file table 'uuid' column when we actually save a bAnalysis</p> <p>Important: Order matters         (1) Save bAnalysis first, it updates uuid in file table.         (2) Save file table with updated uuid</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def saveHdf(self):\n\"\"\"\n    Save file table and any number of loaded and analyzed bAnalysis.\n\n    Set file table 'uuid' column when we actually save a bAnalysis\n\n    Important: Order matters\n            (1) Save bAnalysis first, it updates uuid in file table.\n            (2) Save file table with updated uuid\n    \"\"\"\n    start = time.time()\n\n    df = self.getDataFrame()\n\n    # the compressed version from the last save\n    hdfFile = os.path.splitext(self.dbFile)[0] + \".h5\"\n    hdfFilePath = pathlib.Path(self.path) / hdfFile\n\n    logger.info(f\"Saving db (will be compressed) {hdfFilePath}\")\n\n    # save each bAnalysis\n    for row in range(len(df)):\n        ba = df.at[row, \"_ba\"]\n        if ba is not None:\n            didSave = ba._saveHdf_pytables(hdfFilePath)\n            if didSave:\n                # we are now saved into h5 file, remember uuid to load\n                # print('xxx SETTING dir uuid')\n                df.at[row, \"uuid\"] = ba.uuid\n\n    # rebuild (L, A, S) columns\n    self._updateLoadedAnalyzed()\n\n    #\n    # save file database\n    logger.info(f\"    saving file db with {len(df)} rows\")\n    print(df)\n\n    dbKey = os.path.splitext(self.dbFile)[0]\n    df = df.drop(\"_ba\", axis=1)  # don't ever save _ba, use it for runtime\n\n    # hdfStore[dbKey] = df  # save it\n    df.to_hdf(hdfFilePath, dbKey)\n\n    #\n    self._isDirty = False  # if true, prompt to save on quit\n\n    # rebuild the file to remove old changes and reduce size\n    # self._rebuildHdf()\n    sanpy.h5Util._repackHdf(hdfFilePath)\n\n    # list the keys in the file\n    sanpy.h5Util.listKeys(hdfFilePath)\n\n    stop = time.time()\n    logger.info(f\"Saving took {round(stop-start,2)} seconds\")\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.signalApp","title":"<code>signalApp(str)</code>","text":"<p>Update status bar of SanPy app.</p> <p>TODO make this a signal and connect app to it.     Will not be able to do this, we need to run outside Qt</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def signalApp(self, str):\n\"\"\"Update status bar of SanPy app.\n\n    TODO make this a signal and connect app to it.\n        Will not be able to do this, we need to run outside Qt\n    \"\"\"\n    if self.myApp is not None:\n        self.myApp.slot_updateStatus(str)\n    else:\n        logger.info(str)\n</code></pre>"},{"location":"api/analysisDir/#sanpy.analysisDir.analysisDir.syncDfWithPath","title":"<code>syncDfWithPath()</code>","text":"<p>Sync path with existing df. Used to detect new/removed files.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisDir.py</code> <pre><code>def syncDfWithPath(self):\n\"\"\"Sync path with existing df. Used to detect new/removed files.\"\"\"\n\n    pathFileList = self.getFileList()  # always full path\n    dfFileList = self._df[\"File\"].tolist()\n\n    logger.info(\"\")\n    # print('    === pathFileList (on drive):')\n    # print('    ', pathFileList)\n    # print('    === dfFileList (in table):')\n    # print('    ', dfFileList)\n\n    addedToDf = False\n\n    # look for files in path not in df\n    for pathFile in pathFileList:\n        fileName = os.path.split(pathFile)[1]\n        if fileName not in dfFileList:\n            logger.info(f'Found file in path \"{fileName}\" not in df')\n            # load bAnalysis and get df column values\n            addedToDf = True\n            # fullPathFile = os.path.join(self.path, pathFile)\n            ba, rowDict = self.getFileRow(pathFile)  # loads bAnalysis\n            if rowDict is not None:\n                # listOfDict.append(rowDict)\n\n                # TODO: get this into getFileROw()\n                logger.warning(\"20220718, not sure we need this ???\")\n                # rowDict['relPath'] = pathFile\n                rowDict[\"_ba\"] = None\n\n                self.appendRow(rowDict=rowDict, ba=None)\n\n    # look for files in df not in path\n    # for dfFile in dfFileList:\n    #     if not dfFile in pathFileList:\n    #         logger.info(f'Found file in df \"{dfFile}\" not in path')\n\n    if addedToDf:\n        df = self._df\n        df = df.sort_values(\n            by=[\"File\"], axis=\"index\", ascending=True, inplace=False\n        )\n        df = df.reset_index(drop=True)\n        self._df = df\n\n    self._updateLoadedAnalyzed()\n</code></pre>"},{"location":"api/analysisPlot/","title":"analysisPlot","text":"<p>Class to plot results of sanpy.bAnalysis spike detection.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisPlot.py</code> <pre><code>class bAnalysisPlot:\n\"\"\"\n    Class to plot results of [sanpy.bAnalysis][sanpy.bAnalysis] spike detection.\n\n    \"\"\"\n\n    def __init__(self, ba=None):\n\"\"\"\n        Args:\n            ba: [sanpy.bAnalysis][sanpy.bAnalysis] object\n        \"\"\"\n        self._ba = ba\n\n    @property\n    def ba(self):\n\"\"\"Get underlying bAnalysis object.\"\"\"\n        return self._ba\n\n    def getDefaultPlotStyle(self):\n\"\"\"Get dictionary with default plot style.\"\"\"\n        d = {\n            \"linewidth\": 1,\n            \"color\": \"k\",\n            \"width\": 9,\n            \"height\": 3,\n        }\n        return d.copy()\n\n    def _makeFig(self, plotStyle=None):\n        if plotStyle is None:\n            plotStyle = self.getDefaultPlotStyle()\n\n        grid = plt.GridSpec(1, 1, wspace=0.2, hspace=0.4)\n\n        width = plotStyle[\"width\"]\n        height = plotStyle[\"height\"]\n        fig = plt.figure(figsize=(width, height))\n        ax = fig.add_subplot(grid[0, 0:])  # Vm, entire sweep\n\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"top\"].set_visible(False)\n\n        return fig, ax\n\n    def plotRaw(self, plotStyle=None, ax=None):\n\"\"\"\n        Plot raw recording\n\n        Args:\n            plotStye (float):\n            ax (xxx):\n        \"\"\"\n\n        if plotStyle is None:\n            plotStyle = self.getDefaultPlotStyle()\n\n        if ax is None:\n            _fig, _ax = self._makeFig()\n            _fig.suptitle(f\"{self._ba.fileLoader.filepath}\")\n        else:\n            _ax = ax\n\n        color = plotStyle[\"color\"]\n        linewidth = plotStyle[\"linewidth\"]\n        sweepX = self.ba.fileLoader.sweepX\n        sweepY = self.ba.fileLoader.sweepY\n\n        _ax.plot(\n            sweepX, sweepY, \"-\", c=color, linewidth=linewidth\n        )  # fmt = '[marker][line][color]'\n\n        xUnits = self.ba.fileLoader.get_xUnits()\n        yUnits = self.ba.fileLoader.get_yUnits()\n        _ax.set_xlabel(xUnits)\n        _ax.set_ylabel(yUnits)\n\n        return _ax\n\n    def plotDerivAndRaw(self):\n\"\"\"\n        Plot both Vm and the derivative of Vm (dV/dt).\n\n        Args:\n            fig (matplotlib.pyplot.figure): An existing figure to plot to.\n                see: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html\n\n        Return:\n            fig and axs\n        \"\"\"\n\n        #\n        # make a 2-panel figure\n        grid = plt.GridSpec(2, 1, wspace=0.2, hspace=0.4)\n        fig = plt.figure(figsize=(10, 8))\n        ax1 = fig.add_subplot(grid[0, 0])\n        ax2 = fig.add_subplot(grid[1, 0], sharex=ax1)\n        ax1.spines[\"right\"].set_visible(False)\n        ax1.spines[\"top\"].set_visible(False)\n        ax2.spines[\"right\"].set_visible(False)\n        ax2.spines[\"top\"].set_visible(False)\n\n        self.plotRaw(ax=ax1)\n\n        sweepX = self.ba.fileLoader.sweepX\n        filteredDeriv = self.ba.fileLoader.filteredDeriv\n        ax2.plot(sweepX, filteredDeriv)\n\n        ax2.set_ylabel(\"dV/dt\")\n        # ax2.set_xlabel('Seconds')\n\n        return fig, [ax1, ax2]\n\n    def plotSpikes(\n        self,\n        plotThreshold=False,\n        plotPeak=False,\n        plotStyle=None,\n        hue: Optional[str] = \"condition\",\n        markerSize: Optional[int] = 4,\n        ax=None,\n    ):\n\"\"\"Plot Vm with spike analysis overlaid as symbols\n\n        Args:\n            plotThreshold\n            plotPeak\n            plotStyle (dict): xxx\n            markerSize\n            ax (xxx): If specified will plot into a MatPlotLib axes\n\n        Returns\n            fig\n            ax\n        \"\"\"\n\n        legend = False\n\n        if plotStyle is None:\n            plotStyle = self.getDefaultPlotStyle()\n\n        if ax is None:\n            fig, ax = self._makeFig()\n            fig.suptitle(self.ba.getFileName())\n        # plot vm\n        self.plotRaw(ax=ax)\n\n        # plot spike times\n        if plotThreshold:\n            thresholdSec = self.ba.getStat(\"thresholdSec\")  # x\n            thresholdVal = self.ba.getStat(\"thresholdVal\")  # y\n\n            ax.plot(thresholdSec, thresholdVal, \"pr\", markersize=markerSize)\n            df = self.ba.spikeDict.asDataFrame()  # regenerates, can be expensive\n            # logger.info(f'df hue unique is: {df[hue].unique()}')\n            # sns.scatterplot(x='thresholdSec', y='thresholdVal', hue=hue, data=df, ax=ax, legend=legend)\n\n        # plot the peak\n        if plotPeak:\n            peakPnt = self.ba.getStat(\"peakPnt\")\n            # don't use this for Ca++ concentration\n            # peakVal = self.ba.getStat('peakVal')\n            peakVal = self.ba.fileLoader.sweepY[peakPnt]\n            peakSec = [self.ba.fileLoader.pnt2Sec_(x) for x in peakPnt]\n            ax.plot(peakSec, peakVal, \"oc\", markersize=markerSize)\n\n        xUnits = self.ba.fileLoader.get_xUnits()\n        yUnits = self.ba.fileLoader.get_yUnits()\n        ax.set_xlabel(xUnits)\n        ax.set_ylabel(yUnits)\n\n        return ax\n\n    def plotStat(self, xStat: str, yStat: str, hue: Optional[str] = None, ax=None):\n        # ax : Optional[\"matplotlib.axes._subplots.AxesSubplot\"] = None):\n\n        legend = False\n\n        if ax is None:\n            fig, ax = self._makeFig()\n            fig.suptitle(self.ba.getFileName())\n        print(type(ax))\n\n        df = self.ba.spikeDict.asDataFrame()  # regenerates, can be expensive\n        sns.scatterplot(x=xStat, y=yStat, hue=hue, data=df, ax=ax, legend=legend)\n\n    def plotTimeSeries(ba, stat, halfWidthIdx=0, ax=None):\n\"\"\"Plot a given spike parameter.\"\"\"\n        if stat == \"peak\":\n            yStatName = \"peakVal\"\n            yStatLabel = \"Spike Peak (mV)\"\n        if stat == \"preMin\":\n            yStatName = \"preMinVal\"\n            yStatLabel = \"Pre Min (mV)\"\n        if stat == \"halfWidth\":\n            yStatName = \"widthPnts\"\n            yStatLabel = \"Spike Half Width (ms)\"\n\n        #\n        # pull\n        statX = []\n        statVal = []\n        for i, spike in enumerate(ba.spikeDict):\n            if i == 0 or i == len(ba.spikeTimes) - 1:\n                continue\n            else:\n                statX.append(spike[\"peakSec\"])\n                if stat == \"halfWidth\":\n                    statVal.append(spike[\"widths\"][halfWidthIdx][\"widthMs\"])\n                else:\n                    statVal.append(spike[yStatName])\n\n        #\n        # plot\n        if ax is None:\n            grid = plt.GridSpec(1, 1, wspace=0.2, hspace=0.4)\n\n            fig = plt.figure(figsize=(10, 8))\n            ax = fig.add_subplot(grid[0, 0:])  # Vm, entire sweep\n\n        ax.plot(statX, statVal, \"o-k\")\n\n        ax.set_ylabel(yStatLabel)\n        ax.set_xlabel(\"Time (sec)\")\n\n        return statVal\n\n    def plotISI(ba, ax=None):\n\"\"\"Plot the inter-spike-interval (sec) between each spike threshold\"\"\"\n        #\n        # pull\n        spikeTimes_sec = [x / ba.dataPointsPerMs / 1000 for x in ba.spikeTimes]\n        isi = np.diff(spikeTimes_sec)\n        isi_x = spikeTimes_sec[0:-1]\n\n        #\n        # plot\n        if ax is None:\n            grid = plt.GridSpec(1, 1, wspace=0.2, hspace=0.4)\n\n            fig = plt.figure(figsize=(10, 8))\n            ax = fig.add_subplot(grid[0, 0:])  # Vm, entire sweep\n\n        ax.plot(isi_x, isi, \"o-k\")\n\n        ax.set_ylabel(\"Inter-Spike-Interval (sec)\")\n        ax.set_xlabel(\"Time (sec)\")\n\n    def plotClips(\n        self, plotType=\"Raw\", preClipWidth_ms=None, postClipWidth_ms=None, ax=None\n    ):\n\"\"\"Plot clips of all detected spikes\n\n        Clips are created in self.spikeDetect() and default to clipWidth_ms = 100 ms\n\n        Args:\n            plotType (str): From [Raw, RawPlusMean, Mean, SD, Var]\n            #plotVariance (bool): If tru, plot variance. Otherwise plot all raw clips (black) with mean (red)\n\n        Returns:\n            xPlot\n            yPlot\n        \"\"\"\n\n\"\"\"\n        if ax is None:\n            grid = plt.GridSpec(1, 1, wspace=0.2, hspace=0.4)\n\n            fig = plt.figure(figsize=(10, 8))\n            ax = fig.add_subplot(grid[0, 0:]) #Vm, entire sweep\n        \"\"\"\n\n        if self.ba.numSpikes == 0:\n            return None, None\n\n        if ax is None:\n            fig, ax = self._makeFig()\n            fig.suptitle(self.ba.getFileName())\n\n        startSec, stopSec = None, None\n        selectedSpikeList = []\n        # preClipWidth_ms = 200\n        # postClipWidth_ms = 1000\n\n        # Leave this none, if we pass none, ba.getSpikeClipsWill take care of this\n\"\"\"\n        if preClipWidth_ms is None:\n            preClipWidth_ms = self.ba.detectionClass['preSpikeClipWidth_ms']\n        if postClipWidth_ms is None:\n            postClipWidth_ms = self.ba.detectionClass['postSpikeClipWidth_ms']\n        \"\"\"\n        sweepNumber = 0\n        theseClips, theseClips_x, meanClip = self.ba.getSpikeClips(\n            startSec,\n            stopSec,\n            spikeSelection=selectedSpikeList,\n            preSpikeClipWidth_ms=preClipWidth_ms,\n            postSpikeClipWidth_ms=postClipWidth_ms,\n            sweepNumber=sweepNumber,\n        )\n        numClips = len(theseClips)\n\n        # convert clips to 2d ndarray ???\n        xTmp = np.array(theseClips_x)\n        # xTmp /= self.ba.dataPointsPerMs * 1000  # pnt to seconds\n        xTmp /= 1000  # ms to seconds\n        yTmp = np.array(theseClips)  # mV\n\n        # TODO: plot each clip as different color\n        # this will show variation in sequential clips (for Ca++ imaging they are decreasing)\n        # print(xTmp.shape)  # ( e.g. (9,306)\n        # sys.exit(1)\n\n        # plot variance\n        if plotType == \"Mean\":\n            xPlot = np.nanmean(xTmp, axis=0)  # xTmp is in ms\n            yPlot = np.nanmean(yTmp, axis=0)\n            ax.plot(xPlot, yPlot, \"-k\", linewidth=1)\n            ax.set_ylabel(\"Mean\")\n            ax.set_xlabel(\"Time (sec)\")\n        elif plotType == \"Var\":\n            xPlot = np.nanmean(xTmp, axis=0)  # xTmp is in ms\n            yPlot = np.nanvar(yTmp, axis=0)\n            ax.plot(xPlot, yPlot, \"-k\", linewidth=1)\n            ax.set_ylabel(\"Variance\")\n            ax.set_xlabel(\"Time (sec)\")\n        elif plotType == \"SD\":\n            xPlot = np.nanmean(xTmp, axis=0)  # xTmp is in ms\n            yPlot = np.nanstd(yTmp, axis=0)\n            ax.plot(xPlot, yPlot, \"-k\", linewidth=1)\n            ax.set_ylabel(\"STD\")\n            ax.set_xlabel(\"Time (sec)\")\n        elif plotType in [\"Raw\", \"RawPlusMean\"]:\n            # plot raw\n            # logger.info('PLOTTING RAW')\n\n            cmap = plt.get_cmap(\"jet\")\n            colors = [cmap(i) for i in np.linspace(0, 1, numClips)]\n\n            for i in range(numClips):\n                color = colors[i]\n                xPlot = xTmp[i, :]\n                yPlot = yTmp[i, :]\n                # I want different colors here\n                # ax.plot(xPlot, yPlot, '-k', linewidth=0.5)\n                # WHY IS THIS NOT WORKING !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n                # logger.info(f'!!!!!!!!!!!!!!!!!!!!!! plotting color g {plotType} {color}')\n                # ax.plot(xPlot, yPlot, '-g', linewidth=0.5, color='g')\n                ax.plot(xPlot, yPlot, \"-\", label=f\"{i}\", color=color, linewidth=0.5)\n\n            yLabel = self.ba._sweepLabelY\n            ax.set_ylabel(yLabel)\n            ax.set_xlabel(\"Time (sec)\")\n\n            # plot mean\n            if plotType == \"RawPlusMean\":\n                xMeanClip = np.nanmean(xTmp, axis=0)  # xTmp is in ms\n                yMeanClip = np.nanmean(yTmp, axis=0)\n                ax.plot(xMeanClip, yMeanClip, \"-r\", linewidth=1)\n\n            # show legend for each raw race 0,1,2,3,...\n            ax.legend(loc=\"best\")\n\n        else:\n            logger.error(f\"Did not understand plot type: {plotType}\")\n\n        #\n        return xPlot, yPlot\n\n    def plotPhasePlot(self, oneSpikeNumber=None, ax=None):\n        if ax is None:\n            grid = plt.GridSpec(1, 1, wspace=0.2, hspace=0.4)\n\n            fig = plt.figure(figsize=(10, 8))\n            ax = fig.add_subplot(grid[0, 0:])  # Vm, entire sweep\n\n        filteredClip = scipy.signal.medfilt(self.spikeClips[oneSpikeNumber], 3)\n        dvdt = np.diff(filteredClip)\n        # add an initial point so it is the same length as raw data in abf.sweepY\n        dvdt = np.concatenate(([0], dvdt))\n        (line,) = ax.plot(filteredClip, dvdt, \"y\")\n\n        ax.set_ylabel(\"filtered dV/dt\")\n        ax.set_xlabel(\"filtered Vm (mV)\")\n\n        return line\n</code></pre>"},{"location":"api/analysisPlot/#sanpy.bAnalysisPlot-attributes","title":"Attributes","text":""},{"location":"api/analysisPlot/#sanpy.analysisPlot.bAnalysisPlot.ba","title":"<code>ba</code>  <code>property</code>","text":"<p>Get underlying bAnalysis object.</p>"},{"location":"api/analysisPlot/#sanpy.bAnalysisPlot-functions","title":"Functions","text":""},{"location":"api/analysisPlot/#sanpy.analysisPlot.bAnalysisPlot.__init__","title":"<code>__init__(ba=None)</code>","text":"<p>Args:     ba: sanpy.bAnalysis object</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisPlot.py</code> <pre><code>def __init__(self, ba=None):\n\"\"\"\n    Args:\n        ba: [sanpy.bAnalysis][sanpy.bAnalysis] object\n    \"\"\"\n    self._ba = ba\n</code></pre>"},{"location":"api/analysisPlot/#sanpy.analysisPlot.bAnalysisPlot.getDefaultPlotStyle","title":"<code>getDefaultPlotStyle()</code>","text":"<p>Get dictionary with default plot style.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisPlot.py</code> <pre><code>def getDefaultPlotStyle(self):\n\"\"\"Get dictionary with default plot style.\"\"\"\n    d = {\n        \"linewidth\": 1,\n        \"color\": \"k\",\n        \"width\": 9,\n        \"height\": 3,\n    }\n    return d.copy()\n</code></pre>"},{"location":"api/analysisPlot/#sanpy.analysisPlot.bAnalysisPlot.plotClips","title":"<code>plotClips(plotType='Raw', preClipWidth_ms=None, postClipWidth_ms=None, ax=None)</code>","text":"<p>Plot clips of all detected spikes</p> <p>Clips are created in self.spikeDetect() and default to clipWidth_ms = 100 ms</p> <p>Args:     plotType (str): From [Raw, RawPlusMean, Mean, SD, Var]     #plotVariance (bool): If tru, plot variance. Otherwise plot all raw clips (black) with mean (red)</p> <p>Returns:     xPlot     yPlot</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisPlot.py</code> <pre><code>def plotClips(\n    self, plotType=\"Raw\", preClipWidth_ms=None, postClipWidth_ms=None, ax=None\n):\n\"\"\"Plot clips of all detected spikes\n\n    Clips are created in self.spikeDetect() and default to clipWidth_ms = 100 ms\n\n    Args:\n        plotType (str): From [Raw, RawPlusMean, Mean, SD, Var]\n        #plotVariance (bool): If tru, plot variance. Otherwise plot all raw clips (black) with mean (red)\n\n    Returns:\n        xPlot\n        yPlot\n    \"\"\"\n\n\"\"\"\n    if ax is None:\n        grid = plt.GridSpec(1, 1, wspace=0.2, hspace=0.4)\n\n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(grid[0, 0:]) #Vm, entire sweep\n    \"\"\"\n\n    if self.ba.numSpikes == 0:\n        return None, None\n\n    if ax is None:\n        fig, ax = self._makeFig()\n        fig.suptitle(self.ba.getFileName())\n\n    startSec, stopSec = None, None\n    selectedSpikeList = []\n    # preClipWidth_ms = 200\n    # postClipWidth_ms = 1000\n\n    # Leave this none, if we pass none, ba.getSpikeClipsWill take care of this\n\"\"\"\n    if preClipWidth_ms is None:\n        preClipWidth_ms = self.ba.detectionClass['preSpikeClipWidth_ms']\n    if postClipWidth_ms is None:\n        postClipWidth_ms = self.ba.detectionClass['postSpikeClipWidth_ms']\n    \"\"\"\n    sweepNumber = 0\n    theseClips, theseClips_x, meanClip = self.ba.getSpikeClips(\n        startSec,\n        stopSec,\n        spikeSelection=selectedSpikeList,\n        preSpikeClipWidth_ms=preClipWidth_ms,\n        postSpikeClipWidth_ms=postClipWidth_ms,\n        sweepNumber=sweepNumber,\n    )\n    numClips = len(theseClips)\n\n    # convert clips to 2d ndarray ???\n    xTmp = np.array(theseClips_x)\n    # xTmp /= self.ba.dataPointsPerMs * 1000  # pnt to seconds\n    xTmp /= 1000  # ms to seconds\n    yTmp = np.array(theseClips)  # mV\n\n    # TODO: plot each clip as different color\n    # this will show variation in sequential clips (for Ca++ imaging they are decreasing)\n    # print(xTmp.shape)  # ( e.g. (9,306)\n    # sys.exit(1)\n\n    # plot variance\n    if plotType == \"Mean\":\n        xPlot = np.nanmean(xTmp, axis=0)  # xTmp is in ms\n        yPlot = np.nanmean(yTmp, axis=0)\n        ax.plot(xPlot, yPlot, \"-k\", linewidth=1)\n        ax.set_ylabel(\"Mean\")\n        ax.set_xlabel(\"Time (sec)\")\n    elif plotType == \"Var\":\n        xPlot = np.nanmean(xTmp, axis=0)  # xTmp is in ms\n        yPlot = np.nanvar(yTmp, axis=0)\n        ax.plot(xPlot, yPlot, \"-k\", linewidth=1)\n        ax.set_ylabel(\"Variance\")\n        ax.set_xlabel(\"Time (sec)\")\n    elif plotType == \"SD\":\n        xPlot = np.nanmean(xTmp, axis=0)  # xTmp is in ms\n        yPlot = np.nanstd(yTmp, axis=0)\n        ax.plot(xPlot, yPlot, \"-k\", linewidth=1)\n        ax.set_ylabel(\"STD\")\n        ax.set_xlabel(\"Time (sec)\")\n    elif plotType in [\"Raw\", \"RawPlusMean\"]:\n        # plot raw\n        # logger.info('PLOTTING RAW')\n\n        cmap = plt.get_cmap(\"jet\")\n        colors = [cmap(i) for i in np.linspace(0, 1, numClips)]\n\n        for i in range(numClips):\n            color = colors[i]\n            xPlot = xTmp[i, :]\n            yPlot = yTmp[i, :]\n            # I want different colors here\n            # ax.plot(xPlot, yPlot, '-k', linewidth=0.5)\n            # WHY IS THIS NOT WORKING !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n            # logger.info(f'!!!!!!!!!!!!!!!!!!!!!! plotting color g {plotType} {color}')\n            # ax.plot(xPlot, yPlot, '-g', linewidth=0.5, color='g')\n            ax.plot(xPlot, yPlot, \"-\", label=f\"{i}\", color=color, linewidth=0.5)\n\n        yLabel = self.ba._sweepLabelY\n        ax.set_ylabel(yLabel)\n        ax.set_xlabel(\"Time (sec)\")\n\n        # plot mean\n        if plotType == \"RawPlusMean\":\n            xMeanClip = np.nanmean(xTmp, axis=0)  # xTmp is in ms\n            yMeanClip = np.nanmean(yTmp, axis=0)\n            ax.plot(xMeanClip, yMeanClip, \"-r\", linewidth=1)\n\n        # show legend for each raw race 0,1,2,3,...\n        ax.legend(loc=\"best\")\n\n    else:\n        logger.error(f\"Did not understand plot type: {plotType}\")\n\n    #\n    return xPlot, yPlot\n</code></pre>"},{"location":"api/analysisPlot/#sanpy.analysisPlot.bAnalysisPlot.plotDerivAndRaw","title":"<code>plotDerivAndRaw()</code>","text":"<p>Plot both Vm and the derivative of Vm (dV/dt).</p> <p>Args:     fig (matplotlib.pyplot.figure): An existing figure to plot to.         see: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html</p> <p>Return:     fig and axs</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisPlot.py</code> <pre><code>def plotDerivAndRaw(self):\n\"\"\"\n    Plot both Vm and the derivative of Vm (dV/dt).\n\n    Args:\n        fig (matplotlib.pyplot.figure): An existing figure to plot to.\n            see: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html\n\n    Return:\n        fig and axs\n    \"\"\"\n\n    #\n    # make a 2-panel figure\n    grid = plt.GridSpec(2, 1, wspace=0.2, hspace=0.4)\n    fig = plt.figure(figsize=(10, 8))\n    ax1 = fig.add_subplot(grid[0, 0])\n    ax2 = fig.add_subplot(grid[1, 0], sharex=ax1)\n    ax1.spines[\"right\"].set_visible(False)\n    ax1.spines[\"top\"].set_visible(False)\n    ax2.spines[\"right\"].set_visible(False)\n    ax2.spines[\"top\"].set_visible(False)\n\n    self.plotRaw(ax=ax1)\n\n    sweepX = self.ba.fileLoader.sweepX\n    filteredDeriv = self.ba.fileLoader.filteredDeriv\n    ax2.plot(sweepX, filteredDeriv)\n\n    ax2.set_ylabel(\"dV/dt\")\n    # ax2.set_xlabel('Seconds')\n\n    return fig, [ax1, ax2]\n</code></pre>"},{"location":"api/analysisPlot/#sanpy.analysisPlot.bAnalysisPlot.plotISI","title":"<code>plotISI(ba, ax=None)</code>","text":"<p>Plot the inter-spike-interval (sec) between each spike threshold</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisPlot.py</code> <pre><code>def plotISI(ba, ax=None):\n\"\"\"Plot the inter-spike-interval (sec) between each spike threshold\"\"\"\n    #\n    # pull\n    spikeTimes_sec = [x / ba.dataPointsPerMs / 1000 for x in ba.spikeTimes]\n    isi = np.diff(spikeTimes_sec)\n    isi_x = spikeTimes_sec[0:-1]\n\n    #\n    # plot\n    if ax is None:\n        grid = plt.GridSpec(1, 1, wspace=0.2, hspace=0.4)\n\n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(grid[0, 0:])  # Vm, entire sweep\n\n    ax.plot(isi_x, isi, \"o-k\")\n\n    ax.set_ylabel(\"Inter-Spike-Interval (sec)\")\n    ax.set_xlabel(\"Time (sec)\")\n</code></pre>"},{"location":"api/analysisPlot/#sanpy.analysisPlot.bAnalysisPlot.plotRaw","title":"<code>plotRaw(plotStyle=None, ax=None)</code>","text":"<p>Plot raw recording</p> <p>Args:     plotStye (float):     ax (xxx):</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisPlot.py</code> <pre><code>def plotRaw(self, plotStyle=None, ax=None):\n\"\"\"\n    Plot raw recording\n\n    Args:\n        plotStye (float):\n        ax (xxx):\n    \"\"\"\n\n    if plotStyle is None:\n        plotStyle = self.getDefaultPlotStyle()\n\n    if ax is None:\n        _fig, _ax = self._makeFig()\n        _fig.suptitle(f\"{self._ba.fileLoader.filepath}\")\n    else:\n        _ax = ax\n\n    color = plotStyle[\"color\"]\n    linewidth = plotStyle[\"linewidth\"]\n    sweepX = self.ba.fileLoader.sweepX\n    sweepY = self.ba.fileLoader.sweepY\n\n    _ax.plot(\n        sweepX, sweepY, \"-\", c=color, linewidth=linewidth\n    )  # fmt = '[marker][line][color]'\n\n    xUnits = self.ba.fileLoader.get_xUnits()\n    yUnits = self.ba.fileLoader.get_yUnits()\n    _ax.set_xlabel(xUnits)\n    _ax.set_ylabel(yUnits)\n\n    return _ax\n</code></pre>"},{"location":"api/analysisPlot/#sanpy.analysisPlot.bAnalysisPlot.plotSpikes","title":"<code>plotSpikes(plotThreshold=False, plotPeak=False, plotStyle=None, hue='condition', markerSize=4, ax=None)</code>","text":"<p>Plot Vm with spike analysis overlaid as symbols</p> <p>Args:     plotThreshold     plotPeak     plotStyle (dict): xxx     markerSize     ax (xxx): If specified will plot into a MatPlotLib axes</p> <p>Returns     fig     ax</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisPlot.py</code> <pre><code>def plotSpikes(\n    self,\n    plotThreshold=False,\n    plotPeak=False,\n    plotStyle=None,\n    hue: Optional[str] = \"condition\",\n    markerSize: Optional[int] = 4,\n    ax=None,\n):\n\"\"\"Plot Vm with spike analysis overlaid as symbols\n\n    Args:\n        plotThreshold\n        plotPeak\n        plotStyle (dict): xxx\n        markerSize\n        ax (xxx): If specified will plot into a MatPlotLib axes\n\n    Returns\n        fig\n        ax\n    \"\"\"\n\n    legend = False\n\n    if plotStyle is None:\n        plotStyle = self.getDefaultPlotStyle()\n\n    if ax is None:\n        fig, ax = self._makeFig()\n        fig.suptitle(self.ba.getFileName())\n    # plot vm\n    self.plotRaw(ax=ax)\n\n    # plot spike times\n    if plotThreshold:\n        thresholdSec = self.ba.getStat(\"thresholdSec\")  # x\n        thresholdVal = self.ba.getStat(\"thresholdVal\")  # y\n\n        ax.plot(thresholdSec, thresholdVal, \"pr\", markersize=markerSize)\n        df = self.ba.spikeDict.asDataFrame()  # regenerates, can be expensive\n        # logger.info(f'df hue unique is: {df[hue].unique()}')\n        # sns.scatterplot(x='thresholdSec', y='thresholdVal', hue=hue, data=df, ax=ax, legend=legend)\n\n    # plot the peak\n    if plotPeak:\n        peakPnt = self.ba.getStat(\"peakPnt\")\n        # don't use this for Ca++ concentration\n        # peakVal = self.ba.getStat('peakVal')\n        peakVal = self.ba.fileLoader.sweepY[peakPnt]\n        peakSec = [self.ba.fileLoader.pnt2Sec_(x) for x in peakPnt]\n        ax.plot(peakSec, peakVal, \"oc\", markersize=markerSize)\n\n    xUnits = self.ba.fileLoader.get_xUnits()\n    yUnits = self.ba.fileLoader.get_yUnits()\n    ax.set_xlabel(xUnits)\n    ax.set_ylabel(yUnits)\n\n    return ax\n</code></pre>"},{"location":"api/analysisPlot/#sanpy.analysisPlot.bAnalysisPlot.plotTimeSeries","title":"<code>plotTimeSeries(ba, stat, halfWidthIdx=0, ax=None)</code>","text":"<p>Plot a given spike parameter.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/analysisPlot.py</code> <pre><code>def plotTimeSeries(ba, stat, halfWidthIdx=0, ax=None):\n\"\"\"Plot a given spike parameter.\"\"\"\n    if stat == \"peak\":\n        yStatName = \"peakVal\"\n        yStatLabel = \"Spike Peak (mV)\"\n    if stat == \"preMin\":\n        yStatName = \"preMinVal\"\n        yStatLabel = \"Pre Min (mV)\"\n    if stat == \"halfWidth\":\n        yStatName = \"widthPnts\"\n        yStatLabel = \"Spike Half Width (ms)\"\n\n    #\n    # pull\n    statX = []\n    statVal = []\n    for i, spike in enumerate(ba.spikeDict):\n        if i == 0 or i == len(ba.spikeTimes) - 1:\n            continue\n        else:\n            statX.append(spike[\"peakSec\"])\n            if stat == \"halfWidth\":\n                statVal.append(spike[\"widths\"][halfWidthIdx][\"widthMs\"])\n            else:\n                statVal.append(spike[yStatName])\n\n    #\n    # plot\n    if ax is None:\n        grid = plt.GridSpec(1, 1, wspace=0.2, hspace=0.4)\n\n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(grid[0, 0:])  # Vm, entire sweep\n\n    ax.plot(statX, statVal, \"o-k\")\n\n    ax.set_ylabel(yStatLabel)\n    ax.set_xlabel(\"Time (sec)\")\n\n    return statVal\n</code></pre>"},{"location":"api/bAnalysis/","title":"bAnalysis","text":"<p>The bAnalysis class represents a whole-cell recording and provides functions for analysis.</p> <p>A bAnalysis object can be created in a number of ways: (i) From a file path including .abf and .csv (ii) From a pandas DataFrame when loading from a h5 file. (iii) From a byteStream abf when working in the cloud.</p> <p>Once loaded, a number of operations can be performed including: Spike detection, Error checking, Plotting, and Saving.</p> <p>Examples:</p> <pre><code>path = 'data/19114001.abf'\nba = bAnalysis(path)\ndDict = sanpy.bDetection().getDetectionDict('SA Node')\nba.spikeDetect(dDict)\nprint(ba)\n</code></pre> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>class bAnalysis:\n\"\"\"\n    The bAnalysis class represents a whole-cell recording and provides functions for analysis.\n\n    A bAnalysis object can be created in a number of ways:\n    (i) From a file path including .abf and .csv\n    (ii) From a pandas DataFrame when loading from a h5 file.\n    (iii) From a byteStream abf when working in the cloud.\n\n    Once loaded, a number of operations can be performed including:\n    Spike detection, Error checking, Plotting, and Saving.\n\n    Examples:\n\n    ```python\n    path = 'data/19114001.abf'\n    ba = bAnalysis(path)\n    dDict = sanpy.bDetection().getDetectionDict('SA Node')\n    ba.spikeDetect(dDict)\n    print(ba)\n    ```\n    \"\"\"\n\n    # def getNewUuid():\n    #     return 't' + str(uuid.uuid4()).replace('-', '_')\n\n    def __init__(\n        self,\n        filepath: str = None,\n        byteStream=None,\n        loadData: bool = True,\n        fileLoaderDict: dict = None,\n        stimulusFileFolder: str = None,\n        verbose: bool = False,\n    ):\n\"\"\"\n        Args:\n            filepath (str): Path to either .abf or .csv with time/mV columns.\n            byteStream (io.BytesIO): Binary stream for use in the cloud.\n            loadData: If true, load raw data, otherwise just load header\n            fileLoaderDict (dict)\n                If None then fetch from sanpy.fileloaders.getFileLoaders()\n                Do this if running in a script.\n                If running an SanPy app, we pass the dict\n            stimulusFileFolder:\n        \"\"\"\n\n\"\"\"\n        self._path = file  # todo: change this to filePath\n        \"\"\"\n\"\"\"str: File path.\"\"\"\n\n        self._detectionDict: dict = None  # corresponds to an item in sanpy.bDetection\n\n        self._isAnalyzed: bool = False\n\n        self.loadError: bool = False\n\"\"\"bool: True if error loading file/stream.\"\"\"\n\n        # self.detectionDict = None  # remember the parameters of our last detection\n\"\"\"dict: Dictionary specifying detection parameters, see bDetection.getDefaultDetection.\"\"\"\n\n        # self._abf = None\n\"\"\"pyAbf: If loaded from binary .abf file\"\"\"\n\n        self.dateAnalyzed: str = None\n\"\"\"str: Date Time of analysis. TODO: make a property.\"\"\"\n\n        # self.detectionType = None\n\"\"\"str: From ('dvdt', 'mv')\"\"\"\n\n        self.spikeDict: sanpy.bAnalysisResults.analysisResultList = (\n            sanpy.bAnalysisResults.analysisResultList()\n        )\n        # class to store all analysis results\n\n        # self._spikesPerSweep : int = None\n\n        self.spikeClips = []  # created in self.spikeDetect()\n        self.spikeClips_x = []  #\n        self.spikeClips_x2 = []  #\n\n        self.dfError = None  # dataframe with a list of detection errors\n        self._dfReportForScatter = None  # dataframe to be used by scatterplotwidget\n\n        self._detectionDirty = False\n\n        # will be overwritten by existing uuid in self._loadFromDf()\n        self.uuid = sanpy._util.getNewUuid()\n\n        # self.tifData = None\n        # when we have a tif kymograph\n\n        # self.isBytesIO = False\n        # when we are running in the cloud\n\n        # TODO (cudmore) need to parse folder of file loaders in fileloders/ and determine\n        # class to use to load file (using fileLoader.filetype\n        self._fileLoader = None\n        if filepath is not None and not os.path.isfile(filepath):\n            logger.error(f'File does not exist: \"{filepath}\"')\n            self.loadError = True\n        else:\n            if fileLoaderDict is None:\n                fileLoaderDict = (\n                    sanpy.fileloaders.getFileLoaders()\n                )  # EXPENSIVE, to do, pass in from app\n\n            _ext = os.path.splitext(filepath)[1]\n            _ext = _ext[1:]\n            try:\n                if verbose:\n                    logger.info(f\"Loading file with extension: {_ext}\")\n                constructorObject = fileLoaderDict[_ext][\"constructor\"]\n                self._fileLoader = constructorObject(filepath)\n                # may 2, 2023\n                if self._fileLoader._loadError:\n                    logger.error(f'load error in file loader for ext: \"{_ext}\"')\n                    self.loadError = True\n\n            except KeyError as e:\n                logger.error(f'did not find a file loader for extension \"{_ext}\"')\n                self.loadError = True\n\n\"\"\"\n        if byteStream is not None:\n            self._loadAbf(byteStream=byteStream,\n                    loadData=loadData,\n                    stimulusFileFolder=stimulusFileFolder)\n        elif file is not None and file.endswith('.abf'):\n            self._loadAbf(loadData=loadData)\n        elif file is not None and file.endswith('.atf'):\n            self._loadAtf(loadData=loadData)\n        elif file is not None and file.endswith('.tif'):\n            self._loadTif()\n        elif file is not None and file.endswith('.csv'):\n            self._loadCsv()\n        else:\n            pass\n            #logger.error(f'Can only open abf/csv/tif/stream files: {file}')\n            #self.loadError = True\n        \"\"\"\n\n        # get default derivative\n        if loadData and not self.loadError:\n            self._rebuildFiltered()\n\n        self._detectionDirty = False\n\n\"\"\"\n        self.setSweep()\n        \"\"\"\n\n    @property\n    def fileLoader(self):\n\"\"\" \"\"\"\n        return self._fileLoader\n\n    def getFileName(self):\n        return self.fileLoader.filename\n\n    def asDataFrame(self):\n\"\"\"Return analysis as a Pandas DataFrame.\n\n        Important:\n            This returns a COPY !!!\n            Do not modify and expect changes to stick\n        \"\"\"\n        return self._dfReportForScatter\n        # return self.spikeDict.asDataFrame()\n\n    def getDetectionDict(self, asCopy: bool = False):\n\"\"\"Get the detection dictionary that was used for detect().\"\"\"\n        if asCopy:\n            return copy.deepcopy(self._detectionDict)\n        else:\n            return self._detectionDict\n\n    def __str__(self):\n\"\"\"Get a brief str representation. Usefull for print().\"\"\"\n        # if self.isBytesIO:\n        #      filename = '&lt;BytesIO&gt;'\n        # else:\n        #     filename = self.getFileName()\n        fileLoadStr = self.fileLoader.__str__()\n        txt = f\"fileLoader: {fileLoadStr} spikes:{self.numSpikes}\"\n        return txt\n\n    def _saveHdf_pytables(self, hdfPath):\n\"\"\"Save detection parameters and analysis into an hdf5 file.\"\"\"\n        if not self.detectionDirty:\n            # Do not save it detection has not changed\n            logger.info(f\"NOT SAVING, is not dirty {self}\")\n            return False\n\n        # when making df from dict, need to pass it a list\n        # o.w. key values that are lists get expanded into rows\n        dfDetection = pd.DataFrame([self._detectionDict])\n\n        # convert spikeList (list of dict) to json\n        # spikeList = self.spikeDict.asList()\n        # dataJson = json.dumps(spikeList, cls=NumpyEncoder)  # list of dict\n        # dfAnalysis = pd.DataFrame(spikeList)\n        dfAnalysis = self.spikeDict.asDataFrame()\n\n        uuid = self.uuid\n\n        logger.info(\n            f\"    Saving {self.numSpikes} spikes to uuid {uuid} in h5 file {hdfPath}\"\n        )\n\n        with pd.HDFStore(hdfPath) as hdfStore:\n            key = uuid + \"/\" + \"detectionDict\"\n            dfDetection.to_hdf(hdfStore, key)  # default mode='a'\n\n            key = uuid + \"/\" + \"analysisList\"\n            dfAnalysis.to_hdf(hdfStore, key)\n\n        # we saved, detection is not dirty\n        self._detectionDirty = False\n\n        return True\n\n    def _loadHdf_pytables(self, hdfPath, uuid):\n\"\"\"Load analysis from an h5 file using key 'uuid'.\n\n        Notes\n        -----\n            df.to_dict() requires into=OrderedDIct, o.w. column order is sorted\n            Error report needs to be generated (is not in h5 file)\n                use getErrorReport()\n        \"\"\"\n\n        # cant use pd.HDFStore(&lt;path&gt;) as read_hdf does not understand file pointer\n\n        logger.info(f\"loading {uuid} from {hdfPath}\")\n\n        # load pandas dataframe(s) from h5 file\n        didLoad = True\n        try:\n            detectionDictKey = uuid + \"/\" + \"detectionDict\"  # group\n            dfDetection = pd.read_hdf(hdfPath, detectionDictKey)\n        except KeyError as e:\n            logger.error(e)\n            didLoad = False\n        try:\n            analysisListKey = uuid + \"/\" + \"analysisList\"\n            dfAnalysis = pd.read_hdf(hdfPath, analysisListKey)\n        except KeyError as e:\n            logger.error(e)\n            didLoad = False\n\n        if didLoad:\n            # we take on the uuid we were loaded from\n            self.uuid = uuid\n\n            # convert to a dict\n            detectionDict = dfDetection.to_dict(\"records\", into=OrderedDict)[\n                0\n            ]  # one dict\n\n            self._detectionDict = detectionDict\n            # pprint(detectionDict)\n\n            # convert to a list of dict\n            analysisList = dfAnalysis.to_dict(\n                \"records\", into=OrderedDict\n            )  # list of dict\n            self.spikeDict.setFromListDict(analysisList)\n            # pprint(analysisList[0])\n\n            # recreate spike analysis dataframe\n            self._dfReportForScatter = dfAnalysis\n\n            # regenerate error report\n            self.dfError = self.getErrorReport()\n\n            # dec 2022\n            self._isAnalyzed = True\n\n            logger.info(\n                f\"    loaded {len(detectionDict.keys())} detection keys and {len(self.spikeDict)} spikes\"\n            )\n        else:\n            logger.error(f\"    LOAD FAILED\")\n\n    @property\n    def detectionDirty(self):\n        return self._detectionDirty\n\n    @property\n    def numSpikes(self):\n\"\"\"Get the total number of detected spikes (all sweeps).\n\n        See getNumSpikes(sweep)\n        \"\"\"\n        return len(self.spikeDict)  # spikeDict has all spikes for all sweeps\n\n    def getNumSpikes(self, sweep: int = 0):\n\"\"\"Get number of spikes in a sweep.\n\n        See property numSpikes\n        \"\"\"\n        thresholdSec = self.getStat(\"thresholdSec\", sweepNumber=sweep)\n        return len(thresholdSec)\n        # return self._spikesPerSweep[sweep]\n\n    @property\n    def numErrors(self) -&gt; int:\n\"\"\"Get number of detection errors.\n        \"\"\"\n        if self.dfError is None:\n            # no analysis\n            return None\n        else:\n            return len(self.dfError)\n\n    def _old_getAbsSpikeFromSweep(self, sweepSpikeIdx: int, sweep: int) -&gt; int:\n\"\"\"Given a spike index within a sweep, get the absolute spike index.\n\n        See getSweepSpikeFromAbsolute()\n        \"\"\"\n        absIdx = 0\n        for sweepIdx in range(sweep):\n            absIdx += self._spikesPerSweep[sweepIdx]\n        absIdx += sweepSpikeIdx\n        return absIdx\n\n    def getSweepSpikeFromAbsolute(self, absSpikeIdx: int, sweep: int) -&gt; int:\n\"\"\"Get sweep spike from absolute spike.\n\n        See getAbsSpikeFromSweep()\n        \"\"\"\n        sweepSpikeNum = self.spikeDict[absSpikeIdx][\"sweepSpikeNumber\"]\n        return sweepSpikeNum\n\n        # absIdx = 0\n        # for oneSweep in range(sweep):\n        #     absIdx += self._spikesPerSweep[oneSweep]\n        # sweepSpike = absSpikeIdx - absIdx\n        # return sweepSpike\n\n    def isDirty(self):\n\"\"\"Return True if analysis has been modified but not save.\"\"\"\n        return self._detectionDirty\n\n    def isAnalyzed(self):\n\"\"\"Return True if this bAnalysis has been analyzed, False otherwise.\"\"\"\n        return self._isAnalyzed\n\n    def getStatMean(self, statName: str, sweepNumber: int = None):\n\"\"\"\n        Get the mean of an analysis parameter.\n\n        Args:\n            statName (str): Name of the statistic to retreive.\n                For a list of available stats use bDetection.defaultDetection.\n        \"\"\"\n        theMean = None\n        x = self.getStat(statName, sweepNumber=sweepNumber)\n        if x is not None and len(x) &gt; 1:\n            theMean = np.nanmean(x)\n        return theMean\n\n    def getSpikeStat(self, spikeList : List[int], stat : str):\n\"\"\"Get one stat from a list of spikes\n\n        Parameters\n        ----------\n        spikeList : List[int]\n        stat : str\n        \"\"\"\n\n        # if isinstance(spikeList, int):\n        #     spikeList = [spikeList]\n\n        if len(spikeList) == 0:\n            return None\n\n        # logger.info(f'spikeList: {spikeList} stat:{stat}')\n\n        retList = []\n        # count = 0\n        for idx, spike in enumerate(self.spikeDict):\n            # logger.info(f'  idx:{idx}')\n            if idx in spikeList:\n                try:\n                    val = spike[stat]\n                    retList.append(val)\n                    # count += 1\n                except KeyError as e:\n                    logger.error(e)\n        # logger.info(f'  retList: {retList}')\n        return retList\n\n    def setSpikeStat_time(self, startSec: int, stopSec: int, stat: str, value):\n\"\"\"Set a spike stat for spikes in a range of time.\"\"\"\n\n        # get spike list in range [startSec, stopSec]\n        spikeSeconds = self.getSpikeSeconds()\n        spikeList = [\n            idx for idx, x in enumerate(spikeSeconds) if x &gt;= startSec and x &lt; stopSec\n        ]\n        self.setSpikeStat(spikeList, stat, value)\n\n    def setSpikeStat(self, spikeList: Union[list, int], stat: str, value):\n\"\"\"Set a spike stat for one spike or a list of spikes.\n\n        Used to set things like ('isBad', 'userType1', 'condition', ...)\n        \"\"\"\n        if isinstance(spikeList, int):\n            spikeList = [spikeList]\n            # else:\n            #     logger.error(f'Expecting list[int] or int but got spikeList type {type(spikeList)}')\n            return\n\n        if len(spikeList) == 0:\n            return\n\n        now = datetime.datetime.now()\n        modDate = now.strftime(\"%Y%m%d\")\n        modTime = now.strftime(\"%H:%M:%S\")\n\n        for spike in spikeList:\n            self.spikeDict[spike][stat] = value\n            self.spikeDict[spike][\"modDate\"] = modDate\n            self.spikeDict[spike][\"modTime\"] = modTime\n\n        self._detectionDirty = True\n\n        logger.info(f'set spikes {spikeList} stat \"{stat}\" to value \"{value}\"')\n\n\"\"\"\n        count = 0\n        for idx, spike in enumerate(self.spikeDict):\n            if idx in spikeList:\n                try:\n                    spike[stat] = value\n                    count += 1\n                except (KeyError) as e:\n                    logger.info(e)\n        #\n        logger.info(f'Given {len(spikeList)} and set {count}')\n        \"\"\"\n\n    def getSweepStats(\n        self, statName: str, decimals=3, asDataFrame=False, df: pd.DataFrame = None\n    ):\n\"\"\"\n\n        Args:\n            df (pd.DataFrame): For kymograph we sometimes have to convert (peak) values to molar\n        \"\"\"\n\n        if df is None:\n            df = self.spikeDict.asDataFrame()\n\n        sweepStatList = []\n\n        for sweep in range(self.fileLoader.numSweeps):\n            oneDf = df[df[\"sweep\"] == sweep]\n            theValues = oneDf[statName]\n\n            theCount = np.count_nonzero(~np.isnan(theValues))\n            theMin = np.min(theValues)\n            theMax = np.max(theValues)\n            theMean = np.nanmean(theValues)\n\n            theMin = round(theMin, decimals)\n            theMax = round(theMax, decimals)\n            theMean = round(theMean, decimals)\n\n            if theCount &gt; 2:\n                theMedian = np.nanmedian(theValues)\n                theSEM = scipy.stats.sem(theValues)\n                theSD = np.nanstd(theValues)\n                theVar = np.nanvar(theValues)\n                theCV = theSD / theVar\n\n                theMedian = round(theMedian, decimals)\n                theSEM = round(theSEM, decimals)\n                theSD = round(theSD, decimals)\n                theVar = round(theVar, decimals)\n                theCV = round(theCV, decimals)\n\n            else:\n                theMedian = None\n                theSEM = None\n                theSD = None\n                theVar = None\n                theCV = None\n\n            oneDict = {\n                statName + \"_sweep\": sweep,\n                statName + \"_count\": theCount,\n                statName + \"_min\": theMin,\n                statName + \"_max\": theMax,\n                statName + \"_mean\": theMean,\n                statName + \"_median\": theMedian,\n                statName + \"_sem\": theSEM,\n                statName + \"_std\": theSD,\n                statName + \"_var\": theVar,\n                statName + \"_cv\": theCV,\n            }\n\n            sweepStatList.append(oneDict)\n\n        #\n        if asDataFrame:\n            return pd.DataFrame(sweepStatList)\n        else:\n            return sweepStatList\n\n    def getStat(\n        self,\n        statName1,\n        statName2: Optional[str] = None,\n        sweepNumber: Optional[int] = None,\n        epochNumber: Optional[int] = None,\n        asArray: Optional[bool] = False,\n        getFullList : Optional[bool] = False\n    ):\n\"\"\"Get a list of values for one or two analysis results.\n\n        Parameters\n        ----------\n        statName1 : str\n            Name of the first analysis parameter to retreive.\n        statName2 : str\n            Optional name of the second analysis parameter to retreive.\n        sweepNumber : int str or None\n            Optional sweep number, if None or 'All' then get all sweeps\n        epochNumber : int str or None\n            Optional epoch number, if None or 'All' then get all epochs\n        asArray : bool\n            If True then return as np.array(), otherwise return as a list\n\n        Notes\n        -----\n        For a list of available analysis results,\n            see [bDetection.getDefaultDetection()][sanpy.bDetection.bDetection]\n\n        If the returned list of analysis results are in points,\n            convert to seconds or ms using: pnt2Sec_(pnt) or pnt2Ms_(pnt).\n\n        Returns\n        -------\n        list or np.array\n            List of analysis parameter values, None if error.\n            Returns a np.array is asArray is True\n        \"\"\"\n\n        def clean(val):\n\"\"\"Convert None to float('nan')\"\"\"\n            if val is None:\n                val = float(\"nan\")\n            return val\n\n        x = []  # None\n        y = []  # None\n        error = False\n        if len(self.spikeDict) == 0:\n            # logger.error(f'Did not find any spikes in spikeDict')\n            error = True\n        elif statName1 not in self.spikeDict[0].keys():\n            logger.error(f'Did not find statName1: \"{statName1}\" in spikeDict')\n            error = True\n        elif statName2 is not None and statName2 not in self.spikeDict[0].keys():\n            logger.error(f'Did not find statName2: \"{statName2}\" in spikeDict')\n            error = True\n\n        if sweepNumber is None:\n            sweepNumber = \"All\"\n\n        if epochNumber is None:\n            epochNumber = \"All\"\n\n        if not error:\n            # original\n            # x = [clean(spike[statName1]) for spike in self.spikeDict]\n\n            if getFullList:\n                # April 15, 2023, trying to fix bug in scatter plugin when we are\n                # using sweep and epoch\n                # strategy is to return all spikes, just nan out the ones we \n                # are not interested in\n                x = []\n                for spike in self.spikeDict:\n                    _include = \\\n                        (sweepNumber == \"All\" or spike[\"sweep\"] == sweepNumber) \\\n                            and (epochNumber == \"All\" or spike[\"epoch\"] == epochNumber)\n                    if _include:\n                        x.append(clean(spike[statName1]))\n                    else:\n                        x.append(float(\"nan\"))\n\n            else:\n                # only current sweep and epoch\n                # (1) was this\n                x = [\n                    clean(spike[statName1])\n                    for spike in self.spikeDict\n                    if (sweepNumber == \"All\" or spike[\"sweep\"] == sweepNumber)\n                    and (epochNumber == \"All\" or spike[\"epoch\"] == epochNumber)\n                ]\n\n\n            if statName2 is not None:\n                # original\n                # y = [clean(spike[statName2]) for spike in self.spikeDict]\n                # only current spweek\n                y = [\n                    clean(spike[statName2])\n                    for spike in self.spikeDict\n                    if sweepNumber == \"All\" or spike[\"sweep\"] == sweepNumber\n                ]\n\n        if asArray:\n            x = np.array(x)\n            if statName2 is not None:\n                y = np.array(y)\n\n        if statName2 is not None:\n            return x, y\n        else:\n            return x\n\n    def getSpikeTimes(self, sweepNumber=None, epochNumber='All'):\n\"\"\"Get spike times (points) for current sweep\"\"\"\n        # theRet = [spike['thresholdPnt'] for spike in self.spikeDict if spike['sweep']==self.currentSweep]\n        theRet = self.getStat(\"thresholdPnt\", sweepNumber=sweepNumber, epochNumber=epochNumber)\n        return theRet\n\n    def getSpikeSeconds(self, sweepNumber=None):\n\"\"\"Get spike times (seconds) for current sweep\"\"\"\n        # theRet = [spike['thresholdSec'] for spike in self.spikeDict if spike['sweep']==self.currentSweep]\n        theRet = self.getStat(\"thresholdSec\", sweepNumber=sweepNumber)\n        return theRet\n\n    def getSpikeDictionaries(self, sweepNumber=None):\n\"\"\"Get spike dictionaries for current sweep\n        \"\"\"\n        if sweepNumber is None:\n            sweepNumber = \"All\"\n        # logger.info(f'sweepNumber:{sweepNumber}')\n        theRet = [\n            spike\n            for spike in self.spikeDict\n            if sweepNumber == \"All\" or spike[\"sweep\"] == sweepNumber\n        ]\n        return theRet\n\n    def getOneSpikeDict(self, spikeNumber: int):\n        return self.spikeDict[spikeNumber]\n\n    def _rebuildFiltered(self):\n        if self.fileLoader.sweepX is None:\n            # no data\n            logger.warning(\"not getting derivative ... sweepX was none?\")\n            return\n\n        if (\n            self.fileLoader.recordingMode == recordingModes.iclamp\n            or self.fileLoader.recordingMode == recordingModes.kymograph\n        ):\n            self.fileLoader._getDerivative()\n        elif self.fileLoader.recordingMode == recordingModes.vclamp:\n            self.fileLoader._getDerivative()\n        else:\n            logger.warning(\n                f'Did not take derivative, unknown recording mode \"{self.fileLoader.recordingMode}\"'\n            )\n\n    def _getFilteredRecording(self):\n\"\"\"\n        Get a filtered version of recording, used for both V-Clamp and I-Clamp.\n\n        Args:\n            dDict (dict): Default detection dictionary. See bDetection.defaultDetection\n        \"\"\"\n\n        if self._detectionDict is not None:\n            medianFilter = self._detectionDict[\"medianFilter\"]\n            SavitzkyGolay_pnts = self._detectionDict[\"SavitzkyGolay_pnts\"]\n            SavitzkyGolay_poly = self._detectionDict[\"SavitzkyGolay_poly\"]\n        else:\n            # we have not been analyzed, impose some defaults\n            medianFilter = 0  # no median filter\n            SavitzkyGolay_pnts = 5\n            SavitzkyGolay_poly = 2\n\n        self.fileLoader._getDerivative(\n            medianFilter, SavitzkyGolay_pnts, SavitzkyGolay_poly\n        )\n\n        # if medianFilter &gt; 0:\n        #     if not medianFilter % 2:\n        #         medianFilter += 1\n        #         logger.warning(f'Please use an odd value for the median filter, set medianFilter: {medianFilter}')\n        #     medianFilter = int(medianFilter)\n        #     self._filteredVm = scipy.signal.medfilt2d(self.sweepY(), [medianFilter,1])\n        # elif SavitzkyGolay_pnts &gt; 0:\n        #     self._filteredVm = scipy.signal.savgol_filter(self.sweepY(),\n        #                         SavitzkyGolay_pnts, SavitzkyGolay_poly,\n        #                         mode='nearest', axis=0)\n        # else:\n        #     self._filteredVm = self.sweepY\n\n    def _backupSpikeVm(self, spikeTimes, sweepNumber, medianFilter=None):\n\"\"\"\n        Backup spike time using deminishing SD and diff b/w vm at pnt[i]-pnt[i-1]\n        Used when detecting with just mV threshold (not dv/dt)\n\n        Args:\n            spikeTimes (list of float):\n            medianFilter (int): bin width\n        \"\"\"\n        # realSpikeTimePnts = [np.nan] * self.numSpikes\n        realSpikeTimePnts = [np.nan] * len(spikeTimes)\n\n        medianFilter = 5\n        sweepY = self.fileLoader.sweepY\n        if medianFilter &gt; 0:\n            myVm = scipy.signal.medfilt(sweepY, medianFilter)\n        else:\n            myVm = sweepY\n\n        #\n        # TODO: this is going to fail if spike is at start/stop of recorrding\n        #\n\n        maxNumPntsToBackup = 20  # todo: add _ms\n        bin_ms = 1\n        bin_pnts = round(bin_ms * self.fileLoader.dataPointsPerMs)\n        half_bin_pnts = math.floor(bin_pnts / 2)\n        for idx, spikeTimePnts in enumerate(spikeTimes):\n            foundRealThresh = False\n            thisMean = None\n            thisSD = None\n            backupNumPnts = 0\n            atBinPnt = spikeTimePnts\n            while not foundRealThresh:\n                thisWin = myVm[atBinPnt - half_bin_pnts : atBinPnt + half_bin_pnts]\n                if thisMean is None:\n                    thisMean = np.mean(thisWin)\n                    thisSD = np.std(thisWin)\n\n                nextStart = atBinPnt - 1 - bin_pnts - half_bin_pnts\n                nextStop = atBinPnt - 1 - bin_pnts + half_bin_pnts\n                nextWin = myVm[nextStart:nextStop]\n                nextMean = np.mean(nextWin)\n                nextSD = np.std(nextWin)\n\n                meanDiff = thisMean - nextMean\n                # logic\n                sdMult = 0.7  # 2\n                if (meanDiff &lt; nextSD * sdMult) or (\n                    backupNumPnts == maxNumPntsToBackup\n                ):\n                    # second clause will force us to terminate (this recording has a very slow rise time)\n                    # bingo!\n                    foundRealThresh = True\n                    # not this xxx but the previous\n                    moveForwardPnts = 4\n                    backupNumPnts = backupNumPnts - 1  # the prev is thresh\n                    if backupNumPnts &lt; moveForwardPnts:\n                        logger.warning(\n                            f\"spike {idx} backupNumPnts:{backupNumPnts} &lt; moveForwardPnts:{moveForwardPnts}\"\n                        )\n                        # print('  --&gt;&gt; not adjusting spike time')\n                        realBackupPnts = backupNumPnts - 0\n                        realPnt = spikeTimePnts - (realBackupPnts * bin_pnts)\n\n                    else:\n                        realBackupPnts = backupNumPnts - moveForwardPnts\n                        realPnt = spikeTimePnts - (realBackupPnts * bin_pnts)\n                    #\n                    realSpikeTimePnts[idx] = realPnt\n\n                # increment\n                thisMean = nextMean\n                thisSD = nextSD\n\n                atBinPnt -= bin_pnts\n                backupNumPnts += 1\n\"\"\"\n                if backupNumPnts&gt;maxNumPntsToBackup:\n                    print(f'  WARNING: _backupSpikeVm() exiting spike {idx} ... reached maxNumPntsToBackup:{maxNumPntsToBackup}')\n                    print('  --&gt;&gt; not adjusting spike time')\n                    foundRealThresh = True # set this so we exit the loop\n                    realSpikeTimePnts[idx] = spikeTimePnts\n                \"\"\"\n\n        #\n        return realSpikeTimePnts\n\n    def _throwOutRefractory(self, spikeTimes0, goodSpikeErrors, refractory_ms=20):\n\"\"\"\n        spikeTimes0: spike times to consider\n        goodSpikeErrors: list of errors per spike, can be None\n        refractory_ms:\n        \"\"\"\n        before = len(spikeTimes0)\n\n        # if there are doubles, throw-out the second one\n        # refractory_ms = 20 #10 # remove spike [i] if it occurs within refractory_ms of spike [i-1]\n        lastGood = 0  # first spike [0] will always be good, there is no spike [i-1]\n        for i in range(len(spikeTimes0)):\n            if i == 0:\n                # first spike is always good\n                continue\n            dPoints = spikeTimes0[i] - spikeTimes0[lastGood]\n            if dPoints &lt; self.fileLoader.dataPointsPerMs * refractory_ms:\n                # remove spike time [i]\n                spikeTimes0[i] = 0\n            else:\n                # spike time [i] was good\n                lastGood = i\n        # regenerate spikeTimes0 by throwing out any spike time that does not pass 'if spikeTime'\n        # spikeTimes[i] that were set to 0 above (they were too close to the previous spike)\n        # will not pass 'if spikeTime', as 'if 0' evaluates to False\n        if goodSpikeErrors is not None:\n            goodSpikeErrors = [\n                goodSpikeErrors[idx]\n                for idx, spikeTime in enumerate(spikeTimes0)\n                if spikeTime\n            ]\n        spikeTimes0 = [spikeTime for spikeTime in spikeTimes0 if spikeTime]\n\n        # TODO: put back in and log if detection ['verbose']\n        after = len(spikeTimes0)\n        if self._detectionDict[\"verbose\"]:\n            logger.info(\n                f\"From {before} to {after} spikes with refractory_ms:{refractory_ms}\"\n            )\n\n        return spikeTimes0, goodSpikeErrors\n\n    def _getHalfWidth(\n        self,\n        vm,\n        iIdx,\n        spikeDict,\n        thresholdPnt,\n        peakPnt,\n        hwWindowPnts,\n        dataPointsPerMs,\n        halfHeightList,\n        verbose=False,\n    ):\n\"\"\"\n        Get half-widhts for one spike.\n\n        Note: Want to make this standalone function outside of class but we need self._getErrorDict()\n\n        Args:\n            vm ():\n            iIdx (int):\n            spikeDict (): new 20210928\n            #dictNumber (int):\n            thresholdPnt (int): AP threshold crossing\n            peakPnt (int): AP peak\n            hwWindowPnts (int): Window to look after peakPnt for falling vm\n            dataPointsPerMs (int):\n            halfHeightList (list): List of half-height [10,20,50,80,90]\n        \"\"\"\n\n        halfWidthWindow_ms = hwWindowPnts / dataPointsPerMs\n\n        thresholdVal = vm[thresholdPnt]\n        peakVal = vm[peakPnt]\n        spikeHeight = peakVal - thresholdVal\n\n        spikeSecond = thresholdPnt / dataPointsPerMs / 1000\n        peakSec = peakPnt / dataPointsPerMs / 1000\n\n        widthDictList = []\n        errorList = []\n\n        # clear out any existing list\n        spikeDict[iIdx][\"widths\"] = []\n\n        tmpErrorType = None\n        for j, halfHeight in enumerate(halfHeightList):\n            # halfHeight in [20, 50, 80]\n\n            # search rising/falling phae of vm for this vm\n            thisVm = thresholdVal + spikeHeight * (halfHeight * 0.01)\n\n            # todo: logic is broken, this get over-written in following try\n            widthDict = {\n                \"halfHeight\": halfHeight,\n                \"risingPnt\": None,\n                #'risingVal': defaultVal,\n                \"fallingPnt\": None,\n                #'fallingVal': defaultVal,\n                \"widthPnts\": None,\n                \"widthMs\": float(\"nan\"),\n            }\n            widthMs = float(\"nan\")\n            try:\n                postRange = vm[peakPnt : peakPnt + hwWindowPnts]\n                fallingPnt = np.where(postRange &lt; thisVm)[0]  # less than\n                if len(fallingPnt) == 0:\n                    # no falling pnts found within hwWindowPnts\n                    tmpErrorType = \"falling point\"\n                    raise IndexError\n                fallingPnt = fallingPnt[0]  # first falling point\n                fallingPnt += peakPnt\n                fallingVal = vm[fallingPnt]\n\n                # use the post/falling to find pre/rising\n                preRange = vm[thresholdPnt:peakPnt]\n                risingPnt = np.where(preRange &gt; fallingVal)[0]  # greater than\n                if len(risingPnt) == 0:\n                    tmpErrorType = \"rising point\"\n                    raise IndexError\n                risingPnt = risingPnt[0]  # first rising point\n                risingPnt += thresholdPnt\n                # risingVal = vm[risingPnt]\n\n                # width (pnts)\n                widthPnts = fallingPnt - risingPnt\n                widthMs = widthPnts / dataPointsPerMs\n                # 20210825 may want to add this to analysis\n                # widthPnts2 = fallingPnt - thresholdPnt\n                # assign\n                widthDict[\"halfHeight\"] = halfHeight\n                widthDict[\"risingPnt\"] = risingPnt\n                # widthDict['risingVal'] = risingVal\n                widthDict[\"fallingPnt\"] = fallingPnt\n                # widthDict['fallingVal'] = fallingVal\n                widthDict[\"widthPnts\"] = widthPnts\n                widthDict[\"widthMs\"] = widthMs\n                # widthMs = widthPnts / dataPointsPerMs # abb 20210125\n\n                # may want to add this\n                # widthDict['widthPnts2'] = widthPnts2\n                # widthDict['widthMs2'] = widthPnts2 / dataPointsPerMs\n\n            except IndexError as e:\n                errorType = \"Spike Width\"\n                errorStr = (\n                    f'Half width {halfHeight} error in \"{tmpErrorType}\" '\n                    f\"with halfWidthWindow_ms:{halfWidthWindow_ms} \"\n                    f\"searching for Vm:{round(thisVm,2)} from peak sec {round(peakSec,2)}\"\n                )\n\n                # was this\n                # eDict = self._getErrorDict(spikeNumber, thresholdPnt, errorType, errorStr) # spikeTime is in pnts\n                eDict = self._getErrorDict(\n                    iIdx, thresholdPnt, errorType, errorStr\n                )  # spikeTime is in pnts\n                # self.spikeDict[dictNumber]['errors'].append(eDict)\n                spikeDict[iIdx][\"errors\"].append(eDict)\n                if verbose:\n                    print(\n                        f\"_getHalfWidth() error iIdx:{iIdx} j:{j} halfHeight:{halfHeight} eDict:{eDict}\"\n                    )\n            #\n            # self.spikeDict[dictNumber]['widths_'+str(halfHeight)] = widthMs\n            # self.spikeDict[dictNumber]['widths'][j] = widthDict\n\n            # logger.info('================')\n            # print(f'len(spikeDict):{len(spikeDict)} iIdx:{iIdx} j:{j} widthDict:{widthDict}')\n\n            spikeDict[iIdx][\"widths_\" + str(halfHeight)] = widthMs\n            # spikeDict[iIdx]['widths'][j] = widthDict\n            spikeDict[iIdx][\"widths\"].append(widthDict)\n\n        #\n        # return widthDictList, errorList\n\n    def _getErrorDict(self, spikeNumber, pnt, _type : str, detailStr) -&gt; dict:\n\"\"\"Get error dict for one spike\n\n        Notes\n        -----\n        Can't use self.getSpikeStat() because it is not created yet.\n            We are in the middle of analysis\n        \"\"\"\n        sec = self.fileLoader.pnt2Sec_(pnt)  # pnt / self.dataPointsPerMs / 1000\n        sec = round(sec, 4)\n\n        # print(f'  spikeNumber: {spikeNumber} {type(spikeNumber)}')\n        # print('    sweep:', self.getSpikeStat([spikeNumber], 'sweep'))\n\n        eDict = {\n            \"Spike\": spikeNumber,\n            \"Seconds\": sec,\n            \"Sweep\": '',  # self.getSpikeStat([spikeNumber], 'sweep')[0],\n            \"Epoch\": '',  # self.getSpikeStat([spikeNumber], 'epoch')[0],\n            \"Type\": _type,\n            \"Details\": detailStr,\n        }\n        return eDict\n\n    def _spikeDetect_dvdt(self, dDict: dict, sweepNumber: int, verbose: bool = False):\n\"\"\"\n        Search for threshold crossings (dvdtThreshold) in first derivative (dV/dt) of membrane potential (Vm)\n        append each threshold crossing (e.g. a spike) in self.spikeTimes list\n\n        Returns:\n            self.spikeTimes (pnts): the time before each threshold crossing when dv/dt crosses 15% of its max\n            self.filteredVm:\n            self.filtereddVdt:\n        \"\"\"\n\n        #\n        # analyze full recording\n        filteredDeriv = self.fileLoader.filteredDeriv\n        Is = np.where(filteredDeriv &gt; dDict[\"dvdtThreshold\"])[0]\n        Is = np.concatenate(([0], Is))\n        Ds = Is[:-1] - Is[1:] + 1\n        spikeTimes0 = Is[np.where(Ds)[0] + 1]\n\n        #\n        # reduce spike times based on start/stop\n        # logger.error('THIS IS a BUg if start sec is none then set to 0 !!!')\n        # THIS IS ABUG ... FIX\n        if dDict[\"startSeconds\"] is not None and dDict[\"stopSeconds\"] is not None:\n            startPnt = self.fileLoader.dataPointsPerMs * (\n                dDict[\"startSeconds\"] * 1000\n            )  # seconds to pnt\n            stopPnt = self.fileLoader.dataPointsPerMs * (\n                dDict[\"stopSeconds\"] * 1000\n            )  # seconds to pnt\n            tmpSpikeTimes = [\n                spikeTime\n                for spikeTime in spikeTimes0\n                if (spikeTime &gt;= startPnt and spikeTime &lt;= stopPnt)\n            ]\n            spikeTimes0 = tmpSpikeTimes\n\n        #\n        # throw out all spikes that are below a threshold Vm (usually below -20 mV)\n        peakWindow_pnts = self.fileLoader.ms2Pnt_(dDict[\"peakWindow_ms\"])\n        # peakWindow_pnts = self.dataPointsPerMs * dDict['peakWindow_ms']\n        # peakWindow_pnts = round(peakWindow_pnts)\n        goodSpikeTimes = []\n        sweepY = self.fileLoader.sweepY\n        for spikeTime in spikeTimes0:\n            peakVal = np.max(sweepY[spikeTime : spikeTime + peakWindow_pnts])\n            if peakVal &gt; dDict[\"mvThreshold\"]:\n                goodSpikeTimes.append(spikeTime)\n        spikeTimes0 = goodSpikeTimes\n\n        #\n        # throw out spike that are not upward deflections of Vm\n\"\"\"\n        prePntUp = 7 # pnts\n        goodSpikeTimes = []\n        for spikeTime in spikeTimes0:\n            preAvg = np.average(self.abf.sweepY[spikeTime-prePntUp:spikeTime-1])\n            postAvg = np.average(self.abf.sweepY[spikeTime+1:spikeTime+prePntUp])\n            #print(preAvg, postAvg)\n            if preAvg &lt; postAvg:\n                goodSpikeTimes.append(spikeTime)\n        spikeTimes0 = goodSpikeTimes\n        \"\"\"\n\n        #\n        # if there are doubles, throw-out the second one\n        spikeTimeErrors = None\n        spikeTimes0, ignoreSpikeErrors = self._throwOutRefractory(\n            spikeTimes0, spikeTimeErrors, refractory_ms=dDict[\"refractory_ms\"]\n        )\n\n        # logger.warning('REMOVED SPIKE TOP AS % OF DVDT')\n        # return spikeTimes0, [None] * len(spikeTimes0)\n\n        #\n        # for each threshold crossing, search backwards in dV/dt for a % of maximum (about 10 ms)\n        # dvdt_percentOfMax = 0.1\n        # window_ms = 2\n        window_pnts = dDict[\"dvdtPreWindow_ms\"] * self.fileLoader.dataPointsPerMs\n        # abb 20210130 lcr analysis\n        window_pnts = round(window_pnts)\n        spikeTimes1 = []\n        spikeErrorList1 = []\n        filteredDeriv = self.fileLoader.filteredDeriv\n        for i, spikeTime in enumerate(spikeTimes0):\n            # get max in derivative\n\n            preDerivClip = filteredDeriv[\n                spikeTime - window_pnts : spikeTime\n            ]  # backwards\n            postDerivClip = filteredDeriv[\n                spikeTime : spikeTime + window_pnts\n            ]  # forwards\n\n            if len(preDerivClip) == 0:\n                print(\n                    \"FIX ERROR: spikeDetect_dvdt()\",\n                    \"spike\",\n                    i,\n                    \"at pnt\",\n                    spikeTime,\n                    \"window_pnts:\",\n                    window_pnts,\n                    \"dvdtPreWindow_ms:\",\n                    dDict[\"dvdtPreWindow_ms\"],\n                    \"len(preDerivClip)\",\n                    len(preDerivClip),\n                )  # preDerivClip = np.flip(preDerivClip)\n\n            # look for % of max in dvdt\n            try:\n                # peakPnt = np.argmax(preDerivClip)\n                peakPnt = np.argmax(postDerivClip)\n                # peakPnt += spikeTime-window_pnts\n                peakPnt += spikeTime\n                peakVal = filteredDeriv[peakPnt]\n\n                percentMaxVal = (\n                    peakVal * dDict[\"dvdt_percentOfMax\"]\n                )  # value we are looking for in dv/dt\n                preDerivClip = np.flip(preDerivClip)  # backwards\n                tmpWhere = np.where(preDerivClip &lt; percentMaxVal)\n                # print('tmpWhere:', type(tmpWhere), tmpWhere)\n                tmpWhere = tmpWhere[0]\n                if len(tmpWhere) &gt; 0:\n                    threshPnt2 = np.where(preDerivClip &lt; percentMaxVal)[0][0]\n                    threshPnt2 = (spikeTime) - threshPnt2\n                    # print('i:', i, 'spikeTime:', spikeTime, 'peakPnt:', peakPnt, 'threshPnt2:', threshPnt2)\n                    threshPnt2 -= 1  # backup by 1 pnt\n                    spikeTimes1.append(threshPnt2)\n                    spikeErrorList1.append(None)\n\n                else:\n                    errorType = \"dvdt Percent\"\n                    errStr = f\"Did not find dvdt_percentOfMax: {dDict['dvdt_percentOfMax']} peak dV/dt is {round(peakVal,2)}\"\n                    eDict = self._getErrorDict(\n                        i, spikeTime, errorType, errStr\n                    )  # spikeTime is in pnts\n                    spikeErrorList1.append(eDict)\n                    # always append, do not REJECT spike if we can't find % in dv/dt\n                    spikeTimes1.append(spikeTime)\n            except (IndexError, ValueError) as e:\n                ##\n                print(\n                    \"   FIX ERROR: bAnalysis.spikeDetect_dvdt() looking for dvdt_percentOfMax\"\n                )\n                print(\"      \", \"IndexError for spike\", i, spikeTime)\n                print(\"      \", e)\n                # always append, do not REJECT spike if we can't find % in dv/dt\n                spikeTimes1.append(spikeTime)\n\n        return spikeTimes1, spikeErrorList1\n\n    def _spikeDetect_vm(self, dDict: dict, sweepNumber: int, verbose: bool = False):\n\"\"\"\n        spike detect using Vm threshold and NOT dvdt\n        append each threshold crossing (e.g. a spike) in self.spikeTimes list\n\n        Returns:\n            self.spikeTimes (pnts): the time before each threshold crossing when dv/dt crosses 15% of its max\n            self.filteredVm:\n            self.filtereddVdt:\n        \"\"\"\n\n        filteredVm = self.fileLoader.sweepY_filtered\n        Is = np.where(filteredVm &gt; dDict[\"mvThreshold\"])[0]  # returns boolean array\n        Is = np.concatenate(([0], Is))\n        Ds = Is[:-1] - Is[1:] + 1\n        spikeTimes0 = Is[np.where(Ds)[0] + 1]\n\n        #\n        # reduce spike times based on start/stop\n        if dDict[\"startSeconds\"] is not None and dDict[\"stopSeconds\"] is not None:\n            startPnt = self.fileLoader.dataPointsPerMs * (\n                dDict[\"startSeconds\"] * 1000\n            )  # seconds to pnt\n            stopPnt = self.fileLoader.dataPointsPerMs * (\n                dDict[\"stopSeconds\"] * 1000\n            )  # seconds to pnt\n            tmpSpikeTimes = [\n                spikeTime\n                for spikeTime in spikeTimes0\n                if (spikeTime &gt;= startPnt and spikeTime &lt;= stopPnt)\n            ]\n            spikeTimes0 = tmpSpikeTimes\n\n        spikeErrorList = [None] * len(spikeTimes0)\n\n        #\n        # throw out all spikes that are below a threshold Vm (usually below -20 mV)\n        # spikeTimes0 = [spikeTime for spikeTime in spikeTimes0 if self.abf.sweepY[spikeTime] &gt; self.mvThreshold]\n        # 20190623 - already done in this vm threshold funtion\n\"\"\"\n        peakWindow_ms = 10\n        peakWindow_pnts = self.abf.dataPointsPerMs * peakWindow_ms\n        goodSpikeTimes = []\n        for spikeTime in spikeTimes0:\n            peakVal = np.max(self.abf.sweepY[spikeTime:spikeTime+peakWindow_pnts])\n            if peakVal &gt; self.mvThreshold:\n                goodSpikeTimes.append(spikeTime)\n        spikeTimes0 = goodSpikeTimes\n        \"\"\"\n\n        #\n        # throw out spike that are NOT upward deflections of Vm\n        tmpLastGoodSpike_pnts = None\n        # minISI_pnts = 5000 # at 20 kHz this is 0.25 sec\n        minISI_ms = 75  # 250\n        minISI_pnts = self.fileLoader.ms2Pnt_(minISI_ms)\n\n        prePntUp = 10  # pnts\n        goodSpikeTimes = []\n        goodSpikeErrors = []\n        sweepY = self.fileLoader.sweepY\n        for tmpIdx, spikeTime in enumerate(spikeTimes0):\n            tmpFuckPreClip = sweepY[\n                spikeTime - prePntUp : spikeTime\n            ]  # not including the stop index\n            tmpFuckPostClip = sweepY[\n                spikeTime + 1 : spikeTime + prePntUp + 1\n            ]  # not including the stop index\n            preAvg = np.average(tmpFuckPreClip)\n            postAvg = np.average(tmpFuckPostClip)\n            if postAvg &gt; preAvg:\n                # tmpSpikeTimeSec = self.fileLoader.pnt2Sec_(spikeTime)\n                if (\n                    tmpLastGoodSpike_pnts is not None\n                    and (spikeTime - tmpLastGoodSpike_pnts) &lt; minISI_pnts\n                ):\n                    continue\n                goodSpikeTimes.append(spikeTime)\n                goodSpikeErrors.append(spikeErrorList[tmpIdx])\n                tmpLastGoodSpike_pnts = spikeTime\n            else:\n                tmpSpikeTimeSec = self.fileLoader.pnt2Sec_(spikeTime)\n\n        # todo: add this to spikeDetect_dvdt()\n        goodSpikeTimes, goodSpikeErrors = self._throwOutRefractory(\n            goodSpikeTimes, goodSpikeErrors, refractory_ms=dDict[\"refractory_ms\"]\n        )\n        spikeTimes0 = goodSpikeTimes\n        spikeErrorList = goodSpikeErrors\n\n        #\n        return spikeTimes0, spikeErrorList\n\n    def spikeDetect(self, detectionDict: dict):\n\"\"\"Run spike detection for all sweeps.\n\n        Each spike is a row and has 'sweep'\n\n        Args:\n            detectionDict: From sanpy.bDetection\n        \"\"\"\n\n        rememberSweep = (\n            self.fileLoader.currentSweep\n        )  # This is BAD we are mixing analysis with interface !!!\n\n        startTime = time.time()\n\n        #\n        # todo: ask user if they want to remove their settings for (isBad, userType)\n        #\n\n        self._detectionDict = detectionDict\n\n        if detectionDict[\"verbose\"]:\n            logger.info(\"=== detectionDict is:\")\n            for k in detectionDict.keys():\n                v = detectionDict[k]\n                print(f'  {k} value:\"{v}\" is type {type(v)}')\n\n        self._isAnalyzed = True\n\n        self.spikeDict = sanpy.bAnalysisResults.analysisResultList()\n        # we are filling this in, one dict for each spike\n        # self.spikeDict = [] # we are filling this in, one dict for each spike\n\n        # self._spikesPerSweep = [0] * self.fileLoader.numSweeps\n\n        for sweepNumber in self.fileLoader.sweepList:\n            # self.setSweep(sweep)\n            self._spikeDetect2(sweepNumber)\n\n        #\n        self.fileLoader.setSweep(rememberSweep)\n\n        stopTime = time.time()\n\n        if detectionDict[\"verbose\"]:\n            logger.info(\n                f\"Detected {len(self.spikeDict)} spikes in {round(stopTime-startTime,3)} seconds\"\n            )\n\n    def _spikeDetect2(self, sweepNumber: int):\n\"\"\"Detect all spikes in one sweep.\n\n         Populate bAnalysisResult.py.\n\n        Notes\n        -----\n        First spike in a sweep cannot have interval statistics like freq or isi\n\n        Parameters\n        ----------\n        sweepNumber : int\n        \"\"\"\n        dDict = self._detectionDict\n\n        # a list of dict of sanpy.bAnalysisResults.analysisResult (one dict per spike)\n        spikeDict = sanpy.bAnalysisResults.analysisResultList()\n\n        verbose = dDict[\"verbose\"]\n\n        #\n        self.fileLoader.setSweep(sweepNumber)\n        #\n\n        # in case dDict has new filter values\n        self._getFilteredRecording()\n\n        #\n        # spike detect\n        detectionType = dDict[\"detectionType\"]\n\n        # detect all spikes either with dvdt or mv\n        if detectionType == sanpy.bDetection.detectionTypes[\"mv\"].value:\n            # detect using mV threshold\n            spikeTimes, spikeErrorList = self._spikeDetect_vm(dDict, sweepNumber)\n\n            # TODO: get rid of this and replace with foot\n            # backup childish vm threshold\n            if dDict[\"doBackupSpikeVm\"]:\n                spikeTimes = self._backupSpikeVm(\n                    spikeTimes, sweepNumber, dDict[\"medianFilter\"]\n                )\n        elif detectionType == sanpy.bDetection.detectionTypes[\"dvdt\"].value:\n            # detect using dv/dt threshold AND min mV\n            spikeTimes, spikeErrorList = self._spikeDetect_dvdt(dDict, sweepNumber)\n        else:\n            logger.error(f'Unknown detection type \"{detectionType}\"')\n            return\n\n        #\n        # backup thrshold to zero crossing in dvdt\n        if 0:\n            tmp_window_ms = dDict[\"dvdtPreWindow_ms\"]\n            tmp_window_pnts = self.fileLoader.ms2Pnt_(tmp_window_ms)\n            spikeTimes = self._getFeet(spikeTimes, tmp_window_pnts)\n\n        #\n        # set up\n        sweepX = self.fileLoader.sweepX  # sweepNumber is not optional\n        filteredVm = self.fileLoader.sweepY_filtered  # sweepNumber is not optional\n        filteredDeriv = self.fileLoader.filteredDeriv\n        sweepC = self.fileLoader.sweepC\n\n        #\n        now = datetime.datetime.now()\n        dateStr = now.strftime(\"%Y%m%d\")\n        timeStr = now.strftime(\"%H:%M:%S\")\n        self.dateAnalyzed = dateStr\n\n        #\n        # look in a window after each threshold crossing to get AP peak\n        peakWindow_pnts = self.fileLoader.ms2Pnt_(dDict[\"peakWindow_ms\"])\n\n        #\n        # throw out spikes that have peak BELOW onlyPeaksAbove_mV\n        # throw out spikes that have peak ABOVE onlyPeaksBelow_mV\n        onlyPeaksAbove_mV = dDict[\"onlyPeaksAbove_mV\"]\n        onlyPeaksBelow_mV = dDict[\"onlyPeaksBelow_mV\"]\n        (\n            spikeTimes,\n            spikeErrorList,\n            newSpikePeakPnt,\n            newSpikePeakVal,\n        ) = sanpy.analysisUtil.throwOutAboveBelow(\n            filteredVm,\n            spikeTimes,\n            spikeErrorList,\n            peakWindow_pnts,\n            onlyPeaksAbove_mV=onlyPeaksAbove_mV,\n            onlyPeaksBelow_mV=onlyPeaksBelow_mV,\n        )\n\n        #\n        # small window to average Vm to calculate MDP (itself in a window before spike)\n        avgWindow_pnts = self.fileLoader.ms2Pnt_(dDict[\"avgWindow_ms\"])\n        avgWindow_pnts = math.floor(avgWindow_pnts / 2)\n\n        #\n        # for each spike\n        # numSpikes = len(spikeTimes)\n        for i, spikeTime in enumerate(spikeTimes):\n            # spikeTime units is ALWAYS points\n\n            # new, add a spike dict for this spike time\n            spikeDict.appendDefault()\n\n            # get the AP peak\n            peakPnt = newSpikePeakPnt[i]\n            peakVal = newSpikePeakVal[i]\n            peakSec = (newSpikePeakPnt[i] / self.fileLoader.dataPointsPerMs) / 1000\n\n            # create one spike dictionary\n            # spikeDict = OrderedDict() # use OrderedDict so Pandas output is in the correct order\n\n            # spikeDict[i]['isBad'] = False\n            spikeDict[i][\"analysisDate\"] = dateStr\n            spikeDict[i][\"analysisTime\"] = timeStr\n            spikeDict[i][\"analysisVersion\"] = sanpy.analysisVersion\n            spikeDict[i][\"interfaceVersion\"] = sanpy.interfaceVersion\n            spikeDict[i][\"file\"] = self.fileLoader.filename\n\n            spikeDict[i][\"detectionType\"] = detectionType\n\n            spikeDict[i][\"cellType\"] = dDict[\"cellType\"]\n            spikeDict[i][\"sex\"] = dDict[\"sex\"]\n            spikeDict[i][\"condition\"] = dDict[\"condition\"]\n\n            spikeDict[i][\"sweep\"] = sweepNumber\n\n            epoch = float(\"nan\")\n            epochLevel = float(\"nan\")\n            epochTable = self.fileLoader.getEpochTable(sweepNumber)\n            if epochTable is not None:\n                epoch = epochTable.findEpoch(spikeTime)\n                epochLevel = epochTable.getLevel(epoch)\n            spikeDict[i][\"epoch\"] = epoch\n            spikeDict[i][\"epochLevel\"] = epochLevel\n\n            # keep track of per sweep spike and total spike\n            spikeDict[i][\"sweepSpikeNumber\"] = i\n            spikeDict[i][\"spikeNumber\"] = self.numSpikes + i\n\n            spikeDict[i][\"include\"] = True\n\n            # todo: make this a byte encoding so we can have multiple user tyes per spike\n            spikeDict[i][\"userType\"] = 0  # One userType (int) that can have values\n\n            # using bAnalysisResults will already be []\n            spikeDict[i][\"errors\"] = []\n\n            # append existing spikeErrorList from spikeDetect_dvdt() or spikeDetect_mv()\n            tmpError = spikeErrorList[i]\n            if tmpError is not None and tmpError != np.nan:\n                spikeDict[i][\"errors\"].append(tmpError)  # tmpError is from:\n                if verbose:\n                    print(f\"  spike:{i} error:{tmpError}\")\n            #\n            # detection params\n            spikeDict[i][\"dvdtThreshold\"] = dDict[\"dvdtThreshold\"]\n            spikeDict[i][\"mvThreshold\"] = dDict[\"mvThreshold\"]\n            spikeDict[i][\"medianFilter\"] = dDict[\"medianFilter\"]\n            spikeDict[i][\"halfHeights\"] = dDict[\"halfHeights\"]\n\n            spikeDict[i][\"thresholdPnt\"] = spikeTime\n            spikeDict[i][\"thresholdSec\"] = (\n                spikeTime / self.fileLoader.dataPointsPerMs\n            ) / 1000\n            spikeDict[i][\"thresholdVal\"] = filteredVm[spikeTime]  # in vm\n            spikeDict[i][\"thresholdVal_dvdt\"] = filteredDeriv[\n                spikeTime\n            ]  # in dvdt, spikeTime is points\n\n            # TODO: revamp this for 'Plot FI' plugin\n            # spikeTime falls into wrong epoch for first fast spike\n            # DAC command at the precise spike point\n            # spikeDict[i]['dacCommand'] = sweepC[spikeTime]  # spikeTime is in points\n            # spikeDict[i]['dacCommand'] = sweepC[peakPnt]  # spikeTime is in points\n\n            spikeDict[i][\"peakPnt\"] = peakPnt\n            spikeDict[i][\"peakSec\"] = peakSec\n            spikeDict[i][\"peakVal\"] = peakVal\n\n            spikeDict[i][\"peakHeight\"] = (\n                spikeDict[i][\"peakVal\"] - spikeDict[i][\"thresholdVal\"]\n            )\n\n            tmpThresholdSec = spikeDict[i][\"thresholdSec\"]\n            spikeDict[i][\"timeToPeak_ms\"] = (peakSec - tmpThresholdSec) * 1000\n\n            # only append to spikeDict after we are done (accounting for spikes within a sweep)\n            # self.spikeDict.append(spikeDict)\n            # iIdx = len(self.spikeDict) - 1\n\n            iIdx = i\n\n            # todo: get rid of this\n            defaultVal = float(\"nan\")\n\n\"\"\"\n            # get pre/post spike minima\n            self.spikeDict[iIdx]['preMinPnt'] = None\n            self.spikeDict[iIdx]['preMinVal'] = defaultVal\n\n            # early diastolic duration\n            # 0.1 to 0.5 of time between pre spike min and spike time\n            self.spikeDict[iIdx]['preLinearFitPnt0'] = None\n            self.spikeDict[iIdx]['preLinearFitPnt1'] = None\n            self.spikeDict[iIdx]['earlyDiastolicDuration_ms'] = defaultVal # seconds between preLinearFitPnt0 and preLinearFitPnt1\n            self.spikeDict[iIdx]['preLinearFitVal0'] = defaultVal\n            self.spikeDict[iIdx]['preLinearFitVal1'] = defaultVal\n            # m,b = np.polyfit(x, y, 1)\n            self.spikeDict[iIdx]['earlyDiastolicDurationRate'] = defaultVal # fit of y=preLinearFitVal 0/1 versus x=preLinearFitPnt 0/1\n            self.spikeDict[iIdx]['lateDiastolicDuration'] = defaultVal #\n\n            self.spikeDict[iIdx]['preSpike_dvdt_max_pnt'] = None\n            self.spikeDict[iIdx]['preSpike_dvdt_max_val'] = defaultVal # in units mV\n            self.spikeDict[iIdx]['preSpike_dvdt_max_val2'] = defaultVal # in units dv/dt\n            self.spikeDict[iIdx]['postSpike_dvdt_min_pnt'] = None\n            self.spikeDict[iIdx]['postSpike_dvdt_min_val'] = defaultVal # in units mV\n            self.spikeDict[iIdx]['postSpike_dvdt_min_val2'] = defaultVal # in units dv/dt\n\n            self.spikeDict[iIdx]['isi_pnts'] = defaultVal # time between successive AP thresholds (thresholdSec)\n            self.spikeDict[iIdx]['isi_ms'] = defaultVal # time between successive AP thresholds (thresholdSec)\n            self.spikeDict[iIdx]['spikeFreq_hz'] = defaultVal # time between successive AP thresholds (thresholdSec)\n            self.spikeDict[iIdx]['cycleLength_pnts'] = defaultVal # time between successive MDPs\n            self.spikeDict[iIdx]['cycleLength_ms'] = defaultVal # time between successive MDPs\n\n            # Action potential duration (APD) was defined as the interval between the TOP and the subsequent MDP\n            #self.spikeDict[iIdx]['apDuration_ms'] = defaultVal\n            self.spikeDict[iIdx]['diastolicDuration_ms'] = defaultVal\n\n            # any number of spike widths\n            #print('spikeDetect__() appending widths list to spike iIdx:', iIdx)\n            # was this\n            #self.spikeDict[iIdx]['widths'] = []\n            # debug 20210929, self._getHalfWidth() will assign spikeDict[iIdx]['widths'] = []\n            for halfHeight in dDict['halfHeights']:\n                widthDict = {\n                    'halfHeight': halfHeight,\n                    'risingPnt': None,\n                    'risingVal': defaultVal,\n                    'fallingPnt': None,\n                    'fallingVal': defaultVal,\n                    'widthPnts': None,\n                    'widthMs': defaultVal\n                }\n                # was this\n                #spikeDict[iIdx]['widths_' + str(halfHeight)] = defaultVal\n                spikeDict[iIdx]['widths'].append(widthDict)\n            \"\"\"\n\n            #\n            mdp_ms = dDict[\"mdp_ms\"]\n            mdp_pnts = self.fileLoader.ms2Pnt_(mdp_ms)  # mdp_ms * self.dataPointsPerMs\n            mdp_pnts = int(mdp_pnts)\n\n            # pre spike min\n            # other algorithms look between spike[i-1] and spike[i]\n            # here we are looking in a predefined window\n            startPnt = spikeTimes[i] - mdp_pnts\n            if startPnt &lt; 0:\n                # logger.info('TODO: add an official warning, we went past 0 for pre spike mdp ms window')\n                startPnt = 0\n                # log error\n                errorType = \"Pre spike min under-run (mdp)\"\n                errorStr = \"Went past time 0 searching for pre-spike min\"\n                eDict = self._getErrorDict(\n                    i, spikeTimes[i], errorType, errorStr\n                )  # spikeTime is in pnts\n                spikeDict[iIdx][\"errors\"].append(eDict)\n                if verbose:\n                    print(f\"  spike:{iIdx} error:{eDict}\")\n\n            preRange = filteredVm[startPnt : spikeTimes[i]]  # EXCEPTION\n            try:\n                preMinPnt = np.argmin(preRange)\n            except ValueError as e:\n                # 20220926, happend when we have no scale and mdp_pnts=0\n                # print(f'xxx i:{i} mdp_pnts:{mdp_pnts} len:{len(filteredVm)} startPnt:{startPnt} spikeTimes[i]:{spikeTimes[i]}')\n                # 20220926, we really just want ot bail on this error\n                # lots of code below relies on this\n                # TODO: fix this mess\n                preMinPnt = startPnt\n                errorType = \"Pre spike min 0 (mdp)\"\n                errorStr = f\"Did not find preMinPnt mdp_pnts:{mdp_pnts} startPnt:{startPnt} spikeTimes[i]:{spikeTimes[i]}\"\n                eDict = self._getErrorDict(\n                    i, spikeTimes[i], errorType, errorStr\n                )  # spikeTime is in pnts\n                spikeDict[iIdx][\"errors\"].append(eDict)\n                if verbose:\n                    print(f\"  spike:{iIdx} error:{eDict}\")\n            if preMinPnt is not None:\n                preMinPnt += startPnt\n                # the pre min is actually an average around the real minima\n                avgRange = filteredVm[\n                    preMinPnt - avgWindow_pnts : preMinPnt + avgWindow_pnts\n                ]\n                preMinVal = np.average(avgRange)\n\n                # search backward from spike to find when vm reaches preMinVal (avg)\n                preRange = filteredVm[preMinPnt : spikeTimes[i]]\n                preRange = np.flip(preRange)  # we want to search backwards from peak\n                try:\n                    preMinPnt2 = np.where(preRange &lt; preMinVal)[0][0]\n                    preMinPnt = spikeTimes[i] - preMinPnt2\n                    spikeDict[iIdx][\"preMinPnt\"] = preMinPnt\n                    spikeDict[iIdx][\"preMinVal\"] = preMinVal\n\n                except IndexError as e:\n                    errorType = \"Pre spike min (mdp)\"\n                    errorStr = \"Did not find preMinVal: \" + str(\n                        round(preMinVal, 3)\n                    )  # + ' postRange min:' + str(np.min(postRange)) + ' max ' + str(np.max(postRange))\n                    eDict = self._getErrorDict(\n                        i, spikeTimes[i], errorType, errorStr\n                    )  # spikeTime is in pnts\n                    spikeDict[iIdx][\"errors\"].append(eDict)\n                    if verbose:\n                        print(f\"  spike:{iIdx} error:{eDict}\")\n\n            #\n            # The nonlinear late diastolic depolarization phase was\n            # estimated as the duration between 1% and 10% dV/dt\n            # linear fit on 10% - 50% of the time from preMinPnt to self.spikeTimes[i]\n            startLinearFit = 0.1  # percent of time between pre spike min and AP peak\n            stopLinearFit = 0.5  #\n            timeInterval_pnts = spikeTimes[i] - preMinPnt\n            # taking round() so we always get an integer # points\n            preLinearFitPnt0 = preMinPnt + round(timeInterval_pnts * startLinearFit)\n            preLinearFitPnt1 = preMinPnt + round(timeInterval_pnts * stopLinearFit)\n            preLinearFitVal0 = filteredVm[preLinearFitPnt0]\n            preLinearFitVal1 = filteredVm[preLinearFitPnt1]\n\n            # linear fit before spike\n            spikeDict[iIdx][\"preLinearFitPnt0\"] = preLinearFitPnt0\n            spikeDict[iIdx][\"preLinearFitPnt1\"] = preLinearFitPnt1\n            spikeDict[iIdx][\"earlyDiastolicDuration_ms\"] = self.fileLoader.pnt2Ms_(\n                preLinearFitPnt1 - preLinearFitPnt0\n            )\n            spikeDict[iIdx][\"preLinearFitVal0\"] = preLinearFitVal0\n            spikeDict[iIdx][\"preLinearFitVal1\"] = preLinearFitVal1\n\n            # a linear fit where 'm,b = np.polyfit(x, y, 1)'\n            # m*x+b\"\n            xFit = sweepX[preLinearFitPnt0:preLinearFitPnt1]  # abb added +1\n            yFit = filteredVm[preLinearFitPnt0:preLinearFitPnt1]\n\n            # sometimes xFit/yFit have 0 length --&gt;&gt; TypeError\n            # print(f' {iIdx} preLinearFitPnt0:{preLinearFitPnt0}, preLinearFitPnt1:{preLinearFitPnt1}')\n            # print(f'    xFit:{len(xFit)} yFit:{len(yFit)}')\n\n            # TODO: somehow trigger following errors to confirm code works (pytest)\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\"error\")\n                try:\n                    mLinear, bLinear = np.polyfit(\n                        xFit, yFit, 1\n                    )  # m is slope, b is intercept\n                    spikeDict[iIdx][\"earlyDiastolicDurationRate\"] = mLinear\n                    # todo: make an error if edd rate is too low\n                    lowestEddRate = dDict[\"lowEddRate_warning\"]  # 8\n                    if mLinear &lt;= lowestEddRate:\n                        errorType = \"Fit EDD\"\n                        errorStr = f\"Early diastolic duration rate fit - Too low {round(mLinear,3)}&lt;={lowestEddRate}\"\n                        eDict = self._getErrorDict(\n                            i, spikeTimes[i], errorType, errorStr\n                        )  # spikeTime is in pnts\n                        # print('fit edd start num error:', 'iIdx:', iIdx, 'num error:', len(spikeDict[iIdx]['errors']))\n                        spikeDict[iIdx][\"errors\"].append(eDict)\n                        # print('  after num error:', len(spikeDict[iIdx]['errors']))\n                        if verbose:\n                            print(f\"  spike:{iIdx} error:{eDict}\")\n\n                except TypeError as e:\n                    # catching exception:  expected non-empty vector for x\n                    # xFit/yFit turn up empty when mdp and TOP points are within 1 point\n                    spikeDict[iIdx][\"earlyDiastolicDurationRate\"] = defaultVal\n                    errorType = \"Fit EDD\"\n                    # errorStr = 'Early diastolic duration rate fit - TypeError'\n                    errorStr = (\n                        \"Early diastolic duration rate fit - preMinPnt == spikePnt\"\n                    )\n                    eDict = self._getErrorDict(i, spikeTimes[i], errorType, errorStr)\n                    spikeDict[iIdx][\"errors\"].append(eDict)\n                    if verbose:\n                        print(f\"  spike:{iIdx} error:{eDict}\")\n                except np.RankWarning as e:\n                    # logger.error('== FIX preLinearFitPnt0/preLinearFitPnt1 RankWarning')\n                    # logger.error(f'  error is: {e}')\n                    # print('RankWarning')\n                    # also throws: RankWarning: Polyfit may be poorly conditioned\n                    spikeDict[iIdx][\"earlyDiastolicDurationRate\"] = defaultVal\n                    errorType = \"Fit EDD\"\n                    errorStr = \"Early diastolic duration rate fit - RankWarning\"\n                    eDict = self._getErrorDict(i, spikeTimes[i], errorType, errorStr)\n                    spikeDict[iIdx][\"errors\"].append(eDict)\n                    if verbose:\n                        print(f\"  spike:{iIdx} error:{eDict}\")\n                # 20230422, don't ever catch an unknown exception\n                # except:\n                #     logger.error(\n                #         f\" !!!!!!!!!!!!!!!!!!!!!!!!!!! UNKNOWN EXCEPTION DURING EDD LINEAR FIT for spike {i}\"\n                #     )\n                #     spikeDict[iIdx][\"earlyDiastolicDurationRate\"] = defaultVal\n                #     errorType = \"Fit EDD\"\n                #     errorStr = \"Early diastolic duration rate fit - Unknown Exception\"\n                #     eDict = self._getErrorDict(i, spikeTimes[i], errorType, errorStr)\n                #     if verbose:\n                #         print(f\"  spike:{iIdx} error:{eDict}\")\n\n            # not implemented\n            # self.spikeDict[i]['lateDiastolicDuration'] = ???\n\n            #\n            # maxima in dv/dt before spike (between TOP and peak)\n            try:\n                preRange = filteredDeriv[spikeTimes[i] : peakPnt + 1]\n                preSpike_dvdt_max_pnt = np.argmax(preRange)\n                preSpike_dvdt_max_pnt += spikeTimes[i]\n                spikeDict[iIdx][\"preSpike_dvdt_max_pnt\"] = preSpike_dvdt_max_pnt\n                spikeDict[iIdx][\"preSpike_dvdt_max_val\"] = filteredVm[\n                    preSpike_dvdt_max_pnt\n                ]  # in units mV\n                spikeDict[iIdx][\"preSpike_dvdt_max_val2\"] = filteredDeriv[\n                    preSpike_dvdt_max_pnt\n                ]  # in units mV\n            except ValueError as e:\n                # sometimes preRange is empty, don't try and put min/max in error\n                errorType = \"Pre Spike dvdt\"\n                errorStr = \"Searching for dvdt max - ValueError\"\n                eDict = self._getErrorDict(\n                    i, spikeTimes[i], errorType, errorStr\n                )  # spikeTime is in pnts\n                spikeDict[iIdx][\"errors\"].append(eDict)\n                if verbose:\n                    print(f\"  spike:{iIdx} error:{eDict}\")\n\n            #\n            # minima in dv/dt after spike\n            # postRange = dvdt[self.spikeTimes[i]:postMinPnt]\n            # postSpike_ms = 20 # 10\n            # postSpike_pnts = self.ms2Pnt_(postSpike_ms)\n            dvdtPostWindow_ms = dDict[\"dvdtPostWindow_ms\"]\n            dvdtPostWindow_pnts = self.fileLoader.ms2Pnt_(dvdtPostWindow_ms)\n            postRange = filteredDeriv[\n                peakPnt : peakPnt + dvdtPostWindow_pnts\n            ]  # fixed window after spike\n\n            postSpike_dvdt_min_pnt = np.argmin(postRange)\n            postSpike_dvdt_min_pnt += peakPnt\n            spikeDict[iIdx][\"postSpike_dvdt_min_pnt\"] = postSpike_dvdt_min_pnt\n            spikeDict[iIdx][\"postSpike_dvdt_min_val\"] = filteredVm[\n                postSpike_dvdt_min_pnt\n            ]\n            spikeDict[iIdx][\"postSpike_dvdt_min_val2\"] = filteredDeriv[\n                postSpike_dvdt_min_pnt\n            ]\n\n            #\n            # diastolic duration was defined as the interval between MDP and TOP\n            # one off error when preMinPnt is not defined\n            spikeDict[iIdx][\"diastolicDuration_ms\"] = self.fileLoader.pnt2Ms_(\n                spikeTime - preMinPnt\n            )\n\n            #\n            # calculate instantaneous spike frequency and ISI, for first spike this is not defined\n            spikeDict[iIdx][\"cycleLength_ms\"] = float(\"nan\")\n            if iIdx &gt; 0:\n                isiPnts = (\n                    spikeDict[iIdx][\"thresholdPnt\"]\n                    - spikeDict[iIdx - 1][\"thresholdPnt\"]\n                )\n                isi_ms = self.fileLoader.pnt2Ms_(isiPnts)\n                isi_hz = 1 / (isi_ms / 1000)\n                spikeDict[iIdx][\"isi_pnts\"] = isiPnts\n                spikeDict[iIdx][\"isi_ms\"] = self.fileLoader.pnt2Ms_(isiPnts)\n                spikeDict[iIdx][\"spikeFreq_hz\"] = 1 / (\n                    self.fileLoader.pnt2Ms_(isiPnts) / 1000\n                )\n\n                # Cycle length was defined as the interval between MDPs in successive APs\n                prevPreMinPnt = spikeDict[iIdx - 1][\"preMinPnt\"]  # can be nan\n                thisPreMinPnt = spikeDict[iIdx][\"preMinPnt\"]\n                if prevPreMinPnt is not None and thisPreMinPnt is not None:\n                    cycleLength_pnts = thisPreMinPnt - prevPreMinPnt\n                    spikeDict[iIdx][\"cycleLength_pnts\"] = cycleLength_pnts\n                    spikeDict[iIdx][\"cycleLength_ms\"] = self.fileLoader.pnt2Ms_(\n                        cycleLength_pnts\n                    )\n                else:\n                    # error\n                    prevPreMinSec = self.fileLoader.pnt2Sec_(prevPreMinPnt)\n                    thisPreMinSec = self.fileLoader.pnt2Sec_(thisPreMinPnt)\n                    # errorStr = f'Previous spike preMinPnt is {prevPreMinPnt} and this preMinPnt: {thisPreMinPnt}'\n                    errorType = \"Cycle Length\"\n                    errorStr = f\"Previous spike preMinPnt (s) is {prevPreMinSec} and this preMinPnt: {thisPreMinSec}\"\n                    eDict = self._getErrorDict(\n                        i, spikeTimes[i], errorType, errorStr\n                    )  # spikeTime is in pnts\n                    spikeDict[iIdx][\"errors\"].append(eDict)\n                    if verbose:\n                        print(f\"  spike:{iIdx} error:{eDict}\")\n\n            #\n            # TODO: Move half-width to a function !!!\n            #\n            hwWindowPnts = dDict[\"halfWidthWindow_ms\"] * self.fileLoader.dataPointsPerMs\n            hwWindowPnts = round(hwWindowPnts)\n            halfHeightList = dDict[\"halfHeights\"]\n            # was this\n            # self._getHalfWidth(filteredVm, i, iIdx, spikeTime, peakPnt, hwWindowPnts, self.dataPointsPerMs, halfHeightList)\n            self._getHalfWidth(\n                filteredVm,\n                iIdx,\n                spikeDict,\n                spikeTime,\n                peakPnt,\n                hwWindowPnts,\n                self.fileLoader.dataPointsPerMs,\n                halfHeightList,\n                verbose=verbose,\n            )\n\n        #\n        # look between threshold crossing to get minima\n        # we will ignore the first and last spike\n\n        #\n        # spike clips\n        self.spikeClips = None\n        self.spikeClips_x = None\n        self.spikeClips_x2 = None\n\n        # SUPER important, previously our self.spikeDict was simple list of dict\n        # now it is a list of class xxx\n        # print('=== addind', len(spikeDict))\n        self.spikeDict.appendAnalysis(spikeDict)\n        # print('   now have', len(self.spikeDict))\n        # print(self.spikeDict)\n\n        # keep track of spikes per sweep (expensive to calculate)\n        # self._spikesPerSweep[sweepNumber] = len(spikeDict)\n\n        # run all user analysis ... what if this fails ???\n        sanpy.user_analysis.baseUserAnalysis.runAllUserAnalysis(self)\n\n        #\n        # generate a df holding stats (used by scatterplotwidget)\n        # startSeconds = dDict['startSeconds']\n        # stopSeconds = dDict['stopSeconds']\n        if self.numSpikes &gt; 0:\n            # exportObject = sanpy.bExport(self)\n            # self.dfReportForScatter = exportObject.report(startSeconds, stopSeconds)\n            self._dfReportForScatter = self.spikeDict.asDataFrame()\n        else:\n            self.dfReportForScatter = None\n\n        # generate error report\n        self.dfError = self.getErrorReport()\n\n        # bAnalysis needs to be saved\n        self._detectionDirty = True\n\n        ## done\n\n    def _getFeet(self, thresholdPnts: List[int], prePnts: int) -&gt; List[int]:\n\"\"\"\n\n        Args:\n            thresholdPnts (list of int)\n            prePnts (int): pre point window to search for zero crossing\n\n        Notes:\n            Will need to calculate new (height, half widths)\n        \"\"\"\n\n        # prePnts = int(prePnts)\n\n        logger.info(f\"num thresh:{len(thresholdPnts)} prePnts:{prePnts}\")\n\n        # df = self.asDataFrame()\n        # peaks = df['peakVal']\n        # thresholdPnts = df['thresholdPnt']\n\n        verbose = self._detectionDict[\"verbose\"]\n\n        # using the derivstive to find zero crossing before\n        # original full width left point\n        # TODO: USer self.filteredDeriv\n        # yFull = self.filteredVm\n        # yDiffFull = np.diff(yFull)\n        # yDiffFull = np.insert(yDiffFull, 0, np.nan)\n        yDiffFull = self.fileLoader.filteredDeriv\n\n        secondDeriv = np.diff(yDiffFull, axis=0)\n        secondDeriv = np.insert(secondDeriv, 0, np.nan)\n\n        n = len(thresholdPnts)\n        footPntList = [None] * n\n        footSec = [None] * n  # not used\n        yFoot = [None] * n  # not used\n        # myHeight = []\n\n        # todo: add this to bAnalysis\n        # preMs = self._detectionParams['preFootMs']\n        # prePnts = self._sec2Pnt(preMs/1000)\n\n        # TODO: add to bDetection\n        logger.warning(\"ADD preMs AS PARAMETER !!!\")\n        # preWinMs = 50  # sa-node\n        # prePnts = self.ms2Pnt_(preMs)\n\n        for idx, footPnt in enumerate(thresholdPnts):\n            # footPnt = round(footPnt)  # footPnt is in fractional points\n            lastCrossingPnt = footPnt\n            # move forwared a bit in case we are already in a local minima ???\n            logger.warning(\"REMOVED WHEN WORKING ON NEURON DETECTION\")\n            footPnt += 2  # TODO: add as param\n            preStart = footPnt - prePnts\n            preClip = yDiffFull[preStart:footPnt]\n\n            zero_crossings = np.where(np.diff(np.sign(preClip)))[\n                0\n            ]  # find where derivative flips sign (crosses 0)\n            xLastCrossing = self.fileLoader.pnt2Sec_(footPnt)  # defaults\n            yLastCrossing = self.fileLoader.sweepY_filtered[footPnt]\n            if len(zero_crossings) == 0:\n                if verbose:\n                    tmpSec = round(self.fileLoader.pnt2Sec_(footPnt), 3)\n                    logger.error(\n                        f\"  no foot for peak {idx} at sec {tmpSec} ... did not find zero crossings\"\n                    )\n            else:\n                # print(idx, 'footPnt:', footPnt, zero_crossings, preClip)\n                lastCrossingPnt = preStart + zero_crossings[-1]\n                xLastCrossing = self.fileLoader.pnt2Sec_(lastCrossingPnt)\n                # get y-value (pA) from filtered. This removes 'pops' in raw data\n                yLastCrossing = self.fileLoader.sweepY_filtered[lastCrossingPnt]\n\n            # find peak in second derivative\n\"\"\"\n            preStart2 = lastCrossingPnt\n            footMs2 = 20\n            footPnt2 = preStart2 + self.ms2Pnt_(footMs2)\n            preClip2 = secondDeriv[preStart2:footPnt2]\n            #zero_crossings = np.where(np.diff(np.sign(preClip2)))[0]\n            peakPnt2 = np.argmax(preClip2)\n            peakPnt2 += preStart2\n\n            #\n            footPntList[idx] = peakPnt2\n            \"\"\"\n\n            footPntList[idx] = lastCrossingPnt  # was this and worked, a bit too early\n\n            footSec[idx] = xLastCrossing\n            yFoot[idx] = yLastCrossing\n\n\"\"\"\n            peakPnt = df.loc[idx, 'peak_pnt']\n            peakVal = self.sweepY_filtered[peakPnt]\n            height = peakVal - yLastCrossing\n            #print(f'idx {idx} {peakPnt} {peakVal} - {yLastCrossing} = {height}')\n            myHeight[idx] = (height)\n            \"\"\"\n\n        #\n        # df =self._analysisList[self._analysisIdx]['results_full']\n\"\"\"\n        df['foot_pnt'] = footPntList  # sec\n        df['foot_sec'] = footSec  # sec\n        df['foot_val'] = yFoot  # pA\n        \"\"\"\n        # df['myHeight'] = myHeight\n\n        # return footPntList, footSec, yFoot\n        return footPntList\n\n    def printSpike(self, idx):\n\"\"\"\n        Print values in one spike analysis using self.spikeDict (sanpy.bAnalysisResults).\n        \"\"\"\n        spike = self.spikeDict[idx]\n        for k, v in spike.items():\n            if k == \"widths\":\n                widths = v\n                print(f\"  spike:{idx} has {len(widths)} widths...\")\n                for wIdx, width in enumerate(widths):\n                    print(f\"    spike:{idx} width:{wIdx}: {width}\")\n            elif k == \"errors\":\n                errors = v\n                print(f\"  spike:{idx} has {len(errors)} errors...\")\n                for eIdx, error in enumerate(errors):\n                    print(f\"    spike:{idx} error #:{eIdx}: {error}\")\n            else:\n                print(f\"{k}: {v}\")\n\n    def printErrors(self):\n        for idx, spike in enumerate(self.spikeDict):\n            print(f\"spike {idx} has {len(spike['errors'])} errors\")\n            for eIdx, error in enumerate(spike[\"errors\"]):\n                print(f\"  error # {eIdx} is: {error}\")\n\n    def _makeSpikeClips(\n        self,\n        preSpikeClipWidth_ms,\n        postSpikeClipWidth_ms=None,\n        theseTime_sec=None,\n        sweepNumber=None,\n        epochNumber='All'\n    ):\n\"\"\"\n        (Internal) Make small clips for each spike.\n\n        Args:\n            preSpikeClipWidth_ms (int): Width of each spike clip in milliseconds.\n            postSpikeClipWidth_ms (int): Width of each spike clip in milliseconds.\n            theseTime_sec (list of float): [NOT USED] List of seconds to make clips from.\n\n        Returns:\n            spikeClips_x2: ms\n            self.spikeClips (list): List of spike clips\n        \"\"\"\n\n        verbose = self._detectionDict[\"verbose\"]\n\n        if preSpikeClipWidth_ms is None:\n            preSpikeClipWidth_ms = self._detectionDict[\"preSpikeClipWidth_ms\"]\n        if postSpikeClipWidth_ms is None:\n            postSpikeClipWidth_ms = self._detectionDict[\"postSpikeClipWidth_ms\"]\n\n        if sweepNumber is None:\n            sweepNumber = \"All\"\n\n        # print('makeSpikeClips() spikeClipWidth_ms:', spikeClipWidth_ms, 'theseTime_sec:', theseTime_sec)\n        if theseTime_sec is None:\n            theseTime_pnts = self.getSpikeTimes(sweepNumber=sweepNumber, epochNumber=epochNumber)\n        else:\n            # convert theseTime_sec to pnts\n            theseTime_ms = [x * 1000 for x in theseTime_sec]\n            theseTime_pnts = [x * self.fileLoader.dataPointsPerMs for x in theseTime_ms]\n            theseTime_pnts = [round(x) for x in theseTime_pnts]\n\n        preClipWidth_pnts = self.fileLoader.ms2Pnt_(preSpikeClipWidth_ms)\n        # if preClipWidth_pnts % 2 == 0:\n        #    pass # Even\n        # else:\n        #    clipWidth_pnts += 1 # Make odd even\n        postClipWidth_pnts = self.fileLoader.ms2Pnt_(postSpikeClipWidth_ms)\n\n        # halfClipWidth_pnts = int(clipWidth_pnts/2)\n\n        # print('  makeSpikeClips() clipWidth_pnts:', clipWidth_pnts, 'halfClipWidth_pnts:', halfClipWidth_pnts)\n        # make one x axis clip with the threshold crossing at 0\n        # was this, in ms\n        # self.spikeClips_x = [(x-halfClipWidth_pnts)/self.dataPointsPerMs for x in range(clipWidth_pnts)]\n\n        # in ms\n        self.spikeClips_x = [\n            (x - preClipWidth_pnts) / self.fileLoader.dataPointsPerMs\n            for x in range(preClipWidth_pnts)\n        ]\n        self.spikeClips_x += [\n            (x) / self.fileLoader.dataPointsPerMs for x in range(postClipWidth_pnts)\n        ]\n\n        # 20190714, added this to make all clips same length, much easier to plot in MultiLine\n        numPointsInClip = len(self.spikeClips_x)\n\n        self.spikeClips = []\n        self.spikeClips_x2 = []\n\n        sweepY = self.fileLoader.sweepY_filtered\n\n        # when there are no spikes getStat() will not return anything\n        # For 'All' sweeps, we need to know column\n        sweepNum = self.getStat(\"sweep\", sweepNumber=sweepNumber)\n\n        # logger.info(f'sweepY: {sweepY.shape} {len(sweepY.shape)}')\n        # logger.info(f'theseTime_pnts: {theseTime_pnts}')\n\n        for idx, spikeTime in enumerate(theseTime_pnts):\n            sweep = sweepNum[idx]\n\n            if len(sweepY.shape) == 1:\n                # 1D case where recording has only oone sweep\n                # currentClip = sweepY[spikeTime-halfClipWidth_pnts:spikeTime+halfClipWidth_pnts]\n                currentClip = sweepY[\n                    spikeTime - preClipWidth_pnts : spikeTime + postClipWidth_pnts\n                ]\n            else:\n                # 2D case where recording has multiple sweeps\n                # currentClip = sweepY[spikeTime-halfClipWidth_pnts:spikeTime+halfClipWidth_pnts, sweep]\n                try:\n                    currentClip = sweepY[\n                        spikeTime - preClipWidth_pnts : spikeTime + preClipWidth_pnts,\n                        sweep,\n                    ]\n                except IndexError as e:\n                    logger.error(e)\n                    print(f\"sweep: {sweep}\")\n                    print(f\"sweepY.shape: {sweepY.shape}\")\n\n            if len(currentClip) == numPointsInClip:\n                self.spikeClips.append(currentClip)\n                self.spikeClips_x2.append(\n                    self.spikeClips_x\n                )  # a 2D version to make pyqtgraph multiline happy\n            else:\n                # pass\n                if verbose:\n                    logger.warning(\n                        f\"Did not add clip for spike index: {idx} at time: {spikeTime} len(currentClip): {len(currentClip)} != numPointsInClip: {numPointsInClip}\"\n                    )\n\n        #\n        return self.spikeClips_x2, self.spikeClips\n\n    def getSpikeClips(\n        self,\n        theMin,\n        theMax,\n        spikeSelection=[],\n        preSpikeClipWidth_ms=None,\n        postSpikeClipWidth_ms=None,\n        sweepNumber=None,\n        epochNumber='All',\n        ignoreMinMax=False  # added 20230418\n    ):\n\"\"\"Get 2d list of spike clips, spike clips x, and 1d mean spike clip.\n\n        Args:\n            theMin (float): Start seconds.\n            theMax (float): Stop seconds.\n            spikeSelection (list): List of spike numbers\n            preSpikeClipWidth_ms (float):\n            postSpikeClipWidth_ms (float):\n\n        Requires: self.spikeDetect() and self._makeSpikeClips()\n\n        Returns:\n            theseClips (list): List of clip\n            theseClips_x (list): ms\n            meanClip (list)\n        \"\"\"\n\n        if self.numSpikes == 0:\n            return\n\n        doSpikeSelection = len(spikeSelection) &gt; 0\n\n        if doSpikeSelection:\n            pass\n        elif theMin is None or theMax is None:\n            theMin = 0\n            theMax = self.fileLoader.recordingDur  # self.sweepX[-1]\n\n        # new interface, spike detect no longer auto generates these\n        # need to do this every time because we get here when sweepNumber changes\n        # if self.spikeClips is None:\n        #    self._makeSpikeClips(spikeClipWidth_ms=spikeClipWidth_ms, sweepNumber=sweepNumber)\n        # TODO: don't make all clips\n        # self._makeSpikeClips(spikeClipWidth_ms=spikeClipWidth_ms, sweepNumber=sweepNumber)\n        self._makeSpikeClips(\n            preSpikeClipWidth_ms=preSpikeClipWidth_ms,\n            postSpikeClipWidth_ms=postSpikeClipWidth_ms,\n            sweepNumber=sweepNumber,\n            epochNumber=epochNumber\n        )\n\n        # make a list of clips within start/stop (Seconds)\n        theseClips = []\n        theseClips_x = []\n        tmpMeanClips = []  # for mean clip\n        meanClip = []\n\n        # spikeTimes are in pnts\n        spikeTimes = self.getSpikeTimes(sweepNumber=sweepNumber, epochNumber=epochNumber)\n\n        logger.info(f'spikeTimes:{len(spikeTimes)} sweepNumber:{sweepNumber} epochNumber:{epochNumber}')\n\n        # if len(spikeTimes) != len(self.spikeClips):\n        #    logger.error(f'len spikeTimes {len(spikeTimes)} !=  spikeClips {len(self.spikeClips)}')\n\n        # self.spikeClips is a list of clips\n        for idx, clip in enumerate(self.spikeClips):\n            doThisSpike = False\n            if doSpikeSelection:\n                doThisSpike = idx in spikeSelection\n            else:\n                spikeTime = spikeTimes[idx]\n                spikeTime = self.fileLoader.pnt2Sec_(spikeTime)\n                if ignoreMinMax or (spikeTime &gt;= theMin and spikeTime &lt;= theMax):\n                    doThisSpike = True\n            if doThisSpike:\n                theseClips.append(clip)\n                theseClips_x.append(\n                    self.spikeClips_x2[idx]\n                )  # remember, all _x are the same\n                if len(self.spikeClips_x) == len(clip):\n                    tmpMeanClips.append(clip)  # for mean clip\n        if len(tmpMeanClips):\n            meanClip = np.mean(tmpMeanClips, axis=0)\n\n        return theseClips, theseClips_x, meanClip\n\n    # def numErrors(self):\n    #     if self.dfError is None:\n    #         return \"N/A\"\n    #     else:\n    #         return len(self.dfError)\n\n    def getErrorReport(self):\n\"\"\"Generate an error report, one row per error.\n\n        Spikes can have more than one error.\n\n        Returns:\n            (pandas DataFrame): Pandas DataFrame, one row per error.\n        \"\"\"\n\n        dictList = []\n\n        # numError = 0\n        # errorList = []\n\n        logger.info(f'Generating error report for {len(self.spikeDict)} spikes')\n\n        #  20230422 spikeDict is not working as an iterable\n        # use it as a list instead\n        numSpikes = len(self.spikeDict)\n        #for spike in self.spikeDict:\n        for _spikeNumber in range(numSpikes):\n            spike = self.spikeDict[_spikeNumber]\n            # spike is sanpy.bAnalysisResults.analysisResult\n            #print('spike:', spike)\n            for error in spike[\"errors\"]:\n                # spike[\"errors\"] is a list of dict\n                # error is dict from _getErrorDict\n                if error is None or error == np.nan or error == \"nan\":\n                    continue\n\n                # 20230422 add sweep and epoch to error dict\n                #_spikeNumber = error['Spike']\n\n                #print('  _spikeNumber:', _spikeNumber, type(_spikeNumber))\n\n                # _sweep = self.getSpikeStat([_spikeNumber], 'sweep')\n                # if len(_sweep)==0:\n                #     logger.error(f\"_spikeNumber:{_spikeNumber} sweep:{_sweep}\")\n                #     #print(self.getOneSpikeDict(_spikeNumber))\n\n                error['Sweep'] = self.getSpikeStat([_spikeNumber], 'sweep')[0]\n                error['Epoch'] = self.getSpikeStat([_spikeNumber], 'epoch')[0]\n\n                dictList.append(error)\n\n        if len(dictList) == 0:\n            fakeErrorDict = self._getErrorDict(1, 1, \"fake\", \"fake\")\n            dfError = pd.DataFrame(columns=fakeErrorDict.keys())\n        else:\n            dfError = pd.DataFrame(dictList)\n\n        if self._detectionDict[\"verbose\"]:\n            logger.info(f\"Found {len(dfError)} errors in spike detection\")\n\n        return dfError\n\n    def _old_to_csv(self):\n\"\"\"Save as a CSV text file with name &lt;path&gt;_analysis.csv'\"\"\"\n        savefile = os.path.splitext(self._path)[0]\n        savefile += \"_analysis.csv\"\n        saveExcel = False\n        alsoSaveTxt = True\n        logger.info(f'Saving \"{savefile}\"')\n\n        be = sanpy.bExport(self)\n        be.saveReport(savefile, saveExcel=saveExcel, alsoSaveTxt=alsoSaveTxt)\n\n    def _normalizeData(self, data):\n\"\"\"Calculate normalized data for detection from Kymograph. Is NOT for df/d0.\"\"\"\n        return (data - np.min(data)) / (np.max(data) - np.min(data))\n\n    def _not_used_loadAnalysis(self):\n\"\"\"Not used.\"\"\"\n        saveBase = self._getSaveBase()\n\n        # load detection parameters\n        # self.detectionClass.load(saveBase)\n\n        # load analysis\n        # self.spikeDict.load(saveBase)\n\n        saveBase = self._getSaveBase()\n        savePath = saveBase + \"-analysis.json\"\n\n        if not os.path.isfile(savePath):\n            # logger.error(f'Did not find file: {savePath}')\n            return\n\n        logger.info(f\"Loading from saved analysis: {savePath}\")\n\n        with open(savePath, \"r\") as f:\n            # self._dDict = json.load(f)\n            loadedDict = json.load(f)\n\n        dDict = loadedDict[\"detection\"]\n        self.detectionClass._dDict = dDict\n\n        analysisList = loadedDict[\"analysis\"]\n        self.spikeDict._myList = analysisList\n\n        self._detectionDirty = False\n        self._isAnalyzed = True\n\n    def saveAnalysis_tocsv(self):\n\"\"\"Save analysis to csv.\"\"\"\n        df = self.asDataFrame()  # pd.DataFrame(self.spikeDict)\n\n        saveFolder = self._getSaveFolder()\n        if not os.path.isdir(saveFolder):\n            logger.info(f\"making folder: {saveFolder}\")\n            os.mkdir(saveFolder)\n\n        saveBase = self._getSaveBase()\n        savePath = saveBase + \"-analysis.csv\"\n\n        logger.info(savePath)\n\n        df.to_csv(savePath)\n\n    def saveAnalysis(self, forceSave=False):\n\"\"\"Not used.\n\n        Save detection parameters and analysis results as json.\n        \"\"\"\n        if not self._detectionDirty and not forceSave:\n            return\n\n        saveFolder = self._getSaveFolder()\n        if not os.path.isdir(saveFolder):\n            logger.info(f\"making folder: {saveFolder}\")\n            os.mkdir(saveFolder)\n\n        saveBase = self._getSaveBase()\n        savePath = saveBase + \"-analysis.json\"\n\n        # save detection parameters\n        # self.detectionClass.save(saveBase)\n        dDict = self.detectionClass.getDict()\n\n        saveDict = {}\n        saveDict[\"detection\"] = dDict\n\n        # save list of dict\n        # self.spikeDict = sanpy.bAnalysisResults.analysisResultList()\n        # self.spikeDict.save(saveBase)\n        analysisList = self.spikeDict.asList()\n\n        saveDict[\"analysis\"] = analysisList\n\n        with open(savePath, \"w\") as f:\n            json.dump(saveDict, f, cls=NumpyEncoder, indent=4)\n\n        self._detectionDirty = False\n\n        logger.info(f\"Saved analysis to: {savePath}\")\n\n    def _getSaveFolder(self):\n\"\"\"\n        All analysis will be saved in folder 'sanpy_analysis'\n        \"\"\"\n        parentPath, fileName = os.path.split(self._path)\n        saveFolder = os.path.join(parentPath, \"sanpy_analysis\")\n        return saveFolder\n\n    def _getSaveBase(self):\n\"\"\"\n        Return basename to append to to save\n\n        This will always be in a subfolder named 'sanpy_analysis'\n\n        For example, bDetection uses this to save &lt;base&gt;-detection.json\n        \"\"\"\n        saveFolder = self._getSaveFolder()\n\n        parentPath, fileName = os.path.split(self._path)\n        baseName = os.path.splitext(fileName)[0]\n        savePath = os.path.join(saveFolder, baseName)\n\n        return savePath\n\n    @property\n    def analysisDate(self):\n        if self.spikeDict is not None:\n            return self.spikeDict.analysisDate()\n\n    @property\n    def analysisTime(self):\n        if self.spikeDict is not None:\n            return self.spikeDict.analysisTime()\n\n    def _api_getHeader(self):\n\"\"\"Get header as a dict.\n\n        TODO:\n            - add info on abf file, like samples per ms\n\n        Returns:\n            dict: Dictionary of information about loaded file.\n        \"\"\"\n        # recordingDir_sec = len(self.sweepX) / self.dataPointsPerMs / 1000\n        recordingFrequency = self.dataPointsPerMs\n\n        ret = {\n            \"myFileType\": self.myFileType,  # ('abf', 'tif', 'bytestream', 'csv')\n            \"loadError\": self.loadError,\n            #'detectionDict': self.detectionClass,\n            \"path\": self._path,\n            \"file\": self.fileLoader.filename,\n            \"dateAnalyzed\": self.dateAnalyzed,\n            #'detectionType': self.detectionType,\n            \"acqDate\": self.acqDate,\n            \"acqTime\": self.acqTime,\n            #\n            \"_recordingMode\": self._recordingMode,\n            \"get_yUnits\": self.get_yUnits(),\n            #'currentSweep': self.currentSweep,\n            \"recording_kHz\": recordingFrequency,\n            \"recordingDur_sec\": self.recordingDur,\n        }\n        return ret\n\n    def _api_getSpikeInfo(self, spikeNum=None):\n\"\"\"Get info about each spike.\n\n        Args:\n            spikeNum (int): Get info for one spike, None for all spikes.\n\n        Returns:\n            list: List of dict with info for all (one) spike.\n        \"\"\"\n        if spikeNum is not None:\n            ret = [self.spikeDict[spikeNum]]\n        else:\n            ret = self.spikeDict\n        return ret\n\n    def _api_getSpikeStat(self, stat):\n\"\"\"Get stat for each spike\n\n        Args:\n            stat (str): The name of the stat to get. Corresponds to key in self.spikeDict[i].\n\n        Returns:\n            list: List of values for 'stat'. Ech value is for one spike.\n        \"\"\"\n        statList = self.getStat(statName1=stat, statName2=None)\n        return statList\n\n    def _api_getRecording(self):\n\"\"\"Return primary recording\n\n        Returns:\n            dict: {'header', 'sweepX', 'sweepY'}\n\n        TODO:\n            Add param to only get every n'th point, to return a subset faster (for display)\n        \"\"\"\n        # start = time.time()\n        ret = {\n            \"header\": self.api_getHeader(),\n            \"sweepX\": self.sweepX2.tolist(),\n            \"sweepY\": self.sweepY2.tolist(),\n        }\n        # stop = time.time()\n        # print(stop-start)\n        return ret\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis-attributes","title":"Attributes","text":""},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.dateAnalyzed","title":"<code>dateAnalyzed: str = None</code>  <code>instance-attribute</code>","text":"<p>str: Date Time of analysis. TODO: make a property.</p>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.loadError","title":"<code>loadError: bool = False</code>  <code>instance-attribute</code>","text":"<p>bool: True if error loading file/stream.</p>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.numErrors","title":"<code>numErrors: int</code>  <code>property</code>","text":"<p>Get number of detection errors.</p>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.numSpikes","title":"<code>numSpikes</code>  <code>property</code>","text":"<p>Get the total number of detected spikes (all sweeps).</p> <p>See getNumSpikes(sweep)</p>"},{"location":"api/bAnalysis/#sanpy.bAnalysis-functions","title":"Functions","text":""},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.__init__","title":"<code>__init__(filepath=None, byteStream=None, loadData=True, fileLoaderDict=None, stimulusFileFolder=None, verbose=False)</code>","text":"<p>Args:     filepath (str): Path to either .abf or .csv with time/mV columns.     byteStream (io.BytesIO): Binary stream for use in the cloud.     loadData: If true, load raw data, otherwise just load header     fileLoaderDict (dict)         If None then fetch from sanpy.fileloaders.getFileLoaders()         Do this if running in a script.         If running an SanPy app, we pass the dict     stimulusFileFolder:</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def __init__(\n    self,\n    filepath: str = None,\n    byteStream=None,\n    loadData: bool = True,\n    fileLoaderDict: dict = None,\n    stimulusFileFolder: str = None,\n    verbose: bool = False,\n):\n\"\"\"\n    Args:\n        filepath (str): Path to either .abf or .csv with time/mV columns.\n        byteStream (io.BytesIO): Binary stream for use in the cloud.\n        loadData: If true, load raw data, otherwise just load header\n        fileLoaderDict (dict)\n            If None then fetch from sanpy.fileloaders.getFileLoaders()\n            Do this if running in a script.\n            If running an SanPy app, we pass the dict\n        stimulusFileFolder:\n    \"\"\"\n\n\"\"\"\n    self._path = file  # todo: change this to filePath\n    \"\"\"\n\"\"\"str: File path.\"\"\"\n\n    self._detectionDict: dict = None  # corresponds to an item in sanpy.bDetection\n\n    self._isAnalyzed: bool = False\n\n    self.loadError: bool = False\n\"\"\"bool: True if error loading file/stream.\"\"\"\n\n    # self.detectionDict = None  # remember the parameters of our last detection\n\"\"\"dict: Dictionary specifying detection parameters, see bDetection.getDefaultDetection.\"\"\"\n\n    # self._abf = None\n\"\"\"pyAbf: If loaded from binary .abf file\"\"\"\n\n    self.dateAnalyzed: str = None\n\"\"\"str: Date Time of analysis. TODO: make a property.\"\"\"\n\n    # self.detectionType = None\n\"\"\"str: From ('dvdt', 'mv')\"\"\"\n\n    self.spikeDict: sanpy.bAnalysisResults.analysisResultList = (\n        sanpy.bAnalysisResults.analysisResultList()\n    )\n    # class to store all analysis results\n\n    # self._spikesPerSweep : int = None\n\n    self.spikeClips = []  # created in self.spikeDetect()\n    self.spikeClips_x = []  #\n    self.spikeClips_x2 = []  #\n\n    self.dfError = None  # dataframe with a list of detection errors\n    self._dfReportForScatter = None  # dataframe to be used by scatterplotwidget\n\n    self._detectionDirty = False\n\n    # will be overwritten by existing uuid in self._loadFromDf()\n    self.uuid = sanpy._util.getNewUuid()\n\n    # self.tifData = None\n    # when we have a tif kymograph\n\n    # self.isBytesIO = False\n    # when we are running in the cloud\n\n    # TODO (cudmore) need to parse folder of file loaders in fileloders/ and determine\n    # class to use to load file (using fileLoader.filetype\n    self._fileLoader = None\n    if filepath is not None and not os.path.isfile(filepath):\n        logger.error(f'File does not exist: \"{filepath}\"')\n        self.loadError = True\n    else:\n        if fileLoaderDict is None:\n            fileLoaderDict = (\n                sanpy.fileloaders.getFileLoaders()\n            )  # EXPENSIVE, to do, pass in from app\n\n        _ext = os.path.splitext(filepath)[1]\n        _ext = _ext[1:]\n        try:\n            if verbose:\n                logger.info(f\"Loading file with extension: {_ext}\")\n            constructorObject = fileLoaderDict[_ext][\"constructor\"]\n            self._fileLoader = constructorObject(filepath)\n            # may 2, 2023\n            if self._fileLoader._loadError:\n                logger.error(f'load error in file loader for ext: \"{_ext}\"')\n                self.loadError = True\n\n        except KeyError as e:\n            logger.error(f'did not find a file loader for extension \"{_ext}\"')\n            self.loadError = True\n\n\"\"\"\n    if byteStream is not None:\n        self._loadAbf(byteStream=byteStream,\n                loadData=loadData,\n                stimulusFileFolder=stimulusFileFolder)\n    elif file is not None and file.endswith('.abf'):\n        self._loadAbf(loadData=loadData)\n    elif file is not None and file.endswith('.atf'):\n        self._loadAtf(loadData=loadData)\n    elif file is not None and file.endswith('.tif'):\n        self._loadTif()\n    elif file is not None and file.endswith('.csv'):\n        self._loadCsv()\n    else:\n        pass\n        #logger.error(f'Can only open abf/csv/tif/stream files: {file}')\n        #self.loadError = True\n    \"\"\"\n\n    # get default derivative\n    if loadData and not self.loadError:\n        self._rebuildFiltered()\n\n    self._detectionDirty = False\n\n\"\"\"\n    self.setSweep()\n    \"\"\"\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.__str__","title":"<code>__str__()</code>","text":"<p>Get a brief str representation. Usefull for print().</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def __str__(self):\n\"\"\"Get a brief str representation. Usefull for print().\"\"\"\n    # if self.isBytesIO:\n    #      filename = '&lt;BytesIO&gt;'\n    # else:\n    #     filename = self.getFileName()\n    fileLoadStr = self.fileLoader.__str__()\n    txt = f\"fileLoader: {fileLoadStr} spikes:{self.numSpikes}\"\n    return txt\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.asDataFrame","title":"<code>asDataFrame()</code>","text":"<p>Return analysis as a Pandas DataFrame.</p> <p>Important:     This returns a COPY !!!     Do not modify and expect changes to stick</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def asDataFrame(self):\n\"\"\"Return analysis as a Pandas DataFrame.\n\n    Important:\n        This returns a COPY !!!\n        Do not modify and expect changes to stick\n    \"\"\"\n    return self._dfReportForScatter\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getDetectionDict","title":"<code>getDetectionDict(asCopy=False)</code>","text":"<p>Get the detection dictionary that was used for detect().</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getDetectionDict(self, asCopy: bool = False):\n\"\"\"Get the detection dictionary that was used for detect().\"\"\"\n    if asCopy:\n        return copy.deepcopy(self._detectionDict)\n    else:\n        return self._detectionDict\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getErrorReport","title":"<code>getErrorReport()</code>","text":"<p>Generate an error report, one row per error.</p> <p>Spikes can have more than one error.</p> <p>Returns:     (pandas DataFrame): Pandas DataFrame, one row per error.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getErrorReport(self):\n\"\"\"Generate an error report, one row per error.\n\n    Spikes can have more than one error.\n\n    Returns:\n        (pandas DataFrame): Pandas DataFrame, one row per error.\n    \"\"\"\n\n    dictList = []\n\n    # numError = 0\n    # errorList = []\n\n    logger.info(f'Generating error report for {len(self.spikeDict)} spikes')\n\n    #  20230422 spikeDict is not working as an iterable\n    # use it as a list instead\n    numSpikes = len(self.spikeDict)\n    #for spike in self.spikeDict:\n    for _spikeNumber in range(numSpikes):\n        spike = self.spikeDict[_spikeNumber]\n        # spike is sanpy.bAnalysisResults.analysisResult\n        #print('spike:', spike)\n        for error in spike[\"errors\"]:\n            # spike[\"errors\"] is a list of dict\n            # error is dict from _getErrorDict\n            if error is None or error == np.nan or error == \"nan\":\n                continue\n\n            # 20230422 add sweep and epoch to error dict\n            #_spikeNumber = error['Spike']\n\n            #print('  _spikeNumber:', _spikeNumber, type(_spikeNumber))\n\n            # _sweep = self.getSpikeStat([_spikeNumber], 'sweep')\n            # if len(_sweep)==0:\n            #     logger.error(f\"_spikeNumber:{_spikeNumber} sweep:{_sweep}\")\n            #     #print(self.getOneSpikeDict(_spikeNumber))\n\n            error['Sweep'] = self.getSpikeStat([_spikeNumber], 'sweep')[0]\n            error['Epoch'] = self.getSpikeStat([_spikeNumber], 'epoch')[0]\n\n            dictList.append(error)\n\n    if len(dictList) == 0:\n        fakeErrorDict = self._getErrorDict(1, 1, \"fake\", \"fake\")\n        dfError = pd.DataFrame(columns=fakeErrorDict.keys())\n    else:\n        dfError = pd.DataFrame(dictList)\n\n    if self._detectionDict[\"verbose\"]:\n        logger.info(f\"Found {len(dfError)} errors in spike detection\")\n\n    return dfError\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getNumSpikes","title":"<code>getNumSpikes(sweep=0)</code>","text":"<p>Get number of spikes in a sweep.</p> <p>See property numSpikes</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getNumSpikes(self, sweep: int = 0):\n\"\"\"Get number of spikes in a sweep.\n\n    See property numSpikes\n    \"\"\"\n    thresholdSec = self.getStat(\"thresholdSec\", sweepNumber=sweep)\n    return len(thresholdSec)\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getSpikeClips","title":"<code>getSpikeClips(theMin, theMax, spikeSelection=[], preSpikeClipWidth_ms=None, postSpikeClipWidth_ms=None, sweepNumber=None, epochNumber='All', ignoreMinMax=False)</code>","text":"<p>Get 2d list of spike clips, spike clips x, and 1d mean spike clip.</p> <p>Args:     theMin (float): Start seconds.     theMax (float): Stop seconds.     spikeSelection (list): List of spike numbers     preSpikeClipWidth_ms (float):     postSpikeClipWidth_ms (float):</p> <p>Requires: self.spikeDetect() and self._makeSpikeClips()</p> <p>Returns:     theseClips (list): List of clip     theseClips_x (list): ms     meanClip (list)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getSpikeClips(\n    self,\n    theMin,\n    theMax,\n    spikeSelection=[],\n    preSpikeClipWidth_ms=None,\n    postSpikeClipWidth_ms=None,\n    sweepNumber=None,\n    epochNumber='All',\n    ignoreMinMax=False  # added 20230418\n):\n\"\"\"Get 2d list of spike clips, spike clips x, and 1d mean spike clip.\n\n    Args:\n        theMin (float): Start seconds.\n        theMax (float): Stop seconds.\n        spikeSelection (list): List of spike numbers\n        preSpikeClipWidth_ms (float):\n        postSpikeClipWidth_ms (float):\n\n    Requires: self.spikeDetect() and self._makeSpikeClips()\n\n    Returns:\n        theseClips (list): List of clip\n        theseClips_x (list): ms\n        meanClip (list)\n    \"\"\"\n\n    if self.numSpikes == 0:\n        return\n\n    doSpikeSelection = len(spikeSelection) &gt; 0\n\n    if doSpikeSelection:\n        pass\n    elif theMin is None or theMax is None:\n        theMin = 0\n        theMax = self.fileLoader.recordingDur  # self.sweepX[-1]\n\n    # new interface, spike detect no longer auto generates these\n    # need to do this every time because we get here when sweepNumber changes\n    # if self.spikeClips is None:\n    #    self._makeSpikeClips(spikeClipWidth_ms=spikeClipWidth_ms, sweepNumber=sweepNumber)\n    # TODO: don't make all clips\n    # self._makeSpikeClips(spikeClipWidth_ms=spikeClipWidth_ms, sweepNumber=sweepNumber)\n    self._makeSpikeClips(\n        preSpikeClipWidth_ms=preSpikeClipWidth_ms,\n        postSpikeClipWidth_ms=postSpikeClipWidth_ms,\n        sweepNumber=sweepNumber,\n        epochNumber=epochNumber\n    )\n\n    # make a list of clips within start/stop (Seconds)\n    theseClips = []\n    theseClips_x = []\n    tmpMeanClips = []  # for mean clip\n    meanClip = []\n\n    # spikeTimes are in pnts\n    spikeTimes = self.getSpikeTimes(sweepNumber=sweepNumber, epochNumber=epochNumber)\n\n    logger.info(f'spikeTimes:{len(spikeTimes)} sweepNumber:{sweepNumber} epochNumber:{epochNumber}')\n\n    # if len(spikeTimes) != len(self.spikeClips):\n    #    logger.error(f'len spikeTimes {len(spikeTimes)} !=  spikeClips {len(self.spikeClips)}')\n\n    # self.spikeClips is a list of clips\n    for idx, clip in enumerate(self.spikeClips):\n        doThisSpike = False\n        if doSpikeSelection:\n            doThisSpike = idx in spikeSelection\n        else:\n            spikeTime = spikeTimes[idx]\n            spikeTime = self.fileLoader.pnt2Sec_(spikeTime)\n            if ignoreMinMax or (spikeTime &gt;= theMin and spikeTime &lt;= theMax):\n                doThisSpike = True\n        if doThisSpike:\n            theseClips.append(clip)\n            theseClips_x.append(\n                self.spikeClips_x2[idx]\n            )  # remember, all _x are the same\n            if len(self.spikeClips_x) == len(clip):\n                tmpMeanClips.append(clip)  # for mean clip\n    if len(tmpMeanClips):\n        meanClip = np.mean(tmpMeanClips, axis=0)\n\n    return theseClips, theseClips_x, meanClip\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getSpikeDictionaries","title":"<code>getSpikeDictionaries(sweepNumber=None)</code>","text":"<p>Get spike dictionaries for current sweep</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getSpikeDictionaries(self, sweepNumber=None):\n\"\"\"Get spike dictionaries for current sweep\n    \"\"\"\n    if sweepNumber is None:\n        sweepNumber = \"All\"\n    # logger.info(f'sweepNumber:{sweepNumber}')\n    theRet = [\n        spike\n        for spike in self.spikeDict\n        if sweepNumber == \"All\" or spike[\"sweep\"] == sweepNumber\n    ]\n    return theRet\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getSpikeSeconds","title":"<code>getSpikeSeconds(sweepNumber=None)</code>","text":"<p>Get spike times (seconds) for current sweep</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getSpikeSeconds(self, sweepNumber=None):\n\"\"\"Get spike times (seconds) for current sweep\"\"\"\n    # theRet = [spike['thresholdSec'] for spike in self.spikeDict if spike['sweep']==self.currentSweep]\n    theRet = self.getStat(\"thresholdSec\", sweepNumber=sweepNumber)\n    return theRet\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getSpikeStat","title":"<code>getSpikeStat(spikeList, stat)</code>","text":"<p>Get one stat from a list of spikes</p> <p>Parameters:</p> Name Type Description Default <code>spikeList</code> <code>List[int]</code> required <code>stat</code> <code>str</code> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getSpikeStat(self, spikeList : List[int], stat : str):\n\"\"\"Get one stat from a list of spikes\n\n    Parameters\n    ----------\n    spikeList : List[int]\n    stat : str\n    \"\"\"\n\n    # if isinstance(spikeList, int):\n    #     spikeList = [spikeList]\n\n    if len(spikeList) == 0:\n        return None\n\n    # logger.info(f'spikeList: {spikeList} stat:{stat}')\n\n    retList = []\n    # count = 0\n    for idx, spike in enumerate(self.spikeDict):\n        # logger.info(f'  idx:{idx}')\n        if idx in spikeList:\n            try:\n                val = spike[stat]\n                retList.append(val)\n                # count += 1\n            except KeyError as e:\n                logger.error(e)\n    # logger.info(f'  retList: {retList}')\n    return retList\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getSpikeTimes","title":"<code>getSpikeTimes(sweepNumber=None, epochNumber='All')</code>","text":"<p>Get spike times (points) for current sweep</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getSpikeTimes(self, sweepNumber=None, epochNumber='All'):\n\"\"\"Get spike times (points) for current sweep\"\"\"\n    # theRet = [spike['thresholdPnt'] for spike in self.spikeDict if spike['sweep']==self.currentSweep]\n    theRet = self.getStat(\"thresholdPnt\", sweepNumber=sweepNumber, epochNumber=epochNumber)\n    return theRet\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getStat","title":"<code>getStat(statName1, statName2=None, sweepNumber=None, epochNumber=None, asArray=False, getFullList=False)</code>","text":"<p>Get a list of values for one or two analysis results.</p> <p>Parameters:</p> Name Type Description Default <code>statName1</code> <code>str</code> <p>Name of the first analysis parameter to retreive.</p> required <code>statName2</code> <code>str</code> <p>Optional name of the second analysis parameter to retreive.</p> <code>None</code> <code>sweepNumber</code> <code>int str or None</code> <p>Optional sweep number, if None or 'All' then get all sweeps</p> <code>None</code> <code>epochNumber</code> <code>int str or None</code> <p>Optional epoch number, if None or 'All' then get all epochs</p> <code>None</code> <code>asArray</code> <code>bool</code> <p>If True then return as np.array(), otherwise return as a list</p> <code>False</code>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getStat--notes","title":"Notes","text":"<p>For a list of available analysis results,     see bDetection.getDefaultDetection()</p> <p>If the returned list of analysis results are in points,     convert to seconds or ms using: pnt2Sec_(pnt) or pnt2Ms_(pnt).</p> <p>Returns:</p> Type Description <code>list or np.array</code> <p>List of analysis parameter values, None if error. Returns a np.array is asArray is True</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getStat(\n    self,\n    statName1,\n    statName2: Optional[str] = None,\n    sweepNumber: Optional[int] = None,\n    epochNumber: Optional[int] = None,\n    asArray: Optional[bool] = False,\n    getFullList : Optional[bool] = False\n):\n\"\"\"Get a list of values for one or two analysis results.\n\n    Parameters\n    ----------\n    statName1 : str\n        Name of the first analysis parameter to retreive.\n    statName2 : str\n        Optional name of the second analysis parameter to retreive.\n    sweepNumber : int str or None\n        Optional sweep number, if None or 'All' then get all sweeps\n    epochNumber : int str or None\n        Optional epoch number, if None or 'All' then get all epochs\n    asArray : bool\n        If True then return as np.array(), otherwise return as a list\n\n    Notes\n    -----\n    For a list of available analysis results,\n        see [bDetection.getDefaultDetection()][sanpy.bDetection.bDetection]\n\n    If the returned list of analysis results are in points,\n        convert to seconds or ms using: pnt2Sec_(pnt) or pnt2Ms_(pnt).\n\n    Returns\n    -------\n    list or np.array\n        List of analysis parameter values, None if error.\n        Returns a np.array is asArray is True\n    \"\"\"\n\n    def clean(val):\n\"\"\"Convert None to float('nan')\"\"\"\n        if val is None:\n            val = float(\"nan\")\n        return val\n\n    x = []  # None\n    y = []  # None\n    error = False\n    if len(self.spikeDict) == 0:\n        # logger.error(f'Did not find any spikes in spikeDict')\n        error = True\n    elif statName1 not in self.spikeDict[0].keys():\n        logger.error(f'Did not find statName1: \"{statName1}\" in spikeDict')\n        error = True\n    elif statName2 is not None and statName2 not in self.spikeDict[0].keys():\n        logger.error(f'Did not find statName2: \"{statName2}\" in spikeDict')\n        error = True\n\n    if sweepNumber is None:\n        sweepNumber = \"All\"\n\n    if epochNumber is None:\n        epochNumber = \"All\"\n\n    if not error:\n        # original\n        # x = [clean(spike[statName1]) for spike in self.spikeDict]\n\n        if getFullList:\n            # April 15, 2023, trying to fix bug in scatter plugin when we are\n            # using sweep and epoch\n            # strategy is to return all spikes, just nan out the ones we \n            # are not interested in\n            x = []\n            for spike in self.spikeDict:\n                _include = \\\n                    (sweepNumber == \"All\" or spike[\"sweep\"] == sweepNumber) \\\n                        and (epochNumber == \"All\" or spike[\"epoch\"] == epochNumber)\n                if _include:\n                    x.append(clean(spike[statName1]))\n                else:\n                    x.append(float(\"nan\"))\n\n        else:\n            # only current sweep and epoch\n            # (1) was this\n            x = [\n                clean(spike[statName1])\n                for spike in self.spikeDict\n                if (sweepNumber == \"All\" or spike[\"sweep\"] == sweepNumber)\n                and (epochNumber == \"All\" or spike[\"epoch\"] == epochNumber)\n            ]\n\n\n        if statName2 is not None:\n            # original\n            # y = [clean(spike[statName2]) for spike in self.spikeDict]\n            # only current spweek\n            y = [\n                clean(spike[statName2])\n                for spike in self.spikeDict\n                if sweepNumber == \"All\" or spike[\"sweep\"] == sweepNumber\n            ]\n\n    if asArray:\n        x = np.array(x)\n        if statName2 is not None:\n            y = np.array(y)\n\n    if statName2 is not None:\n        return x, y\n    else:\n        return x\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getStatMean","title":"<code>getStatMean(statName, sweepNumber=None)</code>","text":"<p>Get the mean of an analysis parameter.</p> <p>Args:     statName (str): Name of the statistic to retreive.         For a list of available stats use bDetection.defaultDetection.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getStatMean(self, statName: str, sweepNumber: int = None):\n\"\"\"\n    Get the mean of an analysis parameter.\n\n    Args:\n        statName (str): Name of the statistic to retreive.\n            For a list of available stats use bDetection.defaultDetection.\n    \"\"\"\n    theMean = None\n    x = self.getStat(statName, sweepNumber=sweepNumber)\n    if x is not None and len(x) &gt; 1:\n        theMean = np.nanmean(x)\n    return theMean\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getSweepSpikeFromAbsolute","title":"<code>getSweepSpikeFromAbsolute(absSpikeIdx, sweep)</code>","text":"<p>Get sweep spike from absolute spike.</p> <p>See getAbsSpikeFromSweep()</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getSweepSpikeFromAbsolute(self, absSpikeIdx: int, sweep: int) -&gt; int:\n\"\"\"Get sweep spike from absolute spike.\n\n    See getAbsSpikeFromSweep()\n    \"\"\"\n    sweepSpikeNum = self.spikeDict[absSpikeIdx][\"sweepSpikeNumber\"]\n    return sweepSpikeNum\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.getSweepStats","title":"<code>getSweepStats(statName, decimals=3, asDataFrame=False, df=None)</code>","text":"<p>Args:     df (pd.DataFrame): For kymograph we sometimes have to convert (peak) values to molar</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def getSweepStats(\n    self, statName: str, decimals=3, asDataFrame=False, df: pd.DataFrame = None\n):\n\"\"\"\n\n    Args:\n        df (pd.DataFrame): For kymograph we sometimes have to convert (peak) values to molar\n    \"\"\"\n\n    if df is None:\n        df = self.spikeDict.asDataFrame()\n\n    sweepStatList = []\n\n    for sweep in range(self.fileLoader.numSweeps):\n        oneDf = df[df[\"sweep\"] == sweep]\n        theValues = oneDf[statName]\n\n        theCount = np.count_nonzero(~np.isnan(theValues))\n        theMin = np.min(theValues)\n        theMax = np.max(theValues)\n        theMean = np.nanmean(theValues)\n\n        theMin = round(theMin, decimals)\n        theMax = round(theMax, decimals)\n        theMean = round(theMean, decimals)\n\n        if theCount &gt; 2:\n            theMedian = np.nanmedian(theValues)\n            theSEM = scipy.stats.sem(theValues)\n            theSD = np.nanstd(theValues)\n            theVar = np.nanvar(theValues)\n            theCV = theSD / theVar\n\n            theMedian = round(theMedian, decimals)\n            theSEM = round(theSEM, decimals)\n            theSD = round(theSD, decimals)\n            theVar = round(theVar, decimals)\n            theCV = round(theCV, decimals)\n\n        else:\n            theMedian = None\n            theSEM = None\n            theSD = None\n            theVar = None\n            theCV = None\n\n        oneDict = {\n            statName + \"_sweep\": sweep,\n            statName + \"_count\": theCount,\n            statName + \"_min\": theMin,\n            statName + \"_max\": theMax,\n            statName + \"_mean\": theMean,\n            statName + \"_median\": theMedian,\n            statName + \"_sem\": theSEM,\n            statName + \"_std\": theSD,\n            statName + \"_var\": theVar,\n            statName + \"_cv\": theCV,\n        }\n\n        sweepStatList.append(oneDict)\n\n    #\n    if asDataFrame:\n        return pd.DataFrame(sweepStatList)\n    else:\n        return sweepStatList\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.isAnalyzed","title":"<code>isAnalyzed()</code>","text":"<p>Return True if this bAnalysis has been analyzed, False otherwise.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def isAnalyzed(self):\n\"\"\"Return True if this bAnalysis has been analyzed, False otherwise.\"\"\"\n    return self._isAnalyzed\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.isDirty","title":"<code>isDirty()</code>","text":"<p>Return True if analysis has been modified but not save.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def isDirty(self):\n\"\"\"Return True if analysis has been modified but not save.\"\"\"\n    return self._detectionDirty\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.printSpike","title":"<code>printSpike(idx)</code>","text":"<p>Print values in one spike analysis using self.spikeDict (sanpy.bAnalysisResults).</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def printSpike(self, idx):\n\"\"\"\n    Print values in one spike analysis using self.spikeDict (sanpy.bAnalysisResults).\n    \"\"\"\n    spike = self.spikeDict[idx]\n    for k, v in spike.items():\n        if k == \"widths\":\n            widths = v\n            print(f\"  spike:{idx} has {len(widths)} widths...\")\n            for wIdx, width in enumerate(widths):\n                print(f\"    spike:{idx} width:{wIdx}: {width}\")\n        elif k == \"errors\":\n            errors = v\n            print(f\"  spike:{idx} has {len(errors)} errors...\")\n            for eIdx, error in enumerate(errors):\n                print(f\"    spike:{idx} error #:{eIdx}: {error}\")\n        else:\n            print(f\"{k}: {v}\")\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.saveAnalysis","title":"<code>saveAnalysis(forceSave=False)</code>","text":"<p>Not used.</p> <p>Save detection parameters and analysis results as json.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def saveAnalysis(self, forceSave=False):\n\"\"\"Not used.\n\n    Save detection parameters and analysis results as json.\n    \"\"\"\n    if not self._detectionDirty and not forceSave:\n        return\n\n    saveFolder = self._getSaveFolder()\n    if not os.path.isdir(saveFolder):\n        logger.info(f\"making folder: {saveFolder}\")\n        os.mkdir(saveFolder)\n\n    saveBase = self._getSaveBase()\n    savePath = saveBase + \"-analysis.json\"\n\n    # save detection parameters\n    # self.detectionClass.save(saveBase)\n    dDict = self.detectionClass.getDict()\n\n    saveDict = {}\n    saveDict[\"detection\"] = dDict\n\n    # save list of dict\n    # self.spikeDict = sanpy.bAnalysisResults.analysisResultList()\n    # self.spikeDict.save(saveBase)\n    analysisList = self.spikeDict.asList()\n\n    saveDict[\"analysis\"] = analysisList\n\n    with open(savePath, \"w\") as f:\n        json.dump(saveDict, f, cls=NumpyEncoder, indent=4)\n\n    self._detectionDirty = False\n\n    logger.info(f\"Saved analysis to: {savePath}\")\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.saveAnalysis_tocsv","title":"<code>saveAnalysis_tocsv()</code>","text":"<p>Save analysis to csv.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def saveAnalysis_tocsv(self):\n\"\"\"Save analysis to csv.\"\"\"\n    df = self.asDataFrame()  # pd.DataFrame(self.spikeDict)\n\n    saveFolder = self._getSaveFolder()\n    if not os.path.isdir(saveFolder):\n        logger.info(f\"making folder: {saveFolder}\")\n        os.mkdir(saveFolder)\n\n    saveBase = self._getSaveBase()\n    savePath = saveBase + \"-analysis.csv\"\n\n    logger.info(savePath)\n\n    df.to_csv(savePath)\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.setSpikeStat","title":"<code>setSpikeStat(spikeList, stat, value)</code>","text":"<p>Set a spike stat for one spike or a list of spikes.</p> <p>Used to set things like ('isBad', 'userType1', 'condition', ...)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def setSpikeStat(self, spikeList: Union[list, int], stat: str, value):\n\"\"\"Set a spike stat for one spike or a list of spikes.\n\n    Used to set things like ('isBad', 'userType1', 'condition', ...)\n    \"\"\"\n    if isinstance(spikeList, int):\n        spikeList = [spikeList]\n        # else:\n        #     logger.error(f'Expecting list[int] or int but got spikeList type {type(spikeList)}')\n        return\n\n    if len(spikeList) == 0:\n        return\n\n    now = datetime.datetime.now()\n    modDate = now.strftime(\"%Y%m%d\")\n    modTime = now.strftime(\"%H:%M:%S\")\n\n    for spike in spikeList:\n        self.spikeDict[spike][stat] = value\n        self.spikeDict[spike][\"modDate\"] = modDate\n        self.spikeDict[spike][\"modTime\"] = modTime\n\n    self._detectionDirty = True\n\n    logger.info(f'set spikes {spikeList} stat \"{stat}\" to value \"{value}\"')\n\n\"\"\"\n    count = 0\n    for idx, spike in enumerate(self.spikeDict):\n        if idx in spikeList:\n            try:\n                spike[stat] = value\n                count += 1\n            except (KeyError) as e:\n                logger.info(e)\n    #\n    logger.info(f'Given {len(spikeList)} and set {count}')\n    \"\"\"\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.setSpikeStat_time","title":"<code>setSpikeStat_time(startSec, stopSec, stat, value)</code>","text":"<p>Set a spike stat for spikes in a range of time.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def setSpikeStat_time(self, startSec: int, stopSec: int, stat: str, value):\n\"\"\"Set a spike stat for spikes in a range of time.\"\"\"\n\n    # get spike list in range [startSec, stopSec]\n    spikeSeconds = self.getSpikeSeconds()\n    spikeList = [\n        idx for idx, x in enumerate(spikeSeconds) if x &gt;= startSec and x &lt; stopSec\n    ]\n    self.setSpikeStat(spikeList, stat, value)\n</code></pre>"},{"location":"api/bAnalysis/#sanpy.bAnalysis_.bAnalysis.spikeDetect","title":"<code>spikeDetect(detectionDict)</code>","text":"<p>Run spike detection for all sweeps.</p> <p>Each spike is a row and has 'sweep'</p> <p>Args:     detectionDict: From sanpy.bDetection</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysis_.py</code> <pre><code>def spikeDetect(self, detectionDict: dict):\n\"\"\"Run spike detection for all sweeps.\n\n    Each spike is a row and has 'sweep'\n\n    Args:\n        detectionDict: From sanpy.bDetection\n    \"\"\"\n\n    rememberSweep = (\n        self.fileLoader.currentSweep\n    )  # This is BAD we are mixing analysis with interface !!!\n\n    startTime = time.time()\n\n    #\n    # todo: ask user if they want to remove their settings for (isBad, userType)\n    #\n\n    self._detectionDict = detectionDict\n\n    if detectionDict[\"verbose\"]:\n        logger.info(\"=== detectionDict is:\")\n        for k in detectionDict.keys():\n            v = detectionDict[k]\n            print(f'  {k} value:\"{v}\" is type {type(v)}')\n\n    self._isAnalyzed = True\n\n    self.spikeDict = sanpy.bAnalysisResults.analysisResultList()\n    # we are filling this in, one dict for each spike\n    # self.spikeDict = [] # we are filling this in, one dict for each spike\n\n    # self._spikesPerSweep = [0] * self.fileLoader.numSweeps\n\n    for sweepNumber in self.fileLoader.sweepList:\n        # self.setSweep(sweep)\n        self._spikeDetect2(sweepNumber)\n\n    #\n    self.fileLoader.setSweep(rememberSweep)\n\n    stopTime = time.time()\n\n    if detectionDict[\"verbose\"]:\n        logger.info(\n            f\"Detected {len(self.spikeDict)} spikes in {round(stopTime-startTime,3)} seconds\"\n        )\n</code></pre>"},{"location":"api/bAnalysisResults/","title":"bAnalysisResults","text":""},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults-classes","title":"Classes","text":""},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.NumpyEncoder","title":"<code>NumpyEncoder</code>","text":"<p>         Bases: <code>json.JSONEncoder</code></p> <p>Special json encoder for numpy types</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>class NumpyEncoder(json.JSONEncoder):\n\"\"\"Special json encoder for numpy types\"\"\"\n\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return json.JSONEncoder.default(self, obj)\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResult","title":"<code>analysisResult</code>","text":"Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>class analysisResult:\n    def __init__(self, theDict=None):\n\"\"\"Create an anlysis item (for one spike)\n\n        Args:\n            theDict: Pre-existing dict when we load form h5 file\n        \"\"\"\n        # this is the raw definition of analysis results (See above)\n        # pull from this to create key/value self.rDict\n        # self._dDict = analysisResultDict\n        defaultDict = analysisResultDict\n        # this is simple key/value pairs as we will in detection\n        self._rDict = {}\n        for k, v in defaultDict.items():\n            default = v[\"default\"]\n            self._rDict[k] = default\n\n        if theDict is not None:\n            for k, v in theDict.items():\n                self[k] = v  # calls __setitem__()\n\n    # this was interfering with converting to DataFrame ???\n\"\"\"\n    def __str__(self):\n        printList = []\n        for k,v in self._rDict.items():\n            if isinstance(v, dict):\n                for k2,v2 in v.items():\n                    printList.append(f'  {k2} : {v2} {type(v2)}')\n            else:\n                printList.append(f'{k} : {v} {type(v)}')\n        return '\\n'.join(printList)\n    \"\"\"\n\n    def print(self):\n        printList = []\n        for k, v in self._rDict.items():\n            if isinstance(v, list):\n                for item in v:\n                    for k2, v2 in item.items():\n                        printList.append(f\"  {k2} : {v2} {type(v2)}\")\n            else:\n                printList.append(f\"{k} : {v} {type(v)}\")\n        return \"\\n\".join(printList)\n\n    def addNewKey(self, theKey, theDefault=None):\n\"\"\"\n        Add a new key to this spike.\n\n        Returns: (bool) True if new key added, false if key already exists.\n        \"\"\"\n        if theDefault is None:\n            # theType = 'float'\n            theDefault = float(\"nan\")\n\n        # check if key exists\n        keyExists = theKey in self._rDict.keys()\n        addedKey = False\n        if keyExists:\n            # key exists, don't modify\n            # logger.warning(f'The key \"{theKey}\" already exists and has value \"{self._rDict[theKey]}\"')\n            pass\n        else:\n            self._rDict[theKey] = theDefault\n            addedKey = True\n\n        #\n        return addedKey\n\n    def asDict(self):\n\"\"\"\n        Returns underlying dictionary\n        \"\"\"\n        return self._rDict\n\n    def __getitem__(self, key):\n        # to mimic a dictionary\n        ret = None\n        try:\n            # return self._dDict[key]['currentValue']\n            ret = self._rDict[key]\n        except KeyError as e:\n            logger.error(f'Error getting key \"{key}\" exception:{e}')\n            raise\n        #\n        return ret\n\n    def __setitem__(self, key, value):\n        # to mimic a dictionary\n        try:\n            # self._dDict[key]['currentValue'] = value\n            self._rDict[key] = value\n        except KeyError as e:\n            logger.error(f\"{e}\")\n\n    def items(self):\n        # to mimic a dictionary\n        return self._rDict.items()\n\n    def keys(self):\n        # to mimic a dictionary\n        return self._rDict.keys()\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResult-functions","title":"Functions","text":""},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResult.__init__","title":"<code>__init__(theDict=None)</code>","text":"<p>Create an anlysis item (for one spike)</p> <p>Args:     theDict: Pre-existing dict when we load form h5 file</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def __init__(self, theDict=None):\n\"\"\"Create an anlysis item (for one spike)\n\n    Args:\n        theDict: Pre-existing dict when we load form h5 file\n    \"\"\"\n    # this is the raw definition of analysis results (See above)\n    # pull from this to create key/value self.rDict\n    # self._dDict = analysisResultDict\n    defaultDict = analysisResultDict\n    # this is simple key/value pairs as we will in detection\n    self._rDict = {}\n    for k, v in defaultDict.items():\n        default = v[\"default\"]\n        self._rDict[k] = default\n\n    if theDict is not None:\n        for k, v in theDict.items():\n            self[k] = v  # calls __setitem__()\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResult.addNewKey","title":"<code>addNewKey(theKey, theDefault=None)</code>","text":"<p>Add a new key to this spike.</p> <p>Returns: (bool) True if new key added, false if key already exists.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def addNewKey(self, theKey, theDefault=None):\n\"\"\"\n    Add a new key to this spike.\n\n    Returns: (bool) True if new key added, false if key already exists.\n    \"\"\"\n    if theDefault is None:\n        # theType = 'float'\n        theDefault = float(\"nan\")\n\n    # check if key exists\n    keyExists = theKey in self._rDict.keys()\n    addedKey = False\n    if keyExists:\n        # key exists, don't modify\n        # logger.warning(f'The key \"{theKey}\" already exists and has value \"{self._rDict[theKey]}\"')\n        pass\n    else:\n        self._rDict[theKey] = theDefault\n        addedKey = True\n\n    #\n    return addedKey\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResult.asDict","title":"<code>asDict()</code>","text":"<p>Returns underlying dictionary</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def asDict(self):\n\"\"\"\n    Returns underlying dictionary\n    \"\"\"\n    return self._rDict\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList","title":"<code>analysisResultList</code>","text":"<p>Class encapsulating a list of analysis results.</p> <p>Each row is an analysisResultDict for one spike.</p> <p>These are keys in bAnalysis_ spike dict and columns in output reports</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>class analysisResultList:\n\"\"\"Class encapsulating a list of analysis results.\n\n    Each row is an analysisResultDict for one spike.\n\n    These are keys in bAnalysis_ spike dict and columns in output reports\n    \"\"\"\n\n    def __init__(self):\n        # one copy for entire list\n\n        # TODO: put xxx in a function getAnalysisResltDict()\n        self._dDict = analysisResultDict\n\n        # list of analysisResultDict\n        self._myList = []\n\n        self._iterIdx = -1\n\n    def setFromListDict(self, listOfDict: List[dict]):\n\"\"\"Set analysis results from a list of dict.\n\n        Used when loading sanpy.bAnalysis from h5 file.\n\n        When we create self (during spike detect) we have a list of class analysisResult.\n        When we save/load we have a list of dict.\n\n        This is assuming we re-create self every time we do spike detection\n        \"\"\"\n\n        # do not do this, we are an analysisResultList as a list of analysisResult\n        # self._myList = listOfDict\n\n        self._myList = []\n        for oneDict in listOfDict:\n            oneAnalysisResult = analysisResult(theDict=oneDict)\n            self._myList.append(oneAnalysisResult)\n\n    def analysisDate(self):\n        if len(self) &gt; 0:\n            return self._myList[0][\"analysisDate\"]\n        else:\n            return None\n\n    def analysisTime(self):\n        if len(self) &gt; 0:\n            return self._myList[0][\"analysisTime\"]\n        else:\n            return None\n\n    def _old_save(self, saveBase):\n        savePath = saveBase + \"-analysis.json\"\n\n        analysisList = self.asList()\n\n        # print(analysisList[0].print())\n        print(self._myList[0])\n\n        with open(savePath, \"w\") as f:\n            json.dump(analysisList, f, cls=NumpyEncoder, indent=4)\n\n    def _old_load(self, loadBase):\n        loadPath = loadBase + \"-analysis.json\"\n\n        if not os.path.isfile(loadPath):\n            logger.error(f\"Did not find file: {loadPath}\")\n            return\n\n        with open(loadPath, \"r\") as f:\n            self._myList = json.load(f)\n\n    def appendDefault(self):\n\"\"\"Append a spike to analysis.\n\n        Used in bAnalysis spike detection.\n        \"\"\"\n        oneResult = analysisResult()\n        self._myList.append(oneResult)\n\n    def appendAnalysis(self, analysisResultList):\n        for analysisResult in analysisResultList:\n            # analysisResult is for one spike\n            self._myList.append(analysisResult)\n\n    def addAnalysisResult(self, theKey, theDefault=None):\n        # go through list and add to each [i] dict\n        for spike in self:\n            spike.addNewKey(theKey, theDefault=theDefault)\n\n    def asList(self):\n\"\"\"\n        Return underlying list.\n        \"\"\"\n        # return [spike.asDict() for spike in self._myList]\n        return [x.asDict() for x in self._myList]\n\n    def asDataFrame(self):\n\"\"\"\n        Note: underlying _myList is a list of analysisResult\n        \"\"\"\n        return pd.DataFrame(self.asList())\n\n    def __getitem__(self, key):\n\"\"\"\n        Allow [] indexing with self[int].\n        \"\"\"\n        try:\n            # return self._dDict[key]['currentValue']\n            return self._myList[key]\n        except IndexError as e:\n            logger.error(f\"{e}\")\n\n    def __len__(self):\n\"\"\"Allow len() with len(this)\"\"\"\n        return len(self._myList)\n\n    def __iter__(self):\n\"\"\"Allow iteration with \"for item in self\"\n        \"\"\"\n        _iterIdx = -1\n        return self\n\n    def __next__(self):\n\"\"\"Allow iteration with \"for item in self\"\n        \"\"\"\n        self._iterIdx += 1\n        if self._iterIdx &gt;= len(self._myList):\n            self._iterIdx = -1  # reset to initial value\n            raise StopIteration\n        else:\n            return self._myList[self._iterIdx]\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList-functions","title":"Functions","text":""},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Allow [] indexing with self[int].</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def __getitem__(self, key):\n\"\"\"\n    Allow [] indexing with self[int].\n    \"\"\"\n    try:\n        # return self._dDict[key]['currentValue']\n        return self._myList[key]\n    except IndexError as e:\n        logger.error(f\"{e}\")\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList.__iter__","title":"<code>__iter__()</code>","text":"<p>Allow iteration with \"for item in self\"</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def __iter__(self):\n\"\"\"Allow iteration with \"for item in self\"\n    \"\"\"\n    _iterIdx = -1\n    return self\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList.__len__","title":"<code>__len__()</code>","text":"<p>Allow len() with len(this)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def __len__(self):\n\"\"\"Allow len() with len(this)\"\"\"\n    return len(self._myList)\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList.__next__","title":"<code>__next__()</code>","text":"<p>Allow iteration with \"for item in self\"</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def __next__(self):\n\"\"\"Allow iteration with \"for item in self\"\n    \"\"\"\n    self._iterIdx += 1\n    if self._iterIdx &gt;= len(self._myList):\n        self._iterIdx = -1  # reset to initial value\n        raise StopIteration\n    else:\n        return self._myList[self._iterIdx]\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList.appendDefault","title":"<code>appendDefault()</code>","text":"<p>Append a spike to analysis.</p> <p>Used in bAnalysis spike detection.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def appendDefault(self):\n\"\"\"Append a spike to analysis.\n\n    Used in bAnalysis spike detection.\n    \"\"\"\n    oneResult = analysisResult()\n    self._myList.append(oneResult)\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList.asDataFrame","title":"<code>asDataFrame()</code>","text":"<p>Note: underlying _myList is a list of analysisResult</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def asDataFrame(self):\n\"\"\"\n    Note: underlying _myList is a list of analysisResult\n    \"\"\"\n    return pd.DataFrame(self.asList())\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList.asList","title":"<code>asList()</code>","text":"<p>Return underlying list.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def asList(self):\n\"\"\"\n    Return underlying list.\n    \"\"\"\n    # return [spike.asDict() for spike in self._myList]\n    return [x.asDict() for x in self._myList]\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.analysisResultList.setFromListDict","title":"<code>setFromListDict(listOfDict)</code>","text":"<p>Set analysis results from a list of dict.</p> <p>Used when loading sanpy.bAnalysis from h5 file.</p> <p>When we create self (during spike detect) we have a list of class analysisResult. When we save/load we have a list of dict.</p> <p>This is assuming we re-create self every time we do spike detection</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def setFromListDict(self, listOfDict: List[dict]):\n\"\"\"Set analysis results from a list of dict.\n\n    Used when loading sanpy.bAnalysis from h5 file.\n\n    When we create self (during spike detect) we have a list of class analysisResult.\n    When we save/load we have a list of dict.\n\n    This is assuming we re-create self every time we do spike detection\n    \"\"\"\n\n    # do not do this, we are an analysisResultList as a list of analysisResult\n    # self._myList = listOfDict\n\n    self._myList = []\n    for oneDict in listOfDict:\n        oneAnalysisResult = analysisResult(theDict=oneDict)\n        self._myList.append(oneAnalysisResult)\n</code></pre>"},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults-functions","title":"Functions","text":""},{"location":"api/bAnalysisResults/#sanpy.bAnalysisResults.printDocs","title":"<code>printDocs()</code>","text":"<p>Print out human readable detection parameters and convert to markdown table.</p> <p>Requires:     pip install tabulate</p> <p>See: bDetection.printDocs()</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisResults.py</code> <pre><code>def printDocs():\n\"\"\"\n    Print out human readable detection parameters and convert to markdown table.\n\n    Requires:\n        pip install tabulate\n\n    See: bDetection.printDocs()\n    \"\"\"\n    import pandas as pd\n    from datetime import datetime\n\n    logger.info(\"Ensure there are no errors\")\n\n    dictList = []\n    for k, v in analysisResultDict.items():\n        # iterating on getDefaultDict() to ensure all code above has valid k/v pairs\n        # lineStr = k + '\\t'\n        oneDict = {\n            \"Name\": k,\n        }\n        for k2 in getDefaultDict().keys():\n            # print(f'  {k}: {k2}: {v[k2]}')\n            # lineStr += f'{v[k2]}' + '\\t'\n            oneDict[k2] = v[k2]\n        #\n        # print(lineStr)\n\n        dictList.append(oneDict)\n\n        # check that k is in headerDefaultDict\n        for k3 in v:\n            if not k3 in getDefaultDict().keys():\n                logger.error(f'Found extra key \"{k}\" in \"analysisResultDict\"')\n\n    #\n    df = pd.DataFrame(dictList)\n\n    if 1:\n        # to markdown for mkdocs md file\n        # str = df.to_markdown()\n        str = df.to_html()\n        myDate = datetime.today().strftime(\"%Y-%m-%d\")\n        print(f\"Generated {myDate} with sanpy.analysisVersion {sanpy.analysisVersion}\")\n        print(str)\n\n    if 0:\n        path = \"/Users/cudmore/Desktop/sanpy-analysis-results.csv\"\n        print(\"saving:\", path)\n        df.to_csv(path, index=False)\n</code></pre>"},{"location":"api/bAnalysisUtil/","title":"bAnalysisUtil","text":"Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisUtil.py</code> <pre><code>class bAnalysisUtil:\n    def __init__(self):\n        self.configDict = self.configDefault()\n\n        # load preferences\n        if getattr(sys, \"frozen\", False):\n            # we are running in a bundle (frozen)\n            bundle_dir = sys._MEIPASS\n        else:\n            # we are running in a normal Python environment\n            bundle_dir = os.path.dirname(os.path.abspath(__file__))\n        self.configFilePath = os.path.join(bundle_dir, \"AnalysisApp_Config.json\")\n\n        self.configLoad()\n\n        # self.top = None  # used by tkinter interface\n\n    @staticmethod\n    def getStatList():\n\"\"\"20210929 working on extending stat list with sanpy.userAnalysis\n\n        We first define stat list in this function as statList\n        We then ask for user defined stat functions static members xxx\n        \"\"\"\n        coreStatList = statList  # from global withing function\n\n        # userStatList = sanpy.userAnalysis.findUserAnalysis()\n        # userStatList = sanpy.userAnalysis.baseUserAnalysis.findUserAnalysis()\n        # userStatList = findUserAnalysis()\n\n        #logger.warning(f\"need to reactivate getting user stats\")\n\n\"\"\"\n        Each entry in statList looks like:\n\n        statList['Spike Time (s)'] = {\n            'name': 'thresholdSec',\n            'units': 's',\n            'yStat': 'thresholdVal',\n            'yStatUnits': 'mV',\n            'xStat': 'thresholdSec',\n            'xStatUnits': 's'\n            }\n        \"\"\"\n        userStatList: List[\n            dict\n        ] = sanpy.user_analysis.baseUserAnalysis.findUserAnalysisStats()\n        for userStatDict in userStatList:\n            for k, v in userStatDict.items():\n                if k in coreStatList.keys():\n                    logger.error(\n                        f'user analysis key \"{k}\" already exists in core stat List'\n                    )\n                else:\n                    # name = v['name']\n                    # coreStatList[k] = {}\n                    # coreStatList[k][name] = name\n                    coreStatList[k] = v\n\n        return coreStatList\n\n        # 20220630, was this\n        userStatList = sanpy.user_analysis.baseUserAnalysis.findUserAnalysis()\n\n        for k, v in userStatList.items():\n            # check if key exists !!!\n            if k in coreStatList.keys():\n                logger.error(\n                    f'user analysis key {\"k\"} already exists in core stat List'\n                )\n            else:\n                name = v[\"name\"]\n                coreStatList[k] = {}\n                coreStatList[k][name] = name\n\n        return coreStatList\n\n\"\"\"\n    @staticmethod\n    def humanStatToBackend(theStat):\n        return ''\n    \"\"\"\n\n    def prettyPrint(self):\n        print(json.dumps(self.configDict, indent=4, sort_keys=True))\n\n    def getDetectionConfig(self):\n        return self.config\n\n    def getDetectionParam(self, theParam):\n        if theParam in self.configDict[\"detection\"].keys():\n            return self.configDict[\"detection\"][theParam][\"value\"]\n        else:\n            print(\n                \"error: bAnalysisUtil.getDetectionParam() detection parameter not found:\",\n                theParam,\n            )\n            return None\n\n    def getDetectionDescription(self, theParam):\n        if theParam in self.configDict[\"detection\"].keys():\n            return self.configDict[\"detection\"][theParam][\"meaning\"]\n        else:\n            print(\n                \"error: bAnalysisUtil.getDetectionDescription() detection parameter not found:\",\n                theParam,\n            )\n            return None\n\n    def setDetectionParam(self, theParam, theValue):\n        if theParam in self.configDict[\"detection\"].keys():\n            self.configDict[\"detection\"][theParam][\"value\"] = theValue\n        else:\n            print(\n                \"error: bAnalysisUtil.setDetectionParam() detection parameter not found:\",\n                theParam,\n            )\n            return None\n\n    def configSave(self):\n        print(\"bAnalysisUtil.configSave()\")\n        with open(self.configFilePath, \"w\") as outfile:\n            json.dump(self.configDict, outfile, indent=4, sort_keys=True)\n\n    def configLoad(self):\n        if os.path.isfile(self.configFilePath):\n            print(\n                \"    bAnalysisUtil.configLoad() loading configFile file:\",\n                self.configFilePath,\n            )\n            with open(self.configFilePath) as f:\n                self.configDict = json.load(f)\n        else:\n            # print('    bAnalysisUtil.preferencesLoad() using program provided default options')\n            self.configDefault()\n\n    def configDefault(self):\n        theRet = OrderedDict()\n\n        theRet[\"detection\"] = OrderedDict()\n\n        theRet[\"detection\"][\"dvdtThreshold\"] = OrderedDict()\n        theRet[\"detection\"][\"dvdtThreshold\"] = {\n            \"value\": 100,\n            \"meaning\": \"Threshold crossing in dV/dt\",\n        }\n\n        theRet[\"detection\"][\"minSpikeVm\"] = OrderedDict()\n        theRet[\"detection\"][\"minSpikeVm\"] = {\n            \"value\": -20,\n            \"meaning\": \"Minimum Vm to accept a detected spike\",\n        }\n\n        theRet[\"detection\"][\"medianFilter\"] = OrderedDict()\n        theRet[\"detection\"][\"medianFilter\"] = {\n            \"value\": 5,\n            \"meaning\": \"Median filter for Vm (must be odd)\",\n        }\n\n        theRet[\"detection\"][\"minISI_ms\"] = OrderedDict()\n        theRet[\"detection\"][\"minISI_ms\"] = {\n            \"value\": 75,\n            \"meaning\": \"Minimum allowable inter-spike-interval (ms), anything shorter than this will be rejected\",\n        }\n\n        return theRet\n</code></pre>"},{"location":"api/bAnalysisUtil/#sanpy.bAnalysisUtil-functions","title":"Functions","text":""},{"location":"api/bAnalysisUtil/#sanpy.bAnalysisUtil.bAnalysisUtil.getStatList","title":"<code>getStatList()</code>  <code>staticmethod</code>","text":"<p>20210929 working on extending stat list with sanpy.userAnalysis</p> <p>We first define stat list in this function as statList We then ask for user defined stat functions static members xxx</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bAnalysisUtil.py</code> <pre><code>@staticmethod\ndef getStatList():\n\"\"\"20210929 working on extending stat list with sanpy.userAnalysis\n\n    We first define stat list in this function as statList\n    We then ask for user defined stat functions static members xxx\n    \"\"\"\n    coreStatList = statList  # from global withing function\n\n    # userStatList = sanpy.userAnalysis.findUserAnalysis()\n    # userStatList = sanpy.userAnalysis.baseUserAnalysis.findUserAnalysis()\n    # userStatList = findUserAnalysis()\n\n    #logger.warning(f\"need to reactivate getting user stats\")\n\n\"\"\"\n    Each entry in statList looks like:\n\n    statList['Spike Time (s)'] = {\n        'name': 'thresholdSec',\n        'units': 's',\n        'yStat': 'thresholdVal',\n        'yStatUnits': 'mV',\n        'xStat': 'thresholdSec',\n        'xStatUnits': 's'\n        }\n    \"\"\"\n    userStatList: List[\n        dict\n    ] = sanpy.user_analysis.baseUserAnalysis.findUserAnalysisStats()\n    for userStatDict in userStatList:\n        for k, v in userStatDict.items():\n            if k in coreStatList.keys():\n                logger.error(\n                    f'user analysis key \"{k}\" already exists in core stat List'\n                )\n            else:\n                # name = v['name']\n                # coreStatList[k] = {}\n                # coreStatList[k][name] = name\n                coreStatList[k] = v\n\n    return coreStatList\n\n    # 20220630, was this\n    userStatList = sanpy.user_analysis.baseUserAnalysis.findUserAnalysis()\n\n    for k, v in userStatList.items():\n        # check if key exists !!!\n        if k in coreStatList.keys():\n            logger.error(\n                f'user analysis key {\"k\"} already exists in core stat List'\n            )\n        else:\n            name = v[\"name\"]\n            coreStatList[k] = {}\n            coreStatList[k][name] = name\n\n    return coreStatList\n</code></pre>"},{"location":"api/bDetection/","title":"detectionParams module","text":"<p>The bDetection class provides an interface to get and set detection paramers.</p>"},{"location":"api/bDetection/#sanpy.bDetection--example","title":"Example","text":"<pre><code>import sanpy\n\n# grab the presets for 'SA Node' cells\ndDict = sanpy.bDetection().getDetectionDict('SA Node')\nba.spikeDetect(dDict)\n\n# tweek individual parameters\ndDict['dvdtThreshold'] = 50\n\n# load a recording\nmyPath = 'data/19114001.abf'\nba = sanpy.bAnalysis(myPath)\n\n# perform spike detection\nba.spikeDetect(dDict)\n\n# browse results\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection-classes","title":"Classes","text":""},{"location":"api/bDetection/#sanpy.bDetection.bDetection","title":"<code>bDetection</code>","text":"<p>         Bases: <code>object</code></p> <p>Class to manage detection parameters.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>class bDetection(object):\n\"\"\"Class to manage detection parameters.\"\"\"\n\n    detectionTypes = detectionTypes_\n\"\"\" Enum with the type of spike detection, (dvdt, mv)\"\"\"\n\n    def __init__(self):\n\"\"\"Load all sanpy and &lt;user&gt; detection json files.\"\"\"\n\n        # dict with detection key and current value\n        self._dDict = getDefaultDetection()\n\n        # list of preset names including &lt;user&gt;SanPy/detection json files\n        # use item=e[key] or item=e(value) then use item.name or item.value\n        _theDict, _userPresetsDict = self._getPresetsDict()\n        self._detectionEnum = Enum(\"self.detectionEnum\", _theDict)\n\n        # dictionary of presets, each key is like 'sanode' and then value is a dict of\n        #   detection param keys and their values\n        self._detectionPreset = {}\n        for item in self._detectionEnum:\n            # item is like self.detectionEnum.sanode\n            # logger.info(f'  loaded {item}, {item.name}, \"{item.value}\"')\n            presetValues = self._getPresetValues(item)\n            if presetValues:\n                # got value of built in preset\n                self._detectionPreset[item.name] = presetValues\n            else:\n                # find in user loaded presets\n                _userKey = item.name\n                try:\n                    self._detectionPreset[item.name] = _userPresetsDict[_userKey]\n                except:\n                    logger.erro(\n                        f\"did not find item.name:{item.name} in _detectionPreset {self._detectionPreset.keys()}\"\n                    )\n\n    def getDetectionPresetList(self):\n\"\"\" \"Get list of names of detection type.\n\n        Used to make a list in popup in interface/ and interface/plugins\n        \"\"\"\n        detectionList = []\n        for detectionPreset in self._detectionEnum:\n            detectionList.append(detectionPreset.value)\n        return detectionList\n\n    def _getPresetsDict(self):\n\"\"\"Load detection presets from json files in 2 different folder:\n            1) sanpy/detection-presets\n            2) &lt;user&gt;/Documents/Sanpy/detection/\n\n        For file name like 'Fast Neuron.json' make key 'fastneuron'\n\n        Returns:\n            userPresets (dict): One item per user file\n        \"\"\"\n\n        def fileNameToKey(filePath):\n\"\"\"Given full path to json file, return\n            Filename without extension, and a well formed key.\n            \"\"\"\n            fileName = os.path.split(filePath)[1]\n            fileName = os.path.splitext(fileName)[0]\n\n            fileNameKey = os.path.split(filePath)[1]\n            fileNameKey = os.path.splitext(fileNameKey)[0]\n            # reduce preset json filename to (lower case, no spaces, no dash)\n            fileNameKey = fileNameKey.lower()\n            fileNameKey = fileNameKey.replace(\" \", \"\")\n            fileNameKey = fileNameKey.replace(\n                \"-\", \"\"\n            )  # in case user specifies a '-' in file name\n            return fileName, fileNameKey\n\n        theDict = {}\n        userPresets = {}\n\n        #\n        # get files in our 'detection-presets' folder\n\"\"\"\n        presetsPath = pathlib.Path(sanpy._util.getBundledDir()) / 'detection-presets' / '*.json'\n        files = glob.glob(str(presetsPath))\n        for filePath in files:\n            fileName, fileNameKey = fileNameToKey(filePath)\n            #\n            theDict[fileNameKey] = fileName\n        \"\"\"\n        theDict[\"sanode\"] = \"SA Node\"\n        theDict[\"ventricular\"] = \"Ventricular\"\n        theDict[\"neuron\"] = \"Neuron\"\n        theDict[\"fastneuron\"] = \"Fast Neuron\"\n        theDict[\"subthreshold\"] = \"Sub Threshold\"\n        theDict[\"caspikes\"] = \"Ca Spikes\"\n        theDict[\"cakymograph\"] = \"Ca Kymograph\"\n\n        #\n        # get files in &lt;users&gt;/Documents/SanPy/detection/ folder\n        # userDetectionPath = pathlib.Path(sanpy._util._getUserDetectionFolder()) / '*.json'\n        # files = glob.glob(str(userDetectionPath))\n        files = self._getUserFiles()\n        # print('user files:', files)\n        for filePath in files:\n            fileName, fileNameKey = fileNameToKey(filePath)\n            theDict[fileNameKey] = fileName\n\n            # load user preset json and grab (param keys and values)\n            with open(filePath, \"r\") as f:\n                userPresetsDict = json.load(f)\n                userPresets[fileNameKey] = userPresetsDict\n\n        return theDict, userPresets\n\n    def _getUserFiles(self):\n\"\"\"Get the full path to all user file presets .json\"\"\"\n        userDetectionPath = pathlib.Path(sanpy._util._getUserDetectionFolder())\n        if userDetectionPath.is_dir:\n            files = userDetectionPath.glob(\"*.json\")\n            return files\n        else:\n            return []\n\n    def toJson(self):\n\"\"\"Get key and defaultValue\"\"\"\n        theDict = {}\n        for k, v in self._dDict.items():\n            theDict[k] = v[\"defaultValue\"]\n\n        # logger.info('theDict:')\n        # pprint(theDict)\n\n        # with open(savePath, 'w') as f:\n        #    json.dump(self._dDict, f, indent=4)\n        theJson = json.dumps(theDict, indent=4)\n        # logger.info('theJson:')\n        return theJson\n\n    def old_saveAs(self, detectionType: str, filename, path=None):\n\"\"\"Save a detection dictionary to json.\n\n        If running in GUI, main SanPy app will specify the correct path.\n\n        This is only for user defined sets, we never save our built in detection (hard coded in code).\n\n        Args:\n            detectionType: human readable like 'SA Node', will become 'SA Node.json'\n            filename: Name of file to save (no extension, will append .json)\n        \"\"\"\n        # _keyName = self._detectionEnum(detectionType).name\n        if path is None:\n            # get &lt;user&gt;/Documents/SanPy/xxx folder\n            savePath = sanpy._util._getUserDetectionFolder()\n            savePath = pathlib.Path(savePath) / f\"{filename}.json\"\n        logger.info(str(savePath))\n        with open(savePath, \"w\") as f:\n            dDict = self.getDetectionDict(detectionType)\n            dDict[\"detectionName\"] = filename\n            json.dump(dDict, f, indent=4)\n\n    def printDict(self):\n        for k in self._dDict.keys():\n            v = self._dDict[k][\"currentValue\"]\n            print(f'  {k}: \"{v}\" {type(v)}')\n\n    def getMasterDict(self, detectionType: str):\n\"\"\"Get the full dictionary from self._dDict getDefaultDetection()\n\n        This is needed by sanpy/interface/plugins/detectionParams.py\n        \"\"\"\n\n        retDict = copy.deepcopy(self._dDict)\n\n        detectionTypeKey = self._detectionEnum(detectionType).name\n        oneType = self._detectionPreset[detectionTypeKey]\n        for k, v in oneType.items():\n            retDict[k][\"currentValue\"] = v\n\n        return retDict\n\n    def getDetectionDict(self, detectionType: str, allParameter=True):\n\"\"\"Get a full detection dict.\n\n        Presets like 'SA Node' only over-ride a subset of the defaults, thus need to merge.\n        User saved detection parameters will have all keys.\n\n        Args:\n            detectionType : detection type key, like 'SA Node'\n        \"\"\"\n        try:\n            if allParameter:\n                dDict = {}\n\n                # master template to get all default values\n                for k, v in self._dDict.items():\n                    dDict[k] = v[\"currentValue\"]\n\n                # use specified detection type to get over-written values\n                detectionTypeKey = self._detectionEnum(detectionType).name\n                oneType = self._detectionPreset[detectionTypeKey]\n                for k, v in oneType.items():\n                    dDict[k] = v\n            return dDict\n        except KeyError as e:\n            logger.error(f'Did not find detectionType:\"{detectionType}\"')\n        except ValueError as e:\n            logger.error(f'Did not find detectionType:\"{detectionType}\"')\n\n    def getValue(self, detectionType: str, key):\n\"\"\"Get current value from key. Valid keys are defined in getDefaultDetection().\n\n        Args:\n            detectionType : string value from enum, like 'SA Node'\n        \"\"\"\n        try:\n            # return self._dDict[key]['currentValue']\n            return self._detectionPreset[detectionType][key]\n        except KeyError as e:\n            logger.warning(\n                f'Did not find detectionType \"{detectionType}\" or key \"{key}\" to get current value'\n            )\n            # TODO: define default when not found ???\n            return None\n\n    def setValue(self, detectionType: str, key: str, value):\n\"\"\"\n        Set current value for key. Valid keys are defined in getDefaultDetection.\n\n        For float values that need to take on none, value comes in as -1e9\n\n        Args:\n            detectionType : short name (not value)\n        \"\"\"\n        try:\n            valueType = type(value)\n            valueIsNumber = isinstance(value, numbers.Number)\n            valueIsString = isinstance(value, str)\n            valueIsBool = isinstance(value, bool)\n            valueIsList = isinstance(value, list)\n            valueIsNone = value is None\n\n            # from the master list\n            expectedType = self._dDict[key][\"type\"]  # (number, string, boolean)\n            allowNone = self._dDict[key][\n                \"allowNone\"\n            ]  # used to turn off a detection param\n\n            # logger.info(f'expectedType:{expectedType} value type is {type(value)}')\n\n            if allowNone and valueIsNone:\n                pass\n            elif expectedType == \"number\" and not valueIsNumber:\n                logger.warning(\n                    f'Type mismatch (number) setting key \"{key}\", got {valueType}, expecting {expectedType}'\n                )\n                return False\n            elif expectedType == \"string\" and not valueIsString:\n                logger.warning(\n                    f'Type mismatch (string) setting \"{key}\", got {valueType}, expecting {expectedType}'\n                )\n                return False\n            elif expectedType == \"boolean\" and not valueIsBool:\n                logger.warning(\n                    f'Type mismatch (bool) setting \"{key}\", got {valueType}, expecting {expectedType}'\n                )\n                return False\n            elif expectedType == \"list\" and not valueIsList:\n                logger.warning(\n                    f'Type mismatch (list) setting \"{key}\", got {valueType}, expecting {expectedType}'\n                )\n                return False\n\"\"\"\n            elif expectedType=='sanpy.bDetection.detectionTypes':\n                try:\n                    value = sanpy.bDetection.detectionTypes[value].name\n                    #print(value == sanpy.bDetection.detectionTypes.dvdt)\n                    #print(value == sanpy.bDetection.detectionTypes.mv)\n                except (KeyError) as e:\n                    logger.error(f'sanpy.bDetection.detectionTypes does not contain value \"{value}\"')\n            \"\"\"\n            #\n            # set\n            # self._dDict[key]['currentValue'] = value\n            self._detectionPreset[detectionType][key] = value\n\n            logger.info(\n                f\"now detectionType:{detectionType} key:{key}: {self._detectionPreset[detectionType][key]} {type(self._detectionPreset[detectionType][key])}\"\n            )\n\n            return True\n\n        except KeyError as e:\n            logger.warning(\n                f'Did not find detectionType:{detectionType}, key:\"{key}\" to set current value to \"{value}\"'\n            )\n            return False\n\n    def old_save(self, saveBase):\n\"\"\"\n        Save underlying dict to json file\n\n        Args:\n            save base (str): basename to append '-detection.json'\n        \"\"\"\n\n        # convert\n\n        savePath = saveBase + \"-detection.json\"\n\n        with open(savePath, \"w\") as f:\n            json.dump(self._dDict, f, indent=4)\n\n    def old_load(self, loadBase):\n\"\"\"\n        Load detection from json file.\n\n        Fill in underlying dict\n        \"\"\"\n\n        loadPath = loadBase + \"-detection.json\"\n\n        if not os.path.isfile(loadPath):\n            logger.error(f\"Did not find file: {loadPath}\")\n            return\n\n        with open(loadPath, \"r\") as f:\n            self._dDict = json.load(f)\n\n        # convert\n\n    def _getPresetValues(self, detectionPreset):\n\"\"\"\n        detectionName : corresponds to key in enum self._detectionEnum\n        \"\"\"\n\n        theDict = {}\n\n        if detectionPreset == self._detectionEnum.sanode:\n            theDict[\"detectionName\"] = \"SA Node\"\n            theDict[\"dvdtThreshold\"] = 20\n            theDict[\"mvThreshold\"] = -20\n            theDict[\"refractory_ms\"] = 170  # max freq of 5 Hz\n            theDict[\"peakWindow_ms\"] = 100\n            theDict[\"halfWidthWindow_ms\"] = 200\n            theDict[\"preSpikeClipWidth_ms\"] = 200\n            theDict[\"postSpikeClipWidth_ms\"] = 500\n        elif detectionPreset == self._detectionEnum.ventricular:\n            theDict[\"detectionName\"] = \"Ventricular\"\n            theDict[\"dvdtThreshold\"] = 100\n            theDict[\"mvThreshold\"] = -20\n            theDict[\"refractory_ms\"] = 200  # max freq of 5 Hz\n            theDict[\"peakWindow_ms\"] = 100\n            theDict[\"halfWidthWindow_ms\"] = 300\n            theDict[\"preSpikeClipWidth_ms\"] = 200\n            theDict[\"postSpikeClipWidth_ms\"] = 500\n        elif detectionPreset == self._detectionEnum.neuron:\n            theDict[\"detectionName\"] = \"Neuron\"\n            theDict[\"dvdtThreshold\"] = 20\n            theDict[\"mvThreshold\"] = -40\n            theDict[\"refractory_ms\"] = 4\n            theDict[\"peakWindow_ms\"] = 5\n            theDict[\"halfWidthWindow_ms\"] = 4\n            theDict[\"dvdtPreWindow_ms\"] = 2\n            theDict[\"dvdtPostWindow_ms\"] = 2\n            theDict[\"preSpikeClipWidth_ms\"] = 2\n            theDict[\"postSpikeClipWidth_ms\"] = 2\n        elif detectionPreset == self._detectionEnum.fastneuron:\n            theDict[\"detectionName\"] = \"Fast Neuron\"\n            theDict[\"dvdtThreshold\"] = 20\n            theDict[\"mvThreshold\"] = -40\n            theDict[\"refractory_ms\"] = 3\n            theDict[\"peakWindow_ms\"] = 2\n            theDict[\"halfWidthWindow_ms\"] = 4\n            theDict[\"dvdtPreWindow_ms\"] = 2\n            theDict[\"dvdtPostWindow_ms\"] = 2\n            theDict[\"preSpikeClipWidth_ms\"] = 2\n            theDict[\"postSpikeClipWidth_ms\"] = 2\n        elif detectionPreset == self._detectionEnum.subthreshold:\n            theDict[\"detectionName\"] = \"Subthreshold\"\n            theDict[\"dvdtThreshold\"] = math.nan\n            theDict[\"mvThreshold\"] = -20  # user specifies\n            theDict[\"refractory_ms\"] = 100  # max freq is 10 Hz\n            theDict[\"peakWindow_ms\"] = 50\n            theDict[\"halfWidthWindow_ms\"] = 100\n            theDict[\"preSpikeClipWidth_ms\"] = 100\n            theDict[\"postSpikeClipWidth_ms\"] = 200\n            theDict[\"onlyPeaksAbove_mV\"] = None\n            theDict[\"onlyPeaksBelow_mV\"] = -20\n            # todo: add onlyPeaksBelow_mV\n        elif detectionPreset == self._detectionEnum.caspikes:\n            theDict[\"detectionName\"] = \"Ca Spikes\"\n            # theDict['detectionType'] = sanpy.bDetection.detectionTypes.mv # ('dvdt', 'mv')\n            theDict[\n                \"dvdtThreshold\"\n            ] = math.nan  # if None then detect only using mvThreshold\n            theDict[\"mvThreshold\"] = 0.5\n            # theDict['refractory_ms'] = 200 #170 # reject spikes with instantaneous frequency\n            # theDict['halfWidthWindow_ms'] = 200 #was 20\n        elif detectionPreset == self._detectionEnum.cakymograph:\n            theDict[\"detectionName\"] = \"Ca Kymograph\"\n            theDict[\"detectionType\"] = sanpy.bDetection.detectionTypes[\"mv\"].value\n            theDict[\n                \"dvdtThreshold\"\n            ] = 1.2  # rosie, was math.nan #if None then detect only using mvThreshold\n            theDict[\"mvThreshold\"] = 1.2\n            theDict[\"peakWindow_ms\"] = 400  # rosie, was 700\n            theDict[\"halfWidthWindow_ms\"] = 400  # rosie, was 800\n            theDict[\"refractory_ms\"] = 500\n            theDict[\"doBackupSpikeVm\"] = False\n            # theDict['SavitzkyGolay_pnts'] = 5\n            theDict[\"preSpikeClipWidth_ms\"] = 200\n            theDict[\"postSpikeClipWidth_ms\"] = 1000\n        else:\n            logger.error(f\"did not understand detectionPreset: {detectionPreset}\")\n\n        return theDict\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection-attributes","title":"Attributes","text":""},{"location":"api/bDetection/#sanpy.bDetection.bDetection.detectionTypes","title":"<code>detectionTypes = detectionTypes_</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Enum with the type of spike detection, (dvdt, mv)</p>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection-functions","title":"Functions","text":""},{"location":"api/bDetection/#sanpy.bDetection.bDetection.__init__","title":"<code>__init__()</code>","text":"<p>Load all sanpy and  detection json files. Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def __init__(self):\n\"\"\"Load all sanpy and &lt;user&gt; detection json files.\"\"\"\n\n    # dict with detection key and current value\n    self._dDict = getDefaultDetection()\n\n    # list of preset names including &lt;user&gt;SanPy/detection json files\n    # use item=e[key] or item=e(value) then use item.name or item.value\n    _theDict, _userPresetsDict = self._getPresetsDict()\n    self._detectionEnum = Enum(\"self.detectionEnum\", _theDict)\n\n    # dictionary of presets, each key is like 'sanode' and then value is a dict of\n    #   detection param keys and their values\n    self._detectionPreset = {}\n    for item in self._detectionEnum:\n        # item is like self.detectionEnum.sanode\n        # logger.info(f'  loaded {item}, {item.name}, \"{item.value}\"')\n        presetValues = self._getPresetValues(item)\n        if presetValues:\n            # got value of built in preset\n            self._detectionPreset[item.name] = presetValues\n        else:\n            # find in user loaded presets\n            _userKey = item.name\n            try:\n                self._detectionPreset[item.name] = _userPresetsDict[_userKey]\n            except:\n                logger.erro(\n                    f\"did not find item.name:{item.name} in _detectionPreset {self._detectionPreset.keys()}\"\n                )\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection.getDetectionDict","title":"<code>getDetectionDict(detectionType, allParameter=True)</code>","text":"<p>Get a full detection dict.</p> <p>Presets like 'SA Node' only over-ride a subset of the defaults, thus need to merge. User saved detection parameters will have all keys.</p> <p>Args:     detectionType : detection type key, like 'SA Node'</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def getDetectionDict(self, detectionType: str, allParameter=True):\n\"\"\"Get a full detection dict.\n\n    Presets like 'SA Node' only over-ride a subset of the defaults, thus need to merge.\n    User saved detection parameters will have all keys.\n\n    Args:\n        detectionType : detection type key, like 'SA Node'\n    \"\"\"\n    try:\n        if allParameter:\n            dDict = {}\n\n            # master template to get all default values\n            for k, v in self._dDict.items():\n                dDict[k] = v[\"currentValue\"]\n\n            # use specified detection type to get over-written values\n            detectionTypeKey = self._detectionEnum(detectionType).name\n            oneType = self._detectionPreset[detectionTypeKey]\n            for k, v in oneType.items():\n                dDict[k] = v\n        return dDict\n    except KeyError as e:\n        logger.error(f'Did not find detectionType:\"{detectionType}\"')\n    except ValueError as e:\n        logger.error(f'Did not find detectionType:\"{detectionType}\"')\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection.getDetectionPresetList","title":"<code>getDetectionPresetList()</code>","text":"<p>\"Get list of names of detection type.</p> <p>Used to make a list in popup in interface/ and interface/plugins</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def getDetectionPresetList(self):\n\"\"\" \"Get list of names of detection type.\n\n    Used to make a list in popup in interface/ and interface/plugins\n    \"\"\"\n    detectionList = []\n    for detectionPreset in self._detectionEnum:\n        detectionList.append(detectionPreset.value)\n    return detectionList\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection.getMasterDict","title":"<code>getMasterDict(detectionType)</code>","text":"<p>Get the full dictionary from self._dDict getDefaultDetection()</p> <p>This is needed by sanpy/interface/plugins/detectionParams.py</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def getMasterDict(self, detectionType: str):\n\"\"\"Get the full dictionary from self._dDict getDefaultDetection()\n\n    This is needed by sanpy/interface/plugins/detectionParams.py\n    \"\"\"\n\n    retDict = copy.deepcopy(self._dDict)\n\n    detectionTypeKey = self._detectionEnum(detectionType).name\n    oneType = self._detectionPreset[detectionTypeKey]\n    for k, v in oneType.items():\n        retDict[k][\"currentValue\"] = v\n\n    return retDict\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection.getValue","title":"<code>getValue(detectionType, key)</code>","text":"<p>Get current value from key. Valid keys are defined in getDefaultDetection().</p> <p>Args:     detectionType : string value from enum, like 'SA Node'</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def getValue(self, detectionType: str, key):\n\"\"\"Get current value from key. Valid keys are defined in getDefaultDetection().\n\n    Args:\n        detectionType : string value from enum, like 'SA Node'\n    \"\"\"\n    try:\n        # return self._dDict[key]['currentValue']\n        return self._detectionPreset[detectionType][key]\n    except KeyError as e:\n        logger.warning(\n            f'Did not find detectionType \"{detectionType}\" or key \"{key}\" to get current value'\n        )\n        # TODO: define default when not found ???\n        return None\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection.old_load","title":"<code>old_load(loadBase)</code>","text":"<p>Load detection from json file.</p> <p>Fill in underlying dict</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def old_load(self, loadBase):\n\"\"\"\n    Load detection from json file.\n\n    Fill in underlying dict\n    \"\"\"\n\n    loadPath = loadBase + \"-detection.json\"\n\n    if not os.path.isfile(loadPath):\n        logger.error(f\"Did not find file: {loadPath}\")\n        return\n\n    with open(loadPath, \"r\") as f:\n        self._dDict = json.load(f)\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection.old_save","title":"<code>old_save(saveBase)</code>","text":"<p>Save underlying dict to json file</p> <p>Args:     save base (str): basename to append '-detection.json'</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def old_save(self, saveBase):\n\"\"\"\n    Save underlying dict to json file\n\n    Args:\n        save base (str): basename to append '-detection.json'\n    \"\"\"\n\n    # convert\n\n    savePath = saveBase + \"-detection.json\"\n\n    with open(savePath, \"w\") as f:\n        json.dump(self._dDict, f, indent=4)\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection.old_saveAs","title":"<code>old_saveAs(detectionType, filename, path=None)</code>","text":"<p>Save a detection dictionary to json.</p> <p>If running in GUI, main SanPy app will specify the correct path.</p> <p>This is only for user defined sets, we never save our built in detection (hard coded in code).</p> <p>Args:     detectionType: human readable like 'SA Node', will become 'SA Node.json'     filename: Name of file to save (no extension, will append .json)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def old_saveAs(self, detectionType: str, filename, path=None):\n\"\"\"Save a detection dictionary to json.\n\n    If running in GUI, main SanPy app will specify the correct path.\n\n    This is only for user defined sets, we never save our built in detection (hard coded in code).\n\n    Args:\n        detectionType: human readable like 'SA Node', will become 'SA Node.json'\n        filename: Name of file to save (no extension, will append .json)\n    \"\"\"\n    # _keyName = self._detectionEnum(detectionType).name\n    if path is None:\n        # get &lt;user&gt;/Documents/SanPy/xxx folder\n        savePath = sanpy._util._getUserDetectionFolder()\n        savePath = pathlib.Path(savePath) / f\"{filename}.json\"\n    logger.info(str(savePath))\n    with open(savePath, \"w\") as f:\n        dDict = self.getDetectionDict(detectionType)\n        dDict[\"detectionName\"] = filename\n        json.dump(dDict, f, indent=4)\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection.setValue","title":"<code>setValue(detectionType, key, value)</code>","text":"<p>Set current value for key. Valid keys are defined in getDefaultDetection.</p> <p>For float values that need to take on none, value comes in as -1e9</p> <p>Args:     detectionType : short name (not value)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def setValue(self, detectionType: str, key: str, value):\n\"\"\"\n    Set current value for key. Valid keys are defined in getDefaultDetection.\n\n    For float values that need to take on none, value comes in as -1e9\n\n    Args:\n        detectionType : short name (not value)\n    \"\"\"\n    try:\n        valueType = type(value)\n        valueIsNumber = isinstance(value, numbers.Number)\n        valueIsString = isinstance(value, str)\n        valueIsBool = isinstance(value, bool)\n        valueIsList = isinstance(value, list)\n        valueIsNone = value is None\n\n        # from the master list\n        expectedType = self._dDict[key][\"type\"]  # (number, string, boolean)\n        allowNone = self._dDict[key][\n            \"allowNone\"\n        ]  # used to turn off a detection param\n\n        # logger.info(f'expectedType:{expectedType} value type is {type(value)}')\n\n        if allowNone and valueIsNone:\n            pass\n        elif expectedType == \"number\" and not valueIsNumber:\n            logger.warning(\n                f'Type mismatch (number) setting key \"{key}\", got {valueType}, expecting {expectedType}'\n            )\n            return False\n        elif expectedType == \"string\" and not valueIsString:\n            logger.warning(\n                f'Type mismatch (string) setting \"{key}\", got {valueType}, expecting {expectedType}'\n            )\n            return False\n        elif expectedType == \"boolean\" and not valueIsBool:\n            logger.warning(\n                f'Type mismatch (bool) setting \"{key}\", got {valueType}, expecting {expectedType}'\n            )\n            return False\n        elif expectedType == \"list\" and not valueIsList:\n            logger.warning(\n                f'Type mismatch (list) setting \"{key}\", got {valueType}, expecting {expectedType}'\n            )\n            return False\n\"\"\"\n        elif expectedType=='sanpy.bDetection.detectionTypes':\n            try:\n                value = sanpy.bDetection.detectionTypes[value].name\n                #print(value == sanpy.bDetection.detectionTypes.dvdt)\n                #print(value == sanpy.bDetection.detectionTypes.mv)\n            except (KeyError) as e:\n                logger.error(f'sanpy.bDetection.detectionTypes does not contain value \"{value}\"')\n        \"\"\"\n        #\n        # set\n        # self._dDict[key]['currentValue'] = value\n        self._detectionPreset[detectionType][key] = value\n\n        logger.info(\n            f\"now detectionType:{detectionType} key:{key}: {self._detectionPreset[detectionType][key]} {type(self._detectionPreset[detectionType][key])}\"\n        )\n\n        return True\n\n    except KeyError as e:\n        logger.warning(\n            f'Did not find detectionType:{detectionType}, key:\"{key}\" to set current value to \"{value}\"'\n        )\n        return False\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.bDetection.toJson","title":"<code>toJson()</code>","text":"<p>Get key and defaultValue</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def toJson(self):\n\"\"\"Get key and defaultValue\"\"\"\n    theDict = {}\n    for k, v in self._dDict.items():\n        theDict[k] = v[\"defaultValue\"]\n\n    # logger.info('theDict:')\n    # pprint(theDict)\n\n    # with open(savePath, 'w') as f:\n    #    json.dump(self._dDict, f, indent=4)\n    theJson = json.dumps(theDict, indent=4)\n    # logger.info('theJson:')\n    return theJson\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.detectionTypes_","title":"<code>detectionTypes_</code>","text":"<p>         Bases: <code>Enum</code></p> <p>Detection type is one of (dvdt, mv).</p> <p>dvdt: Search for threshold crossings in first derivative of membrane potential. mv: Search for threshold crossings in membrane potential.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>class detectionTypes_(Enum):\n\"\"\"\n    Detection type is one of (dvdt, mv).\n\n    dvdt: Search for threshold crossings in first derivative of membrane potential.\n    mv: Search for threshold crossings in membrane potential.\n    \"\"\"\n\n    dvdt = \"dvdt\"\n    mv = \"mv\"\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection-functions","title":"Functions","text":""},{"location":"api/bDetection/#sanpy.bDetection.getDefaultDetection","title":"<code>getDefaultDetection()</code>","text":"<p>Get detection parameters</p> <p>This includes a mapping from backend variable names to front-end human readable and long-format descriptions.</p> <p>Args:     detectionPreset (enum): bDetection.detectionPresets.default</p> <p>Returns:     dict: The default detection dictionary.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def getDefaultDetection():\n\"\"\"Get detection parameters\n\n    This includes a mapping from backend variable names to\n    front-end human readable and long-format descriptions.\n\n    Args:\n        detectionPreset (enum): bDetection.detectionPresets.default\n\n    Returns:\n        dict: The default detection dictionary.\n    \"\"\"\n\n    theDict = OrderedDict()  # {}\n\n\"\"\"\n    key = 'include'\n    theDict[key] = {}\n    theDict[key]['defaultValue'] = True\n    theDict[key]['type'] = 'bool'\n    theDict[key]['allowNone'] = False\n    theDict[key]['units'] = ''\n    theDict[key]['humanName'] = 'Include'\n    theDict[key]['errors'] = ('')\n    theDict[key]['description'] = 'Include analysis for this file'\n    \"\"\"\n\n    key = \"detectionName\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = \"default\"  # detectionPreset.value # ('dvdt', 'mv')\n    theDict[key][\"type\"] = \"string\"\n    theDict[key][\n        \"allowNone\"\n    ] = False  # To do, have 2x entry points to bAnalysis detect, never set this to nan\n    theDict[key][\"units\"] = \"\"\n    theDict[key][\"humanName\"] = \"Detection Preset Name\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"The name of detection preset\"\n\n    key = \"userSaveName\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = \"\"  # detectionPreset.value # ('dvdt', 'mv')\n    theDict[key][\"type\"] = \"string\"\n    theDict[key][\n        \"allowNone\"\n    ] = False  # To do, have 2x entry points to bAnalysis detect, never set this to nan\n    theDict[key][\"units\"] = \"\"\n    theDict[key][\"humanName\"] = \"Saved Detection Params\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"The name of saved user detection params\"\n\n    key = \"detectionType\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = sanpy.bDetection.detectionTypes[\n        \"dvdt\"\n    ].value  # ('dvdt', 'mv')\n    theDict[key][\"type\"] = \"sanpy.bDetection.detectionTypes\"\n    theDict[key][\n        \"allowNone\"\n    ] = False  # To do, have 2x entry points to bAnalysis detect, never set this to nan\n    theDict[key][\"units\"] = \"\"\n    theDict[key][\"humanName\"] = \"Detection Type\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"Detect using derivative (dvdt) or membrane potential (mV)\"\n\n    key = \"dvdtThreshold\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 20\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\n        \"allowNone\"\n    ] = True  # To do, have 2x entry points to bAnalysis detect, never set this to nan\n    theDict[key][\"units\"] = \"dVdt\"\n    theDict[key][\"humanName\"] = \"dV/dt Threshold\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"dV/dt threshold for a spike, will be backed up to dvdt_percentOfMax and have xxx error when this fails\"\n\n    key = \"mvThreshold\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = -20\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"mV\"\n    theDict[key][\"humanName\"] = \"mV Threshold\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"mV threshold for spike AND minimum spike mV when detecting with dV/dt\"\n\n    key = \"startSeconds\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = None\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = True\n    theDict[key][\"units\"] = \"s\"\n    theDict[key][\"humanName\"] = \"Start(s)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Start seconds of analysis\"\n\n    key = \"stopSeconds\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = None\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = True\n    theDict[key][\"units\"] = \"s\"\n    theDict[key][\"humanName\"] = \"Stop(s)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Stop seconds of analysis\"\n\n    key = \"cellType\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = \"\"\n    theDict[key][\"type\"] = \"string\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"\"\n    theDict[key][\"humanName\"] = \"Cell Type\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Cell Type\"\n\n    key = \"sex\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = \"\"\n    theDict[key][\"type\"] = \"string\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"\"\n    theDict[key][\"humanName\"] = \"Sex\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Sex\"\n\n    key = \"condition\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = \"\"\n    theDict[key][\"type\"] = \"string\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"\"\n    theDict[key][\"humanName\"] = \"Condition\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Condition\"\n\n    key = \"dvdt_percentOfMax\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 0.1\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"Percent\"\n    theDict[key][\"humanName\"] = \"dV/dt Percent of max\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"For dV/dt detection, the final TOP is when dV/dt drops to this percent from dV/dt AP peak\"\n\n    key = \"onlyPeaksAbove_mV\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = None\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = True\n    theDict[key][\"units\"] = \"mV\"\n    theDict[key][\"humanName\"] = \"Accept Peaks Above (mV)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Only accept APs with peaks above this value (mV)\"\n\n    key = \"onlyPeaksBelow_mV\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = None\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = True\n    theDict[key][\"units\"] = \"mV\"\n    theDict[key][\"humanName\"] = \"Accept Peaks Below (mV)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Only accept APs below this value (mV)\"\n\n    # TODO: get rid of this and replace with foot\n    key = \"doBackupSpikeVm\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = False\n    theDict[key][\"type\"] = \"boolean\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"Boolean\"\n    theDict[key][\"humanName\"] = \"Backup Vm Spikes\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"If true, APs detected with just mV will be backed up until Vm falls to xxx\"\n\n    key = \"refractory_ms\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 170\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"ms\"\n    theDict[key][\"humanName\"] = \"Minimum AP interval (ms)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"APs with interval (wrt previous AP) less than this will be removed\"\n\n    key = \"peakWindow_ms\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 100\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"ms\"\n    theDict[key][\"humanName\"] = \"Peak Window (ms)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Window after TOP (ms) to seach for AP peak (mV)\"\n\n    key = \"dvdtPreWindow_ms\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 10\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"ms\"\n    theDict[key][\"humanName\"] = \"dV/dt Pre Window (ms)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"Window (ms) to search before each TOP for real threshold crossing\"\n\n    key = \"dvdtPostWindow_ms\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 20\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"ms\"\n    theDict[key][\"humanName\"] = \"dV/dt Post Window (ms)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"Window (ms) to search after each AP peak for minimum in dv/dt\"\n\n    key = \"mdp_ms\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 250\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"ms\"\n    theDict[key][\"humanName\"] = \"Pre AP MDP window (ms)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Window (ms) before an AP to look for MDP\"\n\n    key = \"avgWindow_ms\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 5\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"ms\"\n    theDict[key][\"humanName\"] = \"MDP averaging window (ms)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"Window (ms) to calculate MDP (mV) as a mean rather than mV at single point for MDP\"\n\n    key = \"lowEddRate_warning\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 8\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"EDD slope\"\n    theDict[key][\"humanName\"] = \"EDD slope warning\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"Generate warning when EED slope is lower than this value.\"\n\n    key = \"halfHeights\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = [10, 20, 50, 80, 90]\n    theDict[key][\"type\"] = \"list\"  # list of number\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"\"\n    theDict[key][\"humanName\"] = \"AP Durations (%)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"AP Durations as percent of AP height (AP Peak (mV) - TOP (mV))\"\n\n    key = \"halfWidthWindow_ms\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 200\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"ms\"\n    theDict[key][\"humanName\"] = \"Half Width Window (ms)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Window (ms) after TOP to look for AP Durations\"\n\n    key = \"preSpikeClipWidth_ms\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 200\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"ms\"\n    theDict[key][\"humanName\"] = \"Pre AP Clip Width (ms)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"The pre duration of generated AP clips (Before AP)\"\n\n    key = \"postSpikeClipWidth_ms\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 500\n    theDict[key][\"type\"] = \"float\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"ms\"\n    theDict[key][\"humanName\"] = \"Post AP Clip Width (ms)\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"The post duration of generated AP clips (After AP)\"\n\n    key = \"medianFilter\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 0\n    theDict[key][\"type\"] = \"int\"\n    theDict[key][\"allowNone\"] = True  # 0 is no median filter (see SavitzkyGolay_pnts)\n    theDict[key][\"units\"] = \"points\"\n    theDict[key][\"humanName\"] = \"Median Filter Points\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"Number of points in median filter, must be odd, 0 for no filter\"\n\n    key = \"SavitzkyGolay_pnts\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 5  # 20211001 was 5\n    theDict[key][\"type\"] = \"int\"\n    theDict[key][\"allowNone\"] = True  # 0 is no filter\n    theDict[key][\"units\"] = \"points\"\n    theDict[key][\"humanName\"] = \"SavitzkyGolay Points\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"Number of points in SavitzkyGolay filter, must be odd, 0 for no filter\"\n\n    key = \"SavitzkyGolay_poly\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = 2\n    theDict[key][\"type\"] = \"int\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"\"\n    theDict[key][\"humanName\"] = \"SavitzkyGolay Poly Deg\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\n        \"description\"\n    ] = \"The degree of the polynomial for Savitzky-Golay filter\"\n\n    # key = 'dateAnalyzed'\n    # theDict[key] = {}\n    # theDict[key]['defaultValue'] = ''\n    # theDict[key]['type'] = 'str'\n    # theDict[key]['allowNone'] = False\n    # theDict[key]['units'] = ''\n    # theDict[key]['humanName'] = 'Date Analyzed'\n    # theDict[key]['errors'] = ('')\n    # theDict[key]['description'] = 'The date of analysis (yyyymmdd)'\n\n    key = \"verbose\"\n    theDict[key] = {}\n    theDict[key][\"defaultValue\"] = False\n    theDict[key][\"type\"] = \"boolean\"\n    theDict[key][\"allowNone\"] = False\n    theDict[key][\"units\"] = \"Boolean\"\n    theDict[key][\"humanName\"] = \"Verbose\"\n    theDict[key][\"errors\"] = \"\"\n    theDict[key][\"description\"] = \"Verbose Detection Reporting\"\n\n    # assign each detection param current value to it default value\n    for k, v in theDict.items():\n        defaultValue = theDict[k][\"defaultValue\"]\n        theDict[k][\"currentValue\"] = defaultValue\n\n\"\"\"\n    if detectionPreset == bDetection.detectionPresets.default:\n        # these are defaults from above\n        pass\n    elif detectionPreset == bDetection.detectionPresets.sanode:\n        # these are defaults from above\n        pass\n    elif detectionPreset == bDetection.detectionPresets.ventricular:\n        theDict['dvdtThreshold']['defaultValue'] = 100\n        theDict['mvThreshold']['defaultValue'] = -20\n        theDict['refractory_ms']['defaultValue'] = 200  # max freq of 5 Hz\n        theDict['peakWindow_ms']['defaultValue'] = 100\n        theDict['halfWidthWindow_ms']['defaultValue'] = 300\n        theDict['preSpikeClipWidth_ms']['defaultValue'] = 200\n        theDict['postSpikeClipWidth_ms']['defaultValue'] = 500\n    elif detectionPreset == bDetection.detectionPresets.neuron:\n        theDict['dvdtThreshold']['defaultValue'] = 20\n        theDict['mvThreshold']['defaultValue'] = -40\n        theDict['refractory_ms']['defaultValue'] = 4\n        theDict['peakWindow_ms']['defaultValue'] = 5\n        theDict['halfWidthWindow_ms']['defaultValue'] = 4\n        theDict['dvdtPreWindow_ms']['defaultValue'] = 2\n        theDict['dvdtPostWindow_ms']['defaultValue'] = 2\n        theDict['preSpikeClipWidth_ms']['defaultValue'] = 2\n        theDict['postSpikeClipWidth_ms']['defaultValue'] = 2\n    elif detectionPreset == bDetection.detectionPresets.fastneuron:\n        theDict['dvdtThreshold']['defaultValue'] = 20\n        theDict['mvThreshold']['defaultValue'] = -40\n        theDict['refractory_ms']['defaultValue'] = 3\n        theDict['peakWindow_ms']['defaultValue'] = 2\n        theDict['halfWidthWindow_ms']['defaultValue'] = 4\n        theDict['dvdtPreWindow_ms']['defaultValue'] = 2\n        theDict['dvdtPostWindow_ms']['defaultValue'] = 2\n        theDict['preSpikeClipWidth_ms']['defaultValue'] = 2\n        theDict['postSpikeClipWidth_ms']['defaultValue'] = 2\n    elif detectionPreset == bDetection.detectionPresets.subthreshold:\n        theDict['dvdtThreshold']['defaultValue'] = math.nan\n        theDict['mvThreshold']['defaultValue'] = -20  # user specifies\n        theDict['refractory_ms']['defaultValue'] = 100  # max freq is 10 Hz\n        theDict['peakWindow_ms']['defaultValue'] = 50\n        theDict['halfWidthWindow_ms']['defaultValue'] = 100\n        theDict['preSpikeClipWidth_ms']['defaultValue'] = 100\n        theDict['postSpikeClipWidth_ms']['defaultValue'] = 200\n        theDict['onlyPeaksAbove_mV']['defaultValue'] = None\n        theDict['onlyPeaksBelow_mV']['defaultValue'] = -20\n        # todo: add onlyPeaksBelow_mV\n    elif detectionPreset == bDetection.detectionPresets.caspikes:\n        #theDict['detectionType']['defaultValue'] = sanpy.bDetection.detectionTypes.mv # ('dvdt', 'mv')\n        theDict['dvdtThreshold']['defaultValue'] = math.nan #if None then detect only using mvThreshold\n        theDict['mvThreshold']['defaultValue'] = 0.5\n        #theDict['refractory_ms']['defaultValue'] = 200 #170 # reject spikes with instantaneous frequency\n        #theDict['halfWidthWindow_ms']['defaultValue'] = 200 #was 20\n    elif detectionPreset == bDetection.detectionPresets.cakymograph:\n        theDict['detectionType']['defaultValue'] = sanpy.bDetection.detectionTypes['mv'].value\n        theDict['dvdtThreshold']['defaultValue'] = math.nan #if None then detect only using mvThreshold\n        theDict['mvThreshold']['defaultValue'] = 1.2\n        theDict['peakWindow_ms']['defaultValue'] = 700\n        theDict['halfWidthWindow_ms']['defaultValue'] = 800\n        theDict['refractory_ms']['defaultValue'] = 500\n        theDict['doBackupSpikeVm']['defaultValue'] = False\n        # theDict['SavitzkyGolay_pnts']['defaultValue'] = 5\n        theDict['preSpikeClipWidth_ms']['defaultValue'] = 200\n        theDict['postSpikeClipWidth_ms']['defaultValue'] = 1000\n    else:\n        logger.error(f'Did not understand detection type \"{detectionPreset}\"')\n        logger.error(f'    bDetection.detectionPresets.fastneuron: {bDetection.detectionPresets.fastneuron}')\n        logger.error(f'    type(bDetection.detectionPresets.fastneuron): {type(bDetection.detectionPresets.fastneuron)}')\n        logger.error(f'    detectionPreset == bDetection.detectionPresets.fastneuron: {detectionPreset == bDetection.detectionPresets.fastneuron}')\n    \"\"\"\n\n    # assign each detection param current value to it default value\n\"\"\"\n    for k,v in theDict.items():\n        defaultValue = theDict[k]['defaultValue']\n        theDict[k]['currentValue'] = defaultValue\n    \"\"\"\n\n    return theDict.copy()\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.printDocs","title":"<code>printDocs()</code>","text":"<p>Print out human readable detection parameters and convert to markdown table.</p> <p>Requires:     pip install tabulate</p> <p>See: bAnalysisResults.printDocs()</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def printDocs():\n\"\"\"Print out human readable detection parameters and convert to markdown table.\n\n    Requires:\n        pip install tabulate\n\n    See: bAnalysisResults.printDocs()\n    \"\"\"\n    logger.info(\"\")\n\n    import pandas as pd\n\n    # detectionPreset = bDetection.detectionPresets.default  # detectionPresets_ is an enum class\n    d = getDefaultDetection()\n    dictList = []\n    for k, v in d.items():\n        parameter = k\n        oneDict = {\n            \"Parameter\": parameter,\n            \"Default Value\": v[\"defaultValue\"],\n            \"Units\": v[\"units\"],\n            \"Human Readable\": v[\"humanName\"],\n            \"Description\": v[\"description\"],\n        }\n        dictList.append(oneDict)\n    #\n    df = pd.DataFrame(dictList)\n\n    # spit out markdown to copy/paste into mkdocs md file\n    # REMEMBER: This requires `pip install tabulate`\n    # outStr = df.to_markdown()\n    # print(outStr)\n\n    # save to csv for making a table for manuscript\n    path = \"/Users/cudmore/Desktop/sanpy-detection-params-20230316.csv\"\n    print(\"saving to:\", path)\n    df.to_csv(path, index=False)\n</code></pre>"},{"location":"api/bDetection/#sanpy.bDetection.test_0","title":"<code>test_0()</code>","text":"<p>Testing get/set of detection params</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bDetection.py</code> <pre><code>def test_0():\n\"\"\"\n    Testing get/set of detection params\n    \"\"\"\n\n    bd = bDetection()\n\n    # xxx = bd.getValue('xxx')\n\n    # ok = bd.setValue('xxx', 2)\n    # print('ok:', ok)\n\n    ok1 = bd.setValue(\"dvdtThreshold\", None)\n    if not ok1:\n        print(\"ok1:\", ok1)\n\n    ok1_5 = bd.setValue(\"mvThreshold\", None)\n    if not ok1_5:\n        print(\"failure ok ok1_5:\", ok1_5)\n\n    ok2 = bd.setValue(\"cellType\", \"111\")\n    if not ok2:\n        print(\"ok2:\", ok2)\n\n    # for setting list, check that (i) not empty and (ii) list[i] == expected type\n    ok3 = bd.setValue(\"halfHeights\", [])\n    if not ok3:\n        print(\"ok3:\", ok3)\n\n    # start/stop seconds defaults to None but we want 'number'\n    ok4 = bd.setValue(\"startSeconds\", 1e6)\n    if not ok4:\n        print(\"ok4:\", ok4)\n\n    tmpDict = {\n        \"Idx\": 2.0,\n        \"Include\": 1.0,\n        \"File\": \"19114001.abf\",\n        \"Dur(s)\": 60.0,\n        \"kHz\": 20.0,\n        \"Mode\": \"fix\",\n        \"Cell Type\": \"\",\n        \"Sex\": \"\",\n        \"Condition\": \"\",\n        \"Start(s)\": math.nan,\n        \"Stop(s)\": math.nan,\n        \"dvdtThreshold\": 50.0,\n        \"mvThreshold\": -20.0,\n        \"refractory_ms\": math.nan,\n        \"peakWindow_ms\": math.nan,\n        \"halfWidthWindow_ms\": math.nan,\n        \"Notes\": \"\",\n    }\n    for k, v in tmpDict.items():\n        print(\"  \", k, \":\", v)\n    okSetFromDict = bd.setFromDict(tmpDict)\n</code></pre>"},{"location":"api/bExport/","title":"bExport","text":""},{"location":"api/bExport/#sanpy.bExport-classes","title":"Classes","text":""},{"location":"api/bExport/#sanpy.bExport.bExport","title":"<code>bExport</code>","text":"<p>Once analysis is performed with sanpy.bAnalysis.spikeDetect(),     reports can be generated with the bExport class.</p> <p>Example reports are:</p> <ul> <li>Generating reports as a Pandas DataFrame.</li> <li>(depreciated) Saving reports as a Microsoft Excel file.</li> <li>Saving reports as a CSV text files.</li> </ul> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bExport.py</code> <pre><code>class bExport:\n\"\"\"Once analysis is performed with sanpy.bAnalysis.spikeDetect(),\n        reports can be generated with the bExport class.\n\n    Example reports are:\n\n    - Generating reports as a Pandas DataFrame.\n    - (depreciated) Saving reports as a Microsoft Excel file.\n    - Saving reports as a CSV text files.\n    \"\"\"\n\n    def __init__(self, ba):\n\"\"\"\n        Args:\n            ba (sanpy.bAnalysis): A bAnalysis object that has had spikes detected with detectSpikes().\n        \"\"\"\n        self.ba = ba\n        self.sweepNumber = 0\n\n    def old_report(self, theMin, theMax):\n\"\"\"\n        Get entire spikeDict as a Pandas DataFrame.\n\n        Args:\n            theMin (float): Start seconds of the analysis\n            theMax (float): Stop seconds of the analysis\n\n        Returns:\n            df: Pandas DataFrame\n        \"\"\"\n        if theMin is None or theMax is None:\n            # return None\n            theMin = 0\n            theMax = self.ba.fileLoader.recordingDur\n\n        logger.info(f\"theMin:{theMin} theMax:{theMax}\")\n\n        df = self.ba.asDataFrame()\n        df = df[(df[\"thresholdSec\"] &gt;= theMin) &amp; (df[\"thresholdSec\"] &lt;= theMax)]\n\n        # added when trying to make scatterwidget for one file\n        df[\"Condition\"] = \"\"  # df['condition1']\n        df[\"File Number\"] = \"\"  # df['condition2']\n        df[\"Sex\"] = \"\"  # df['condition3']\n        df[\"Region\"] = \"\"  # df['condition4']\n\n        # make new column with sex/region encoded\n\"\"\"\n        tmpNewCol = 'RegSex'\n        self.ba.masterDf[tmpNewCol] = ''\n        for tmpRegion in ['Superior', 'Inferior']:\n            for tmpSex in ['Male', 'Female']:\n                newEncoding = tmpRegion[0] + tmpSex[0]\n                regSex = self.ba.masterDf[ (self.ba.masterDf['Region']==tmpRegion) &amp; (self.ba.masterDf['Sex']==tmpSex)]\n                regSex = (self.ba.masterDf['Region']==tmpRegion) &amp; (self.ba.masterDf['Sex']==tmpSex)\n                print('newEncoding:', newEncoding, 'regSex:', regSex.shape)\n                self.ba.masterDf.loc[regSex, tmpNewCol] = newEncoding\n        \"\"\"\n\n        # want this but region/sex/condition are not defined\n        # print('bExport.report()')\n        # print(df.head())\n        tmpNewCol = \"CellTypeSex\"\n        cellTypeStr = df[\"cellType\"].iloc[0]\n        sexStr = df[\"sex\"].iloc[0]\n        # print('cellTypeStr:', cellTypeStr, 'sexStr:', sexStr)\n        regSexEncoding = cellTypeStr + sexStr\n        df[tmpNewCol] = regSexEncoding\n\n        minStr = \"%.2f\" % (theMin)\n        maxStr = \"%.2f\" % (theMax)\n        minStr = minStr.replace(\".\", \"_\")\n        maxStr = maxStr.replace(\".\", \"_\")\n\n        # TODO: bytestreams are not strictly from a hdd folder or file\n        fileName = self.ba.fileLoader.filename\n        if fileName is not None:\n            fileName, tmpExt = os.path.splitext(fileName)\n            analysisName = fileName + \"_s\" + minStr + \"_s\" + maxStr\n            # print('    minStr:', minStr, 'maxStr:', maxStr, 'analysisName:', analysisName)\n        else:\n            analysisName = \"bytestream\"\n        df[\"analysisname\"] = analysisName\n\n        return df\n\n    def report3(self, sweep='All',\n                epoch='All',\n                theMin : Optional[float] = None,\n                theMax : Optional[float] = None,\n                ) -&gt; pd.DataFrame:\n\"\"\"Generate a full report of all spike columns.\n\n        Like what is save in csv but limited by sweep, epoch, etc\n        \"\"\"\n\n        if self.ba.numSpikes == 0:\n            logger.warning(f\"did not find and spikes for summary\")\n            return None\n\n        df = self.ba.asDataFrame()  # full df with all spikes\n\n        spikeList = self.ba.getStat('spikeNumber', sweepNumber=sweep, epochNumber=epoch)\n\n        # reduce to spikes in list\n        df = df.loc[df['spikeNumber'].isin(spikeList)]\n\n        if theMin is not None and theMax is not None:\n            df = df[ (df['thresholdSec']&gt;=theMin) &amp; (df['thresholdSec']&lt;theMax)]\n\n        return df\n\n    def report2(self, sweep='All',\n                epoch='All',\n                theMin : Optional[float] = None,\n                theMax : Optional[float] = None,\n                ) -&gt; pd.DataFrame:\n\n\"\"\"Generate a human readable report of spikes.\n        Include spike times between theMin and theMax (Sec).\n\n        Args:\n            sweep ('All' or int') : 'All' for all sweeps or int for one sweep\n            epoch ('All' or int) : 'All' for all epochs or int for one epoch\n            theMin (float): Start seconds to save, inclusive\n            theMax (float): Stop seconds to save, inclusive\n\n        Returns:\n            df: pd.DataFrame\n        \"\"\"\n\n        spikeList = self.ba.getStat('spikeNumber', sweepNumber=sweep, epochNumber=epoch)\n\n        newList = []\n        for spikeIdx in spikeList:\n            spike = self.ba.getOneSpikeDict(spikeIdx)\n\n            # if current spike time is out of bounds\n            # then continue (e.g. it is not between theMin (sec) and theMax (sec)\n            spikeTime_sec = self.ba.fileLoader.pnt2Sec_(spike[\"thresholdPnt\"])\n            if theMin is not None and theMax is not None:\n                if spikeTime_sec &lt; theMin or spikeTime_sec &gt; theMax:\n                    continue\n\n            spikeDict = (\n                OrderedDict()\n            )  # use OrderedDict so Pandas output is in the correct order\n\n            spikeDict[\"Spike\"] = spikeIdx\n            spikeDict[\"Take Off Potential (s)\"] = self.ba.fileLoader.pnt2Sec_(\n                spike[\"thresholdPnt\"]\n            )\n            spikeDict[\"Take Off Potential (ms)\"] = self.ba.fileLoader.pnt2Ms_(\n                spike[\"thresholdPnt\"]\n            )\n            spikeDict[\"Take Off Potential (mV)\"] = spike[\"thresholdVal\"]\n            spikeDict[\"AP Peak (ms)\"] = self.ba.fileLoader.pnt2Ms_(spike[\"peakPnt\"])\n            spikeDict[\"AP Peak (mV)\"] = spike[\"peakVal\"]\n            spikeDict[\"AP Height (mV)\"] = spike[\"peakHeight\"]\n            spikeDict[\"Pre AP Min (mV)\"] = spike[\"preMinVal\"]\n            # spikeDict['Post AP Min (mV)'] = spike['postMinVal']\n            #\n            # spikeDict['AP Duration (ms)'] = spike['apDuration_ms']\n            spikeDict[\"Early Diastolic Duration (ms)\"] = spike[\n                \"earlyDiastolicDuration_ms\"\n            ]\n            spikeDict[\"Early Diastolic Depolarization Rate (dV/s)\"] = spike[\n                \"earlyDiastolicDurationRate\"\n            ]  # abb 202012\n            spikeDict[\"Diastolic Duration (ms)\"] = spike[\"diastolicDuration_ms\"]\n            #\n            spikeDict[\"Inter-Spike-Interval (ms)\"] = spike[\"isi_ms\"]\n            spikeDict[\"Spike Frequency (Hz)\"] = spike[\"spikeFreq_hz\"]\n            spikeDict[\"ISI (ms)\"] = spike[\"isi_ms\"]\n\n            spikeDict[\"Cycle Length (ms)\"] = spike[\"cycleLength_ms\"]\n\n            spikeDict[\"Max AP Upstroke (dV/dt)\"] = spike[\"preSpike_dvdt_max_val2\"]\n            spikeDict[\"Max AP Upstroke (mV)\"] = spike[\"preSpike_dvdt_max_val\"]\n\n            spikeDict[\"Max AP Repolarization (dV/dt)\"] = spike[\n                \"postSpike_dvdt_min_val2\"\n            ]\n            spikeDict[\"Max AP Repolarization (mV)\"] = spike[\"postSpike_dvdt_min_val\"]\n\n            # half-width\n            for widthDict in spike[\"widths\"]:\n                keyName = \"width_\" + str(widthDict[\"halfHeight\"])\n                spikeDict[keyName] = widthDict[\"widthMs\"]\n\n            spikeDict[\"File\"] = self.ba.fileLoader.filename\n\n            # errors\n            # spikeDict['numError'] = spike['numError']\n            spikeDict[\"errors\"] = spike[\"errors\"]\n\n            # append\n            newList.append(spikeDict)\n\n        df = pd.DataFrame(newList)\n        return df\n\n    def getSummary(self,\n                   sweep='All',\n                    epoch='All',\n                    theMin: float = None, \n                    theMax: float = None\n                    ) -&gt; pd.DataFrame:\n\"\"\"Get analysis summary as df.\n\n        This adds some header information to spike report bExport.report2().\n        \"\"\"\n\n        if self.ba.numSpikes == 0:\n            logger.warning(f\"did not find and spikes for summary\")\n            return None\n\n        # if theMin is None or theMax is None:\n        #     theMin = 0\n        #     theMax = self.ba.fileLoader.recordingDur\n\n        #\n        # cardiac style analysis to sheet 'cardiac'\n        # human readable columns\n        cardiac_df = self.report2(sweep=sweep,\n                                  epoch=epoch,\n                                  theMin=theMin,\n                                  theMax=theMax)\n\n        dDict = self.ba.getDetectionDict()\n\n        #\n        # header sheet\n        headerDict = OrderedDict()\n        filePath, fileName = os.path.split(self.ba.fileLoader.filepath)\n        headerDict[\"File Name\"] = [fileName]\n        headerDict[\"File Path\"] = [filePath]\n\n        headerDict[\"Cell Type\"] = [dDict[\"cellType\"]]\n        headerDict[\"Sex\"] = [dDict[\"sex\"]]\n        headerDict[\"Condition\"] = [dDict[\"condition\"]]\n\n        headerDict[\"Date Analyzed\"] = [\n            self.ba.analysisDate\n        ]  # pulled from first detected spike\n        headerDict[\"Time Analyzed\"] = [self.ba.analysisTime]\n\n        headerDict[\"Detection Type\"] = [dDict[\"detectionType\"]]\n        headerDict[\"dV/dt Threshold\"] = [dDict[\"dvdtThreshold\"]]\n        # headerDict['mV Threshold'] = [self.ba.mvThreshold] # abb 202012\n        headerDict[\"Vm Threshold (mV)\"] = [dDict[\"mvThreshold\"]]\n        # headerDict['Median Filter (pnts)'] = [self.ba.medianFilter]\n        headerDict[\"Analysis Version\"] = [sanpy.analysisVersion]\n        headerDict[\"Interface Version\"] = [sanpy.interfaceVersion]\n\n        # headerDict['Analysis Start (sec)'] = [self.ba.startSeconds]\n        # headerDict['Analysis Stop (sec)'] = [self.ba.stopSeconds]\n        headerDict[\"Sweep Number\"] = [\"Default 0\"]  # [self.ba.currentSweep]\n        headerDict[\"Number of Sweeps\"] = [self.ba.fileLoader.numSweeps]\n        headerDict[\"Export Start (sec)\"] = [\n            float(\"%.2f\" % (theMin))\n        ]  # on export, x-axis of raw plot will be ouput\n        headerDict[\"Export Stop (sec)\"] = [\n            float(\"%.2f\" % (theMax))\n        ]  # on export, x-axis of raw plot will be ouput\n\n        # 'stats' has xxx columns (name, mean, sd, se, n)\n        headerDict[\"stats\"] = []\n\n        ignoreColumns = [\"Spike\", \"File\"]\n        for idx, col in enumerate(cardiac_df):\n            if col in ignoreColumns:\n                # in general, skip non numerical columns\n                continue\n            headerDict[col] = []\n\n        # mean\n        theMean = cardiac_df.mean(numeric_only=True)  # skipna default is True\n\n        logger.info('cardiac_df:')\n        print(cardiac_df)\n        logger.info('theMean:')\n        print(theMean)\n\n        theMean[\"errors\"] = \"\"\n\n        # sd\n        theSD = cardiac_df.std(numeric_only=True)  # skipna default is True\n        theSD[\"errors\"] = \"\"\n        # se\n        theSE = cardiac_df.sem(numeric_only=True)  # skipna default is True\n        theSE[\"errors\"] = \"\"\n        # n\n        theN = cardiac_df.count(numeric_only=True)  # skipna default is True\n        theN[\"errors\"] = \"\"\n\n        statCols = [\"mean\", \"sd\", \"se\", \"n\"]\n        for j, stat in enumerate(statCols):\n            if j == 0:\n                pass\n            else:\n                # need to append columns to keep Excel sheet columns in sync\n                # for k,v in headerDict.items():\n                #    headerDict[k].append('')\n\n                headerDict[\"File Name\"].append(\"\")\n                headerDict[\"File Path\"].append(\"\")\n                headerDict[\"Cell Type\"].append(\"\")\n                headerDict[\"Sex\"].append(\"\")\n                headerDict[\"Condition\"].append(\"\")\n                #\n                headerDict[\"Date Analyzed\"].append(\"\")\n                headerDict[\"Time Analyzed\"].append(\"\")\n                headerDict[\"Detection Type\"].append(\"\")\n                headerDict[\"dV/dt Threshold\"].append(\"\")\n                headerDict[\"Vm Threshold (mV)\"].append(\"\")\n                # headerDict['Median Filter (pnts)'].append('')\n                headerDict[\"Analysis Version\"].append(\"\")\n                headerDict[\"Interface Version\"].append(\"\")\n                headerDict[\"Sweep Number\"].append(\"\")\n                headerDict[\"Number of Sweeps\"].append(\"\")\n                headerDict[\"Export Start (sec)\"].append(\"\")\n                headerDict[\"Export Stop (sec)\"].append(\"\")\n\n            # a dictionary key for each stat\n            headerDict[\"stats\"].append(stat)\n            for idx, col in enumerate(cardiac_df):\n                if col in ignoreColumns:\n                    # in general, need to ignore string columns\n                    # headerDict[col].append('')\n                    continue\n                # headerDict[col].append('')\n                if stat == \"mean\":\n                    headerDict[col].append(theMean[col])\n                elif stat == \"sd\":\n                    headerDict[col].append(theSD[col])\n                elif stat == \"se\":\n                    headerDict[col].append(theSE[col])\n                elif stat == \"n\":\n                    headerDict[col].append(theN[col])\n\n        # end for j, stat\n        # print('=== headerDict')\n        # for k,v in headerDict.items():\n        #    print(k, ':', v)\n\n        # dict to pandas dataframe\n        df = pd.DataFrame(headerDict).T\n        df.insert(0, \"\", headerDict.keys(), allow_duplicates=True)\n\n        return df\n\n    def saveReport(\n        self,\n        savefile,\n        theMin=None,\n        theMax=None,\n        saveExcel=True,\n        alsoSaveTxt=True,\n        verbose=True,\n    ):\n\"\"\"\n        Save a spike report for detected spikes between theMin (sec) and theMax (sec).\n\n        This is used by main interface 'Export Spike Report'\n\n        Args:\n            savefile (str): path to xlsx file\n            theMin (float): start/stop seconds of the analysis\n            theMax (float): start/stop seconds of the analysis\n            saveExcel (bool):\n            alsoSaveTxt (bool):\n\n        Return:\n            str: analysisName\n            df: df\n        \"\"\"\n        if theMin is None or theMax is None:\n            theMin = 0\n            theMax = self.ba.fileLoader.recordingDur\n\n        # always grab a df to the entire analysis (not sure what I will do with this)\n        # df = self.ba.report() # report() is my own 'bob' verbiage\n\n        theRet = None\n\n        logger.warning(\"NEVER SAVING EXCEL !!! dec 2022\")\n        saveExcel = False\n        if saveExcel and savefile:\n            # if verbose: print('    bExport.saveReport() saving user specified .xlsx file:', savefile)\n            excelFilePath = savefile\n            writer = pd.ExcelWriter(excelFilePath, engine=\"xlsxwriter\")\n\n            #\n            # cardiac style analysis to sheet 'cardiac'\n            cardiac_df = self.report2(theMin, theMax)  # report2 is more 'cardiac'\n\n            dDict = self.ba.getDetectionDict()\n            dateAnalyzed = self.ba.dateAnalyzed\n            timeAnalyzed = self.ba.dateAnalyzed\n\n            #\n            # header sheet\n            headerDict = OrderedDict()\n            filePath, fileName = os.path.split(self.ba.filepath)\n            headerDict[\"File Name\"] = [fileName]\n            headerDict[\"File Path\"] = [filePath]\n\n            headerDict[\"Cell Type\"] = [dDict[\"cellType\"]]\n            headerDict[\"Sex\"] = [dDict[\"sex\"]]\n            headerDict[\"Condition\"] = [dDict[\"condition\"]]\n\n            # todo: get these params in ONE dict inside self.ba\n            # dateAnalyzed, timeAnalyzed = self.ba.dateAnalyzed.split(' ')\n            headerDict[\"Date Analyzed\"] = [dateAnalyzed]\n            headerDict[\"Time Analyzed\"] = [timeAnalyzed]\n            headerDict[\"Detection Type\"] = [dDict[\"detectionType\"]]\n            headerDict[\"dV/dt Threshold\"] = [dDict[\"dvdtThreshold\"]]\n            # headerDict['mV Threshold'] = [self.ba.mvThreshold] # abb 202012\n            headerDict[\"Vm Threshold (mV)\"] = [dDict[\"mvThreshold\"]]\n            # headerDict['Median Filter (pnts)'] = [self.ba.medianFilter]\n            headerDict[\"Analysis Version\"] = [sanpy.analysisVersion]\n            headerDict[\"Interface Version\"] = [sanpy.interfaceVersion]\n\n            # headerDict['Analysis Start (sec)'] = [self.ba.startSeconds]\n            # headerDict['Analysis Stop (sec)'] = [self.ba.stopSeconds]\n            headerDict[\"Sweep Number\"] = [\"Default 0\"]  # [self.ba.currentSweep]\n            headerDict[\"Number of Sweeps\"] = [self.ba.fileLoader.numSweeps]\n            headerDict[\"Export Start (sec)\"] = [\n                float(\"%.2f\" % (theMin))\n            ]  # on export, x-axis of raw plot will be ouput\n            headerDict[\"Export Stop (sec)\"] = [\n                float(\"%.2f\" % (theMax))\n            ]  # on export, x-axis of raw plot will be ouput\n\n            # 'stats' has xxx columns (name, mean, sd, se, n)\n            headerDict[\"stats\"] = []\n\n            ignoreColumns = [\"Spike\", \"File\"]\n            for idx, col in enumerate(cardiac_df):\n                if col in ignoreColumns:\n                    # in general, need to ignore string columns\n                    # headerDict[col].append('')\n                    continue\n                headerDict[col] = []\n\n            # mean\n            theMean = cardiac_df.mean()  # skipna default is True\n            theMean[\"errors\"] = \"\"\n            # sd\n            theSD = cardiac_df.std()  # skipna default is True\n            theSD[\"errors\"] = \"\"\n            # se\n            theSE = cardiac_df.sem()  # skipna default is True\n            theSE[\"errors\"] = \"\"\n            # n\n            theN = cardiac_df.count()  # skipna default is True\n            theN[\"errors\"] = \"\"\n\n            statCols = [\"mean\", \"sd\", \"se\", \"n\"]\n            for j, stat in enumerate(statCols):\n                if j == 0:\n                    pass\n                else:\n                    # need to append columns to keep Excel sheet columns in sync\n                    # for k,v in headerDict.items():\n                    #    headerDict[k].append('')\n\n                    headerDict[\"File Name\"].append(\"\")\n                    headerDict[\"File Path\"].append(\"\")\n                    headerDict[\"Cell Type\"].append(\"\")\n                    headerDict[\"Sex\"].append(\"\")\n                    headerDict[\"Condition\"].append(\"\")\n                    #\n                    headerDict[\"Date Analyzed\"].append(\"\")\n                    headerDict[\"Time Analyzed\"].append(\"\")\n                    headerDict[\"Detection Type\"].append(\"\")\n                    headerDict[\"dV/dt Threshold\"].append(\"\")\n                    headerDict[\"Vm Threshold (mV)\"].append(\"\")\n                    # headerDict['Median Filter (pnts)'].append('')\n                    headerDict[\"Analysis Version\"].append(\"\")\n                    headerDict[\"Interface Version\"].append(\"\")\n                    headerDict[\"Sweep Number\"].append(\"\")\n                    headerDict[\"Number of Sweeps\"].append(\"\")\n                    headerDict[\"Export Start (sec)\"].append(\"\")\n                    headerDict[\"Export Stop (sec)\"].append(\"\")\n\n                # a dictionary key for each stat\n                headerDict[\"stats\"].append(stat)\n                for idx, col in enumerate(cardiac_df):\n                    if col in ignoreColumns:\n                        # in general, need to ignore string columns\n                        # headerDict[col].append('')\n                        continue\n                    # headerDict[col].append('')\n                    if stat == \"mean\":\n                        headerDict[col].append(theMean[col])\n                    elif stat == \"sd\":\n                        headerDict[col].append(theSD[col])\n                    elif stat == \"se\":\n                        headerDict[col].append(theSE[col])\n                    elif stat == \"n\":\n                        headerDict[col].append(theN[col])\n\n            # print(headerDict)\n            # for k,v in headerDict.items():\n            #    print(k, v)\n\n            # dict to pandas dataframe\n            df = pd.DataFrame(headerDict).T\n            df.to_excel(writer, sheet_name=\"summary\")\n\n            # set the column widths in excel sheet 'cardiac'\n            columnWidth = 25\n            worksheet = writer.sheets[\"summary\"]  # pull worksheet object\n            for idx, col in enumerate(df):  # loop through all columns\n                worksheet.set_column(idx, idx, columnWidth)  # set column width\n\n            #\n            # 'params' sheet with all detection params\n            # need to convert list values in dict to string (o.w. we get one row per item in list)\n            exportDetectionDict = {}\n            for k, v in dDict.items():\n                # v is a dict from bDetection\n                if isinstance(v, list):\n                    v = f'\"{v}\"'\n                exportDetectionDict[k] = v\n            # print('  === \"params\" sheet exportDetectionDict:', exportDetectionDict)\n            # df = pd.DataFrame(exportDetectionDict, index=[0]).T # index=[0] needed when dict has all scalar values\n            detection_df = pd.DataFrame(exportDetectionDict).T\n            detection_df.to_excel(writer, sheet_name=\"params\")\n            # worksheet is &lt;class 'xlsxwriter.worksheet.Worksheet'&gt;\n            worksheet = writer.sheets[\"params\"]  # pull worksheet object\n            # set first 20 columns to columnWidth\n            columnWidth = 18\n            startCol = 0\n            stopCol = 20  # xlswriter.worksheet does not care about the stop column\n            worksheet.set_column(0, stopCol, columnWidth)  # set column width\n\n            #\n            # 'cardiac' sheet with human readable stat names\n            cardiac_df.to_excel(writer, sheet_name=\"cardiac\")\n\n            # set the column widths in excel sheet 'cardiac'\n            columnWidth = 20\n            worksheet = writer.sheets[\"cardiac\"]  # pull worksheet object\n            for idx, col in enumerate(cardiac_df):  # loop through all columns\n                worksheet.set_column(idx, idx, columnWidth)  # set column width\n\n            #\n            # mean spike clip\n            theseClips, theseClips_x, meanClip = self.ba.getSpikeClips(\n                theMin, theMax, sweepNumber=self.sweepNumber\n            )\n            try:\n                first_X = theseClips_x[0]  # - theseClips_x[0][0]\n                # if verbose: print('    bExport.saveReport() saving mean clip to sheet \"Avg Spike\" from', len(theseClips), 'clips')\n                df = pd.DataFrame(meanClip, first_X)\n                df.to_excel(writer, sheet_name=\"Avg Spike\")\n            except IndexError as e:\n                logger.warning(\"Got bad spike clips. Usually happend when 1-2 spikes\")\n\n            writer.save()\n\n        #\n        # save a csv text file\n        #\n        analysisName = \"\"\n        if alsoSaveTxt:\n            # this also saves\n            analysisName, df0 = self.getReportDf(theMin, theMax, savefile)\n\n            #\n            # save mean spike clip\n\n            not_used_theseClips, theseClips_x, meanClip = self.ba.getSpikeClips(\n                theMin, theMax, sweepNumber=self.sweepNumber\n            )\n            if len(theseClips_x) == 0:\n                pass\n            else:\n                first_X = theseClips_x[0]  # - theseClips_x[0][0]\n                first_X = np.array(first_X)\n                first_X /= self.ba.fileLoader.dataPointsPerMs  # pnts to ms\n                # if verbose: print('    bExport.saveReport() saving mean clip to sheet \"Avg Spike\" from', len(theseClips), 'clips')\n                # dfClip = pd.DataFrame(meanClip, first_X)\n                dfClip = pd.DataFrame.from_dict({\"xMs\": first_X, \"yVm\": meanClip})\n                # load clip based on analysisname (with start/stop seconds)\n                analysisname = df0[\"analysisname\"].iloc[\n                    0\n                ]  # name with start/stop seconds\n                logger.info(f\"analysisname: {analysisname}\")\n                clipFileName = analysisname + \"_clip.csv\"\n                tmpPath, tmpFile = os.path.split(savefile)\n                tmpPath = os.path.join(tmpPath, \"analysis\")\n                # dir is already created in getReportDf\n                if not os.path.isdir(tmpPath):\n                    os.mkdir(tmpPath)\n                clipSavePath = os.path.join(tmpPath, clipFileName)\n                logger.info(f\"clipSavePath: {clipSavePath}\")\n                dfClip.to_csv(clipSavePath)\n            #\n            theRet = df0\n        #\n        return analysisName, theRet\n\n    def getReportDf(self, theMin, theMax, savefile):\n\"\"\"Get spikes as a Pandas DataFrame, one row per spike.\n\n        Args:\n            theMin (float): xxx\n            theMax (float): xxx\n            savefile (str): .xls file path\n\n        Returns:\n            df: Pandas DataFrame\n        \"\"\"\n        filePath, fileName = os.path.split(os.path.abspath(savefile))\n\n        dDict = self.ba.getDetectionDict()\n\n        # make an analysis folder\n        filePath = os.path.join(filePath, \"analysis\")\n        if not os.path.isdir(filePath):\n            logger.info(f\"Making output folder: {filePath}\")\n            os.mkdir(filePath)\n\n        textFileBaseName, tmpExtension = os.path.splitext(fileName)\n        textFilePath = os.path.join(filePath, textFileBaseName + \".csv\")\n\n        # save header\n        textFileHeader = OrderedDict()\n        textFileHeader[\"file\"] = self.ba.fileLoader.filename\n        # textFileHeader['condition1'] = self.ba.condition1\n        # textFileHeader['condition2'] = self.ba.condition2\n        # textFileHeader['condition3'] = self.ba.condition3\n        textFileHeader[\"cellType\"] = dDict[\"cellType\"]\n        textFileHeader[\"sex\"] = dDict[\"sex\"]\n        textFileHeader[\"condition\"] = dDict[\"condition\"]\n        #\n        textFileHeader[\"dateAnalyzed\"] = self.ba.dateAnalyzed\n        textFileHeader[\"detectionType\"] = dDict[\"detectionType\"]\n        textFileHeader[\"dvdtThreshold\"] = [dDict[\"dvdtThreshold\"]]\n        textFileHeader[\"mvThreshold\"] = [dDict[\"mvThreshold\"]]\n        # textFileHeader['medianFilter'] = self.ba.medianFilter\n        textFileHeader[\"startSeconds\"] = \"%.2f\" % (theMin)\n        textFileHeader[\"stopSeconds\"] = \"%.2f\" % (theMax)\n        # textFileHeader['startSeconds'] = self.ba.startSeconds\n        # textFileHeader['stopSeconds'] = self.ba.stopSeconds\n        textFileHeader[\"currentSweep\"] = \"Default 0\"  # self.ba.currentSweep\n        textFileHeader[\"numSweeps\"] = self.ba.fileLoader.numSweeps\n        # textFileHeader['theMin'] = theMin\n        # textFileHeader['theMax'] = theMax\n\n        # 20210125, this is not needed, we are saviing pandas df below ???\n        headerStr = \"\"\n        for k, v in textFileHeader.items():\n            headerStr += k + \"=\" + str(v) + \";\"\n        headerStr += \"\\n\"\n        # print('headerStr:', headerStr)\n        with open(textFilePath, \"w\") as f:\n            f.write(headerStr)\n\n        # df = self.report(theMin, theMax)\n        df = self.ba.asDataFrame()\n\n        # we need a column indicating (path), the original .abf file\n        # along with (start,stop) which should make this analysis unique?\n        minStr = \"%.2f\" % (theMin)\n        maxStr = \"%.2f\" % (theMax)\n        minStr = minStr.replace(\".\", \"_\")\n        maxStr = maxStr.replace(\".\", \"_\")\n        tmpPath, tmpFile = os.path.split(self.ba.fileLoader.filepath)\n        tmpFile, tmpExt = os.path.splitext(tmpFile)\n        analysisName = tmpFile + \"_s\" + minStr + \"_s\" + maxStr\n        logger.info(f\"minStr:{minStr} maxStr:{maxStr} analysisName:{analysisName}\")\n        df[\"analysisname\"] = analysisName\n\n        # should be filled in by self.ba.report\n        # df['Condition'] =     df['condition1']\n        # df['File Number'] =     df['condition2']\n        # df['Sex'] =     df['condition3']\n        # df['Region'] =     df['condition4']\n        df[\"filename\"] = [\n            os.path.splitext(os.path.split(x)[1])[0] for x in df[\"file\"].tolist()\n        ]\n\n        #\n        logger.info(\"saving text file: {textFilePath}\")\n        # df.to_csv(textFilePath, sep=',', index_label='index', mode='a')\n        df.to_csv(textFilePath, sep=\",\", index_label=\"index\", mode=\"w\")\n\n        return analysisName, df\n</code></pre>"},{"location":"api/bExport/#sanpy.bExport.bExport-functions","title":"Functions","text":""},{"location":"api/bExport/#sanpy.bExport.bExport.__init__","title":"<code>__init__(ba)</code>","text":"<p>Args:     ba (sanpy.bAnalysis): A bAnalysis object that has had spikes detected with detectSpikes().</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bExport.py</code> <pre><code>def __init__(self, ba):\n\"\"\"\n    Args:\n        ba (sanpy.bAnalysis): A bAnalysis object that has had spikes detected with detectSpikes().\n    \"\"\"\n    self.ba = ba\n    self.sweepNumber = 0\n</code></pre>"},{"location":"api/bExport/#sanpy.bExport.bExport.getReportDf","title":"<code>getReportDf(theMin, theMax, savefile)</code>","text":"<p>Get spikes as a Pandas DataFrame, one row per spike.</p> <p>Args:     theMin (float): xxx     theMax (float): xxx     savefile (str): .xls file path</p> <p>Returns:     df: Pandas DataFrame</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bExport.py</code> <pre><code>def getReportDf(self, theMin, theMax, savefile):\n\"\"\"Get spikes as a Pandas DataFrame, one row per spike.\n\n    Args:\n        theMin (float): xxx\n        theMax (float): xxx\n        savefile (str): .xls file path\n\n    Returns:\n        df: Pandas DataFrame\n    \"\"\"\n    filePath, fileName = os.path.split(os.path.abspath(savefile))\n\n    dDict = self.ba.getDetectionDict()\n\n    # make an analysis folder\n    filePath = os.path.join(filePath, \"analysis\")\n    if not os.path.isdir(filePath):\n        logger.info(f\"Making output folder: {filePath}\")\n        os.mkdir(filePath)\n\n    textFileBaseName, tmpExtension = os.path.splitext(fileName)\n    textFilePath = os.path.join(filePath, textFileBaseName + \".csv\")\n\n    # save header\n    textFileHeader = OrderedDict()\n    textFileHeader[\"file\"] = self.ba.fileLoader.filename\n    # textFileHeader['condition1'] = self.ba.condition1\n    # textFileHeader['condition2'] = self.ba.condition2\n    # textFileHeader['condition3'] = self.ba.condition3\n    textFileHeader[\"cellType\"] = dDict[\"cellType\"]\n    textFileHeader[\"sex\"] = dDict[\"sex\"]\n    textFileHeader[\"condition\"] = dDict[\"condition\"]\n    #\n    textFileHeader[\"dateAnalyzed\"] = self.ba.dateAnalyzed\n    textFileHeader[\"detectionType\"] = dDict[\"detectionType\"]\n    textFileHeader[\"dvdtThreshold\"] = [dDict[\"dvdtThreshold\"]]\n    textFileHeader[\"mvThreshold\"] = [dDict[\"mvThreshold\"]]\n    # textFileHeader['medianFilter'] = self.ba.medianFilter\n    textFileHeader[\"startSeconds\"] = \"%.2f\" % (theMin)\n    textFileHeader[\"stopSeconds\"] = \"%.2f\" % (theMax)\n    # textFileHeader['startSeconds'] = self.ba.startSeconds\n    # textFileHeader['stopSeconds'] = self.ba.stopSeconds\n    textFileHeader[\"currentSweep\"] = \"Default 0\"  # self.ba.currentSweep\n    textFileHeader[\"numSweeps\"] = self.ba.fileLoader.numSweeps\n    # textFileHeader['theMin'] = theMin\n    # textFileHeader['theMax'] = theMax\n\n    # 20210125, this is not needed, we are saviing pandas df below ???\n    headerStr = \"\"\n    for k, v in textFileHeader.items():\n        headerStr += k + \"=\" + str(v) + \";\"\n    headerStr += \"\\n\"\n    # print('headerStr:', headerStr)\n    with open(textFilePath, \"w\") as f:\n        f.write(headerStr)\n\n    # df = self.report(theMin, theMax)\n    df = self.ba.asDataFrame()\n\n    # we need a column indicating (path), the original .abf file\n    # along with (start,stop) which should make this analysis unique?\n    minStr = \"%.2f\" % (theMin)\n    maxStr = \"%.2f\" % (theMax)\n    minStr = minStr.replace(\".\", \"_\")\n    maxStr = maxStr.replace(\".\", \"_\")\n    tmpPath, tmpFile = os.path.split(self.ba.fileLoader.filepath)\n    tmpFile, tmpExt = os.path.splitext(tmpFile)\n    analysisName = tmpFile + \"_s\" + minStr + \"_s\" + maxStr\n    logger.info(f\"minStr:{minStr} maxStr:{maxStr} analysisName:{analysisName}\")\n    df[\"analysisname\"] = analysisName\n\n    # should be filled in by self.ba.report\n    # df['Condition'] =     df['condition1']\n    # df['File Number'] =     df['condition2']\n    # df['Sex'] =     df['condition3']\n    # df['Region'] =     df['condition4']\n    df[\"filename\"] = [\n        os.path.splitext(os.path.split(x)[1])[0] for x in df[\"file\"].tolist()\n    ]\n\n    #\n    logger.info(\"saving text file: {textFilePath}\")\n    # df.to_csv(textFilePath, sep=',', index_label='index', mode='a')\n    df.to_csv(textFilePath, sep=\",\", index_label=\"index\", mode=\"w\")\n\n    return analysisName, df\n</code></pre>"},{"location":"api/bExport/#sanpy.bExport.bExport.getSummary","title":"<code>getSummary(sweep='All', epoch='All', theMin=None, theMax=None)</code>","text":"<p>Get analysis summary as df.</p> <p>This adds some header information to spike report bExport.report2().</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bExport.py</code> <pre><code>def getSummary(self,\n               sweep='All',\n                epoch='All',\n                theMin: float = None, \n                theMax: float = None\n                ) -&gt; pd.DataFrame:\n\"\"\"Get analysis summary as df.\n\n    This adds some header information to spike report bExport.report2().\n    \"\"\"\n\n    if self.ba.numSpikes == 0:\n        logger.warning(f\"did not find and spikes for summary\")\n        return None\n\n    # if theMin is None or theMax is None:\n    #     theMin = 0\n    #     theMax = self.ba.fileLoader.recordingDur\n\n    #\n    # cardiac style analysis to sheet 'cardiac'\n    # human readable columns\n    cardiac_df = self.report2(sweep=sweep,\n                              epoch=epoch,\n                              theMin=theMin,\n                              theMax=theMax)\n\n    dDict = self.ba.getDetectionDict()\n\n    #\n    # header sheet\n    headerDict = OrderedDict()\n    filePath, fileName = os.path.split(self.ba.fileLoader.filepath)\n    headerDict[\"File Name\"] = [fileName]\n    headerDict[\"File Path\"] = [filePath]\n\n    headerDict[\"Cell Type\"] = [dDict[\"cellType\"]]\n    headerDict[\"Sex\"] = [dDict[\"sex\"]]\n    headerDict[\"Condition\"] = [dDict[\"condition\"]]\n\n    headerDict[\"Date Analyzed\"] = [\n        self.ba.analysisDate\n    ]  # pulled from first detected spike\n    headerDict[\"Time Analyzed\"] = [self.ba.analysisTime]\n\n    headerDict[\"Detection Type\"] = [dDict[\"detectionType\"]]\n    headerDict[\"dV/dt Threshold\"] = [dDict[\"dvdtThreshold\"]]\n    # headerDict['mV Threshold'] = [self.ba.mvThreshold] # abb 202012\n    headerDict[\"Vm Threshold (mV)\"] = [dDict[\"mvThreshold\"]]\n    # headerDict['Median Filter (pnts)'] = [self.ba.medianFilter]\n    headerDict[\"Analysis Version\"] = [sanpy.analysisVersion]\n    headerDict[\"Interface Version\"] = [sanpy.interfaceVersion]\n\n    # headerDict['Analysis Start (sec)'] = [self.ba.startSeconds]\n    # headerDict['Analysis Stop (sec)'] = [self.ba.stopSeconds]\n    headerDict[\"Sweep Number\"] = [\"Default 0\"]  # [self.ba.currentSweep]\n    headerDict[\"Number of Sweeps\"] = [self.ba.fileLoader.numSweeps]\n    headerDict[\"Export Start (sec)\"] = [\n        float(\"%.2f\" % (theMin))\n    ]  # on export, x-axis of raw plot will be ouput\n    headerDict[\"Export Stop (sec)\"] = [\n        float(\"%.2f\" % (theMax))\n    ]  # on export, x-axis of raw plot will be ouput\n\n    # 'stats' has xxx columns (name, mean, sd, se, n)\n    headerDict[\"stats\"] = []\n\n    ignoreColumns = [\"Spike\", \"File\"]\n    for idx, col in enumerate(cardiac_df):\n        if col in ignoreColumns:\n            # in general, skip non numerical columns\n            continue\n        headerDict[col] = []\n\n    # mean\n    theMean = cardiac_df.mean(numeric_only=True)  # skipna default is True\n\n    logger.info('cardiac_df:')\n    print(cardiac_df)\n    logger.info('theMean:')\n    print(theMean)\n\n    theMean[\"errors\"] = \"\"\n\n    # sd\n    theSD = cardiac_df.std(numeric_only=True)  # skipna default is True\n    theSD[\"errors\"] = \"\"\n    # se\n    theSE = cardiac_df.sem(numeric_only=True)  # skipna default is True\n    theSE[\"errors\"] = \"\"\n    # n\n    theN = cardiac_df.count(numeric_only=True)  # skipna default is True\n    theN[\"errors\"] = \"\"\n\n    statCols = [\"mean\", \"sd\", \"se\", \"n\"]\n    for j, stat in enumerate(statCols):\n        if j == 0:\n            pass\n        else:\n            # need to append columns to keep Excel sheet columns in sync\n            # for k,v in headerDict.items():\n            #    headerDict[k].append('')\n\n            headerDict[\"File Name\"].append(\"\")\n            headerDict[\"File Path\"].append(\"\")\n            headerDict[\"Cell Type\"].append(\"\")\n            headerDict[\"Sex\"].append(\"\")\n            headerDict[\"Condition\"].append(\"\")\n            #\n            headerDict[\"Date Analyzed\"].append(\"\")\n            headerDict[\"Time Analyzed\"].append(\"\")\n            headerDict[\"Detection Type\"].append(\"\")\n            headerDict[\"dV/dt Threshold\"].append(\"\")\n            headerDict[\"Vm Threshold (mV)\"].append(\"\")\n            # headerDict['Median Filter (pnts)'].append('')\n            headerDict[\"Analysis Version\"].append(\"\")\n            headerDict[\"Interface Version\"].append(\"\")\n            headerDict[\"Sweep Number\"].append(\"\")\n            headerDict[\"Number of Sweeps\"].append(\"\")\n            headerDict[\"Export Start (sec)\"].append(\"\")\n            headerDict[\"Export Stop (sec)\"].append(\"\")\n\n        # a dictionary key for each stat\n        headerDict[\"stats\"].append(stat)\n        for idx, col in enumerate(cardiac_df):\n            if col in ignoreColumns:\n                # in general, need to ignore string columns\n                # headerDict[col].append('')\n                continue\n            # headerDict[col].append('')\n            if stat == \"mean\":\n                headerDict[col].append(theMean[col])\n            elif stat == \"sd\":\n                headerDict[col].append(theSD[col])\n            elif stat == \"se\":\n                headerDict[col].append(theSE[col])\n            elif stat == \"n\":\n                headerDict[col].append(theN[col])\n\n    # end for j, stat\n    # print('=== headerDict')\n    # for k,v in headerDict.items():\n    #    print(k, ':', v)\n\n    # dict to pandas dataframe\n    df = pd.DataFrame(headerDict).T\n    df.insert(0, \"\", headerDict.keys(), allow_duplicates=True)\n\n    return df\n</code></pre>"},{"location":"api/bExport/#sanpy.bExport.bExport.old_report","title":"<code>old_report(theMin, theMax)</code>","text":"<p>Get entire spikeDict as a Pandas DataFrame.</p> <p>Args:     theMin (float): Start seconds of the analysis     theMax (float): Stop seconds of the analysis</p> <p>Returns:     df: Pandas DataFrame</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bExport.py</code> <pre><code>def old_report(self, theMin, theMax):\n\"\"\"\n    Get entire spikeDict as a Pandas DataFrame.\n\n    Args:\n        theMin (float): Start seconds of the analysis\n        theMax (float): Stop seconds of the analysis\n\n    Returns:\n        df: Pandas DataFrame\n    \"\"\"\n    if theMin is None or theMax is None:\n        # return None\n        theMin = 0\n        theMax = self.ba.fileLoader.recordingDur\n\n    logger.info(f\"theMin:{theMin} theMax:{theMax}\")\n\n    df = self.ba.asDataFrame()\n    df = df[(df[\"thresholdSec\"] &gt;= theMin) &amp; (df[\"thresholdSec\"] &lt;= theMax)]\n\n    # added when trying to make scatterwidget for one file\n    df[\"Condition\"] = \"\"  # df['condition1']\n    df[\"File Number\"] = \"\"  # df['condition2']\n    df[\"Sex\"] = \"\"  # df['condition3']\n    df[\"Region\"] = \"\"  # df['condition4']\n\n    # make new column with sex/region encoded\n\"\"\"\n    tmpNewCol = 'RegSex'\n    self.ba.masterDf[tmpNewCol] = ''\n    for tmpRegion in ['Superior', 'Inferior']:\n        for tmpSex in ['Male', 'Female']:\n            newEncoding = tmpRegion[0] + tmpSex[0]\n            regSex = self.ba.masterDf[ (self.ba.masterDf['Region']==tmpRegion) &amp; (self.ba.masterDf['Sex']==tmpSex)]\n            regSex = (self.ba.masterDf['Region']==tmpRegion) &amp; (self.ba.masterDf['Sex']==tmpSex)\n            print('newEncoding:', newEncoding, 'regSex:', regSex.shape)\n            self.ba.masterDf.loc[regSex, tmpNewCol] = newEncoding\n    \"\"\"\n\n    # want this but region/sex/condition are not defined\n    # print('bExport.report()')\n    # print(df.head())\n    tmpNewCol = \"CellTypeSex\"\n    cellTypeStr = df[\"cellType\"].iloc[0]\n    sexStr = df[\"sex\"].iloc[0]\n    # print('cellTypeStr:', cellTypeStr, 'sexStr:', sexStr)\n    regSexEncoding = cellTypeStr + sexStr\n    df[tmpNewCol] = regSexEncoding\n\n    minStr = \"%.2f\" % (theMin)\n    maxStr = \"%.2f\" % (theMax)\n    minStr = minStr.replace(\".\", \"_\")\n    maxStr = maxStr.replace(\".\", \"_\")\n\n    # TODO: bytestreams are not strictly from a hdd folder or file\n    fileName = self.ba.fileLoader.filename\n    if fileName is not None:\n        fileName, tmpExt = os.path.splitext(fileName)\n        analysisName = fileName + \"_s\" + minStr + \"_s\" + maxStr\n        # print('    minStr:', minStr, 'maxStr:', maxStr, 'analysisName:', analysisName)\n    else:\n        analysisName = \"bytestream\"\n    df[\"analysisname\"] = analysisName\n\n    return df\n</code></pre>"},{"location":"api/bExport/#sanpy.bExport.bExport.report2","title":"<code>report2(sweep='All', epoch='All', theMin=None, theMax=None)</code>","text":"<p>Generate a human readable report of spikes. Include spike times between theMin and theMax (Sec).</p> <p>Args:     sweep ('All' or int') : 'All' for all sweeps or int for one sweep     epoch ('All' or int) : 'All' for all epochs or int for one epoch     theMin (float): Start seconds to save, inclusive     theMax (float): Stop seconds to save, inclusive</p> <p>Returns:     df: pd.DataFrame</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bExport.py</code> <pre><code>def report2(self, sweep='All',\n            epoch='All',\n            theMin : Optional[float] = None,\n            theMax : Optional[float] = None,\n            ) -&gt; pd.DataFrame:\n\n\"\"\"Generate a human readable report of spikes.\n    Include spike times between theMin and theMax (Sec).\n\n    Args:\n        sweep ('All' or int') : 'All' for all sweeps or int for one sweep\n        epoch ('All' or int) : 'All' for all epochs or int for one epoch\n        theMin (float): Start seconds to save, inclusive\n        theMax (float): Stop seconds to save, inclusive\n\n    Returns:\n        df: pd.DataFrame\n    \"\"\"\n\n    spikeList = self.ba.getStat('spikeNumber', sweepNumber=sweep, epochNumber=epoch)\n\n    newList = []\n    for spikeIdx in spikeList:\n        spike = self.ba.getOneSpikeDict(spikeIdx)\n\n        # if current spike time is out of bounds\n        # then continue (e.g. it is not between theMin (sec) and theMax (sec)\n        spikeTime_sec = self.ba.fileLoader.pnt2Sec_(spike[\"thresholdPnt\"])\n        if theMin is not None and theMax is not None:\n            if spikeTime_sec &lt; theMin or spikeTime_sec &gt; theMax:\n                continue\n\n        spikeDict = (\n            OrderedDict()\n        )  # use OrderedDict so Pandas output is in the correct order\n\n        spikeDict[\"Spike\"] = spikeIdx\n        spikeDict[\"Take Off Potential (s)\"] = self.ba.fileLoader.pnt2Sec_(\n            spike[\"thresholdPnt\"]\n        )\n        spikeDict[\"Take Off Potential (ms)\"] = self.ba.fileLoader.pnt2Ms_(\n            spike[\"thresholdPnt\"]\n        )\n        spikeDict[\"Take Off Potential (mV)\"] = spike[\"thresholdVal\"]\n        spikeDict[\"AP Peak (ms)\"] = self.ba.fileLoader.pnt2Ms_(spike[\"peakPnt\"])\n        spikeDict[\"AP Peak (mV)\"] = spike[\"peakVal\"]\n        spikeDict[\"AP Height (mV)\"] = spike[\"peakHeight\"]\n        spikeDict[\"Pre AP Min (mV)\"] = spike[\"preMinVal\"]\n        # spikeDict['Post AP Min (mV)'] = spike['postMinVal']\n        #\n        # spikeDict['AP Duration (ms)'] = spike['apDuration_ms']\n        spikeDict[\"Early Diastolic Duration (ms)\"] = spike[\n            \"earlyDiastolicDuration_ms\"\n        ]\n        spikeDict[\"Early Diastolic Depolarization Rate (dV/s)\"] = spike[\n            \"earlyDiastolicDurationRate\"\n        ]  # abb 202012\n        spikeDict[\"Diastolic Duration (ms)\"] = spike[\"diastolicDuration_ms\"]\n        #\n        spikeDict[\"Inter-Spike-Interval (ms)\"] = spike[\"isi_ms\"]\n        spikeDict[\"Spike Frequency (Hz)\"] = spike[\"spikeFreq_hz\"]\n        spikeDict[\"ISI (ms)\"] = spike[\"isi_ms\"]\n\n        spikeDict[\"Cycle Length (ms)\"] = spike[\"cycleLength_ms\"]\n\n        spikeDict[\"Max AP Upstroke (dV/dt)\"] = spike[\"preSpike_dvdt_max_val2\"]\n        spikeDict[\"Max AP Upstroke (mV)\"] = spike[\"preSpike_dvdt_max_val\"]\n\n        spikeDict[\"Max AP Repolarization (dV/dt)\"] = spike[\n            \"postSpike_dvdt_min_val2\"\n        ]\n        spikeDict[\"Max AP Repolarization (mV)\"] = spike[\"postSpike_dvdt_min_val\"]\n\n        # half-width\n        for widthDict in spike[\"widths\"]:\n            keyName = \"width_\" + str(widthDict[\"halfHeight\"])\n            spikeDict[keyName] = widthDict[\"widthMs\"]\n\n        spikeDict[\"File\"] = self.ba.fileLoader.filename\n\n        # errors\n        # spikeDict['numError'] = spike['numError']\n        spikeDict[\"errors\"] = spike[\"errors\"]\n\n        # append\n        newList.append(spikeDict)\n\n    df = pd.DataFrame(newList)\n    return df\n</code></pre>"},{"location":"api/bExport/#sanpy.bExport.bExport.report3","title":"<code>report3(sweep='All', epoch='All', theMin=None, theMax=None)</code>","text":"<p>Generate a full report of all spike columns.</p> <p>Like what is save in csv but limited by sweep, epoch, etc</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bExport.py</code> <pre><code>def report3(self, sweep='All',\n            epoch='All',\n            theMin : Optional[float] = None,\n            theMax : Optional[float] = None,\n            ) -&gt; pd.DataFrame:\n\"\"\"Generate a full report of all spike columns.\n\n    Like what is save in csv but limited by sweep, epoch, etc\n    \"\"\"\n\n    if self.ba.numSpikes == 0:\n        logger.warning(f\"did not find and spikes for summary\")\n        return None\n\n    df = self.ba.asDataFrame()  # full df with all spikes\n\n    spikeList = self.ba.getStat('spikeNumber', sweepNumber=sweep, epochNumber=epoch)\n\n    # reduce to spikes in list\n    df = df.loc[df['spikeNumber'].isin(spikeList)]\n\n    if theMin is not None and theMax is not None:\n        df = df[ (df['thresholdSec']&gt;=theMin) &amp; (df['thresholdSec']&lt;theMax)]\n\n    return df\n</code></pre>"},{"location":"api/bExport/#sanpy.bExport.bExport.saveReport","title":"<code>saveReport(savefile, theMin=None, theMax=None, saveExcel=True, alsoSaveTxt=True, verbose=True)</code>","text":"<p>Save a spike report for detected spikes between theMin (sec) and theMax (sec).</p> <p>This is used by main interface 'Export Spike Report'</p> <p>Args:     savefile (str): path to xlsx file     theMin (float): start/stop seconds of the analysis     theMax (float): start/stop seconds of the analysis     saveExcel (bool):     alsoSaveTxt (bool):</p> <p>Return:     str: analysisName     df: df</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/bExport.py</code> <pre><code>def saveReport(\n    self,\n    savefile,\n    theMin=None,\n    theMax=None,\n    saveExcel=True,\n    alsoSaveTxt=True,\n    verbose=True,\n):\n\"\"\"\n    Save a spike report for detected spikes between theMin (sec) and theMax (sec).\n\n    This is used by main interface 'Export Spike Report'\n\n    Args:\n        savefile (str): path to xlsx file\n        theMin (float): start/stop seconds of the analysis\n        theMax (float): start/stop seconds of the analysis\n        saveExcel (bool):\n        alsoSaveTxt (bool):\n\n    Return:\n        str: analysisName\n        df: df\n    \"\"\"\n    if theMin is None or theMax is None:\n        theMin = 0\n        theMax = self.ba.fileLoader.recordingDur\n\n    # always grab a df to the entire analysis (not sure what I will do with this)\n    # df = self.ba.report() # report() is my own 'bob' verbiage\n\n    theRet = None\n\n    logger.warning(\"NEVER SAVING EXCEL !!! dec 2022\")\n    saveExcel = False\n    if saveExcel and savefile:\n        # if verbose: print('    bExport.saveReport() saving user specified .xlsx file:', savefile)\n        excelFilePath = savefile\n        writer = pd.ExcelWriter(excelFilePath, engine=\"xlsxwriter\")\n\n        #\n        # cardiac style analysis to sheet 'cardiac'\n        cardiac_df = self.report2(theMin, theMax)  # report2 is more 'cardiac'\n\n        dDict = self.ba.getDetectionDict()\n        dateAnalyzed = self.ba.dateAnalyzed\n        timeAnalyzed = self.ba.dateAnalyzed\n\n        #\n        # header sheet\n        headerDict = OrderedDict()\n        filePath, fileName = os.path.split(self.ba.filepath)\n        headerDict[\"File Name\"] = [fileName]\n        headerDict[\"File Path\"] = [filePath]\n\n        headerDict[\"Cell Type\"] = [dDict[\"cellType\"]]\n        headerDict[\"Sex\"] = [dDict[\"sex\"]]\n        headerDict[\"Condition\"] = [dDict[\"condition\"]]\n\n        # todo: get these params in ONE dict inside self.ba\n        # dateAnalyzed, timeAnalyzed = self.ba.dateAnalyzed.split(' ')\n        headerDict[\"Date Analyzed\"] = [dateAnalyzed]\n        headerDict[\"Time Analyzed\"] = [timeAnalyzed]\n        headerDict[\"Detection Type\"] = [dDict[\"detectionType\"]]\n        headerDict[\"dV/dt Threshold\"] = [dDict[\"dvdtThreshold\"]]\n        # headerDict['mV Threshold'] = [self.ba.mvThreshold] # abb 202012\n        headerDict[\"Vm Threshold (mV)\"] = [dDict[\"mvThreshold\"]]\n        # headerDict['Median Filter (pnts)'] = [self.ba.medianFilter]\n        headerDict[\"Analysis Version\"] = [sanpy.analysisVersion]\n        headerDict[\"Interface Version\"] = [sanpy.interfaceVersion]\n\n        # headerDict['Analysis Start (sec)'] = [self.ba.startSeconds]\n        # headerDict['Analysis Stop (sec)'] = [self.ba.stopSeconds]\n        headerDict[\"Sweep Number\"] = [\"Default 0\"]  # [self.ba.currentSweep]\n        headerDict[\"Number of Sweeps\"] = [self.ba.fileLoader.numSweeps]\n        headerDict[\"Export Start (sec)\"] = [\n            float(\"%.2f\" % (theMin))\n        ]  # on export, x-axis of raw plot will be ouput\n        headerDict[\"Export Stop (sec)\"] = [\n            float(\"%.2f\" % (theMax))\n        ]  # on export, x-axis of raw plot will be ouput\n\n        # 'stats' has xxx columns (name, mean, sd, se, n)\n        headerDict[\"stats\"] = []\n\n        ignoreColumns = [\"Spike\", \"File\"]\n        for idx, col in enumerate(cardiac_df):\n            if col in ignoreColumns:\n                # in general, need to ignore string columns\n                # headerDict[col].append('')\n                continue\n            headerDict[col] = []\n\n        # mean\n        theMean = cardiac_df.mean()  # skipna default is True\n        theMean[\"errors\"] = \"\"\n        # sd\n        theSD = cardiac_df.std()  # skipna default is True\n        theSD[\"errors\"] = \"\"\n        # se\n        theSE = cardiac_df.sem()  # skipna default is True\n        theSE[\"errors\"] = \"\"\n        # n\n        theN = cardiac_df.count()  # skipna default is True\n        theN[\"errors\"] = \"\"\n\n        statCols = [\"mean\", \"sd\", \"se\", \"n\"]\n        for j, stat in enumerate(statCols):\n            if j == 0:\n                pass\n            else:\n                # need to append columns to keep Excel sheet columns in sync\n                # for k,v in headerDict.items():\n                #    headerDict[k].append('')\n\n                headerDict[\"File Name\"].append(\"\")\n                headerDict[\"File Path\"].append(\"\")\n                headerDict[\"Cell Type\"].append(\"\")\n                headerDict[\"Sex\"].append(\"\")\n                headerDict[\"Condition\"].append(\"\")\n                #\n                headerDict[\"Date Analyzed\"].append(\"\")\n                headerDict[\"Time Analyzed\"].append(\"\")\n                headerDict[\"Detection Type\"].append(\"\")\n                headerDict[\"dV/dt Threshold\"].append(\"\")\n                headerDict[\"Vm Threshold (mV)\"].append(\"\")\n                # headerDict['Median Filter (pnts)'].append('')\n                headerDict[\"Analysis Version\"].append(\"\")\n                headerDict[\"Interface Version\"].append(\"\")\n                headerDict[\"Sweep Number\"].append(\"\")\n                headerDict[\"Number of Sweeps\"].append(\"\")\n                headerDict[\"Export Start (sec)\"].append(\"\")\n                headerDict[\"Export Stop (sec)\"].append(\"\")\n\n            # a dictionary key for each stat\n            headerDict[\"stats\"].append(stat)\n            for idx, col in enumerate(cardiac_df):\n                if col in ignoreColumns:\n                    # in general, need to ignore string columns\n                    # headerDict[col].append('')\n                    continue\n                # headerDict[col].append('')\n                if stat == \"mean\":\n                    headerDict[col].append(theMean[col])\n                elif stat == \"sd\":\n                    headerDict[col].append(theSD[col])\n                elif stat == \"se\":\n                    headerDict[col].append(theSE[col])\n                elif stat == \"n\":\n                    headerDict[col].append(theN[col])\n\n        # print(headerDict)\n        # for k,v in headerDict.items():\n        #    print(k, v)\n\n        # dict to pandas dataframe\n        df = pd.DataFrame(headerDict).T\n        df.to_excel(writer, sheet_name=\"summary\")\n\n        # set the column widths in excel sheet 'cardiac'\n        columnWidth = 25\n        worksheet = writer.sheets[\"summary\"]  # pull worksheet object\n        for idx, col in enumerate(df):  # loop through all columns\n            worksheet.set_column(idx, idx, columnWidth)  # set column width\n\n        #\n        # 'params' sheet with all detection params\n        # need to convert list values in dict to string (o.w. we get one row per item in list)\n        exportDetectionDict = {}\n        for k, v in dDict.items():\n            # v is a dict from bDetection\n            if isinstance(v, list):\n                v = f'\"{v}\"'\n            exportDetectionDict[k] = v\n        # print('  === \"params\" sheet exportDetectionDict:', exportDetectionDict)\n        # df = pd.DataFrame(exportDetectionDict, index=[0]).T # index=[0] needed when dict has all scalar values\n        detection_df = pd.DataFrame(exportDetectionDict).T\n        detection_df.to_excel(writer, sheet_name=\"params\")\n        # worksheet is &lt;class 'xlsxwriter.worksheet.Worksheet'&gt;\n        worksheet = writer.sheets[\"params\"]  # pull worksheet object\n        # set first 20 columns to columnWidth\n        columnWidth = 18\n        startCol = 0\n        stopCol = 20  # xlswriter.worksheet does not care about the stop column\n        worksheet.set_column(0, stopCol, columnWidth)  # set column width\n\n        #\n        # 'cardiac' sheet with human readable stat names\n        cardiac_df.to_excel(writer, sheet_name=\"cardiac\")\n\n        # set the column widths in excel sheet 'cardiac'\n        columnWidth = 20\n        worksheet = writer.sheets[\"cardiac\"]  # pull worksheet object\n        for idx, col in enumerate(cardiac_df):  # loop through all columns\n            worksheet.set_column(idx, idx, columnWidth)  # set column width\n\n        #\n        # mean spike clip\n        theseClips, theseClips_x, meanClip = self.ba.getSpikeClips(\n            theMin, theMax, sweepNumber=self.sweepNumber\n        )\n        try:\n            first_X = theseClips_x[0]  # - theseClips_x[0][0]\n            # if verbose: print('    bExport.saveReport() saving mean clip to sheet \"Avg Spike\" from', len(theseClips), 'clips')\n            df = pd.DataFrame(meanClip, first_X)\n            df.to_excel(writer, sheet_name=\"Avg Spike\")\n        except IndexError as e:\n            logger.warning(\"Got bad spike clips. Usually happend when 1-2 spikes\")\n\n        writer.save()\n\n    #\n    # save a csv text file\n    #\n    analysisName = \"\"\n    if alsoSaveTxt:\n        # this also saves\n        analysisName, df0 = self.getReportDf(theMin, theMax, savefile)\n\n        #\n        # save mean spike clip\n\n        not_used_theseClips, theseClips_x, meanClip = self.ba.getSpikeClips(\n            theMin, theMax, sweepNumber=self.sweepNumber\n        )\n        if len(theseClips_x) == 0:\n            pass\n        else:\n            first_X = theseClips_x[0]  # - theseClips_x[0][0]\n            first_X = np.array(first_X)\n            first_X /= self.ba.fileLoader.dataPointsPerMs  # pnts to ms\n            # if verbose: print('    bExport.saveReport() saving mean clip to sheet \"Avg Spike\" from', len(theseClips), 'clips')\n            # dfClip = pd.DataFrame(meanClip, first_X)\n            dfClip = pd.DataFrame.from_dict({\"xMs\": first_X, \"yVm\": meanClip})\n            # load clip based on analysisname (with start/stop seconds)\n            analysisname = df0[\"analysisname\"].iloc[\n                0\n            ]  # name with start/stop seconds\n            logger.info(f\"analysisname: {analysisname}\")\n            clipFileName = analysisname + \"_clip.csv\"\n            tmpPath, tmpFile = os.path.split(savefile)\n            tmpPath = os.path.join(tmpPath, \"analysis\")\n            # dir is already created in getReportDf\n            if not os.path.isdir(tmpPath):\n                os.mkdir(tmpPath)\n            clipSavePath = os.path.join(tmpPath, clipFileName)\n            logger.info(f\"clipSavePath: {clipSavePath}\")\n            dfClip.to_csv(clipSavePath)\n        #\n        theRet = df0\n    #\n    return analysisName, theRet\n</code></pre>"},{"location":"api/epochTable/","title":"epochTable","text":""},{"location":"api/epochTable/#sanpy.epochTable-classes","title":"Classes","text":""},{"location":"api/epochTable/#sanpy.fileloaders.epochTable.epochTable","title":"<code>epochTable</code>","text":"<p>Load epoch/stimulation from abf file using 'sweepEpochs'.</p> <p>Values in epoch table are per sweep!</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/epochTable.py</code> <pre><code>class epochTable:\n\"\"\"Load epoch/stimulation from abf file using 'sweepEpochs'.\n\n    Values in epoch table are per sweep!\n    \"\"\"\n\n    def __init__(self, abf: pyabf.ABF):\n        self._epochList = []\n\n        dataPointsPerMs = abf.dataPointsPerMs\n\"\"\"To convert point to seconds\"\"\"\n\n        try:\n            _tmp = abf.sweepEpochs.p1s\n        except AttributeError as e:\n            logger.error(e)\n            return\n\n        # sweepEpochs is type \"pyabf.waveform.EpochSweepWaveform\"\n        for epochIdx, p1 in enumerate(abf.sweepEpochs.p1s):\n            p2 = abf.sweepEpochs.p2s[epochIdx]  # stop point of each pulse\n            epochLevel = abf.sweepEpochs.levels[epochIdx]\n            epochType = abf.sweepEpochs.types[epochIdx]\n            pulseWidth = abf.sweepEpochs.pulseWidths[epochIdx]\n            pulsePeriod = abf.sweepEpochs.pulsePeriods[epochIdx]\n            digitalState = abf.sweepEpochs.pulsePeriods[epochIdx]\n            ##print(f\"epoch index {epochIdx}: at point {p1} there is a {epochType} to level {epochLevel}\")\n\n            p1_sec = p1 / abf.dataPointsPerMs / 1000\n            p2_sec = p2 / abf.dataPointsPerMs / 1000\n\n            epochDict = {\n                \"sweepNumber\": abf.sweepNumber,\n                \"index\": epochIdx,\n                \"type\": epochType,\n                \"startPoint\": p1,  # point the epoch starts\n                \"stopPoint\": p2,  # point the epoch ends\n                \"startSec\": p1_sec,\n                \"stopSec\": p2_sec,\n                \"durSec\": p2_sec - p1_sec,\n                \"level\": epochLevel,\n                \"pulseWidth\": pulseWidth,\n                \"pulsePeriod\": pulsePeriod,\n                \"digitalState\": digitalState,  # list of 0/1 for 8x digital states\n            }\n            self._epochList.append(epochDict)\n\n    def getEpochList(self, asDataFrame: bool = False):\n        if asDataFrame:\n            return pd.DataFrame(self._epochList)\n        else:\n            return self._epochList\n\n    def findEpoch(self, pnt: int) -&gt; Optional[int]:\n\"\"\"Return epoch index for a point in recording.\n\n        Stop points are always the same as next epoch start point.\n        Be sure to use '&lt;' like pnt&lt;stopPnt to get epoch index correct.\n\n        If not found, return None\n\n        Parameters\n        ----------\n        pnt : int\n            Point index into recording (within a sweep)\n        \"\"\"\n        for epochIdx, epoch in enumerate(self._epochList):\n            startPoint = epoch[\"startPoint\"]\n            stopPoint = epoch[\"stopPoint\"]\n            if pnt &gt;= startPoint and pnt &lt; stopPoint:\n                return epochIdx\n        #\n        # return None\n\n    def getLevel(self, epoch):\n\"\"\"Given an epoch number return the 'level'\"\"\"\n        return self._epochList[epoch][\"level\"]\n\n    def getStartSec(self, epoch):\n\"\"\"Given an epoch number return the 'startSec'\"\"\"\n        return self._epochList[epoch][\"startSec\"]\n\n    def getStartSecs(self):\n\"\"\"Return all epoch start times.\"\"\"\n        startSecs = [epoch[\"startSec\"] for epoch in self._epochList]\n        return startSecs\n\n    def getEpochLines(self, yMin=0, yMax=1):\n        x = [float(\"nan\")] * (self.numEpochs() * 3)\n        y = [float(\"nan\")] * (self.numEpochs() * 3)\n\n        for epoch in range(self.numEpochs()):\n            idx = epoch * 3\n            x[idx] = self._epochList[epoch][\"startSec\"]\n            x[idx + 1] = self._epochList[epoch][\"startSec\"]\n            x[idx + 2] = float(\"nan\")\n\n            y[idx] = yMin\n            y[idx + 1] = yMax\n            y[idx + 2] = float(\"nan\")\n\n        return x, y\n\n    def numEpochs(self):\n        # print('qqq:', self._epochList)\n        return len(self._epochList)\n</code></pre>"},{"location":"api/epochTable/#sanpy.fileloaders.epochTable.epochTable-functions","title":"Functions","text":""},{"location":"api/epochTable/#sanpy.fileloaders.epochTable.epochTable.findEpoch","title":"<code>findEpoch(pnt)</code>","text":"<p>Return epoch index for a point in recording.</p> <p>Stop points are always the same as next epoch start point. Be sure to use '&lt;' like pnt&lt;stopPnt to get epoch index correct.</p> <p>If not found, return None</p> <p>Parameters:</p> Name Type Description Default <code>pnt</code> <code>int</code> <p>Point index into recording (within a sweep)</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/epochTable.py</code> <pre><code>def findEpoch(self, pnt: int) -&gt; Optional[int]:\n\"\"\"Return epoch index for a point in recording.\n\n    Stop points are always the same as next epoch start point.\n    Be sure to use '&lt;' like pnt&lt;stopPnt to get epoch index correct.\n\n    If not found, return None\n\n    Parameters\n    ----------\n    pnt : int\n        Point index into recording (within a sweep)\n    \"\"\"\n    for epochIdx, epoch in enumerate(self._epochList):\n        startPoint = epoch[\"startPoint\"]\n        stopPoint = epoch[\"stopPoint\"]\n        if pnt &gt;= startPoint and pnt &lt; stopPoint:\n            return epochIdx\n</code></pre>"},{"location":"api/epochTable/#sanpy.fileloaders.epochTable.epochTable.getLevel","title":"<code>getLevel(epoch)</code>","text":"<p>Given an epoch number return the 'level'</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/epochTable.py</code> <pre><code>def getLevel(self, epoch):\n\"\"\"Given an epoch number return the 'level'\"\"\"\n    return self._epochList[epoch][\"level\"]\n</code></pre>"},{"location":"api/epochTable/#sanpy.fileloaders.epochTable.epochTable.getStartSec","title":"<code>getStartSec(epoch)</code>","text":"<p>Given an epoch number return the 'startSec'</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/epochTable.py</code> <pre><code>def getStartSec(self, epoch):\n\"\"\"Given an epoch number return the 'startSec'\"\"\"\n    return self._epochList[epoch][\"startSec\"]\n</code></pre>"},{"location":"api/epochTable/#sanpy.fileloaders.epochTable.epochTable.getStartSecs","title":"<code>getStartSecs()</code>","text":"<p>Return all epoch start times.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/epochTable.py</code> <pre><code>def getStartSecs(self):\n\"\"\"Return all epoch start times.\"\"\"\n    startSecs = [epoch[\"startSec\"] for epoch in self._epochList]\n    return startSecs\n</code></pre>"},{"location":"api/overview/","title":"Overview","text":"<p>The SanPy API is split into two main sections</p> <p>1) Backend. This is where most of the work will be done. It provides the core functionality and all code can easily be used in a script, a Jupyter notebook, or an existing Python package.</p> <p>2) Frontend. This is the code that drives the SanPy desktop GUI.</p> <p>See an example of how to use the backend API to load, analyze, and plot.</p> <p>The backend provides three additional software architectures that provide a powerful and easy to use mechanism to extend the capabilities of SanPy including:</p> <ul> <li> <p>Custom File Loaders. With this, new raw data formats can be loaded into SanPy.</p> </li> <li> <p>Extending the core analysis. With this, new analysis can be performed and automatically integrated into the main SanPy analysis.</p> </li> <li> <p>Writing new plugins. With this, new plugins can be created for use in the frontend desktop GUI.</p> </li> </ul>"},{"location":"api/writing-a-file-loader/","title":"Writing A File Loader","text":""},{"location":"api/writing-a-file-loader/#how-to-write-a-custom-sanpy-file-loader","title":"How to write a custom SanPy file loader.","text":"<p>1) Derive a new class from sanpy.fileloaders.fileLoader_base.</p> <p>2) Specify the file extension you want to load with <code>loadFileType = 'your_file_extension'</code></p> <p>3) In a <code>loadFile()</code> member function, load your raw data file</p> <p>4) Call <code>self.setLoadedData(...)</code> with the results. </p> <p>5) Place your file loader py file in the <code>&lt;User&gt;/Documents/SanPy/file loaders</code> folder.</p> <p>6) Run SanPy and make sure it works!</p> <p>Coming Soon. We will provide unit testing for user file loaders.</p> <p>Here is some sample code to get started, this is taken from the SanPy CSV file loader fileLoader_csv.</p> <pre><code>import sanpy.fileloaders.fileLoader_base as fileLoader_base\n\nclass fileLoader_csv(fileLoader_base):\n    loadFileType = 'csv'\n\n    def loadFile(self):\n\"\"\"Load file and call setLoadedData().\n\n        Use self.filepath for the file path to load\n        \"\"\"\n</code></pre> <p>The function signature for <code>setLoadedData</code> is as follows. There are only two required parameters and a number of optional parameters.</p> <pre><code>    def setLoadedData(self,\n        sweepX : np.ndarray,\n        sweepY : np.ndarray,\n        sweepC : Optional[np.ndarray] = None,\n        recordingMode : recordingModes = recordingModes.iclamp,\n        xLabel : str = '',\n        yLabel : str = ''):\n\n\"\"\"\n        Parameters\n        ----------\n        sweepX : np.ndarray\n            Time values\n        sweepY : np.ndarray\n            Recording values, mV or pA\n        sweepC : np.ndarray\n            (optional) DAC stimulus, pA or mV\n        recordingMode : recordingModes\n            (optional) Defaults to recordingModes.iclamp)\n        xLabel : str\n            (optional) str for x-axis label\n        yLabel : str\n            (optional) str for y-axis label\n        \"\"\"\n</code></pre>"},{"location":"api/writing-a-plugin/","title":"Writing A Plugin","text":""},{"location":"api/writing-a-plugin/#how-to-write-a-sanpy-plugin","title":"How to write a SanPy plugin.","text":"<p>1) Derive a class from sanpy.interface.plugins.sanpyPlugin</p> <p>2) Give you plugin a name by defining the static property <code>myHumanName = 'Nice name for your plugin</code>.</p> <p>3) Build your user interface in a <code>plot()</code> member function.</p> <p>4) Have your plugin respond to the main interface by reploting in a <code>replot()</code> member function.     This is to enable your plugin to respond to different pre-defined interface changes, see below.</p> <p>5) Place you new plugin py file in the <code>&lt;user&gt;Documents/SanPy/plugins</code> folder</p> <p>6) Run SanPy and it will append you plugin to the list of available plugins in the <code>Plugins Menu</code>.</p> <p>Coming soon. We will provide unit tests to ensure new plugins is working.</p> <p>Here is a template to get started. This is the same as gets installed in the User plugin folder file <code>exampleUserPlugin.py</code>.</p> <pre><code>from sanpy.interface.plugins import sanpyPlugin\n\nclass exampleUserPlugin1(sanpyPlugin):\n\"\"\"\n    Plot x/y statistics as a scatter\n\n    Get stat names and variables from sanpy.bAnalysisUtil.getStatList()\n    \"\"\"\n    myHumanName = 'Example User Plugin 1'\n\n    def plot(self):\n\"\"\"Create the plot in the widget (called once).\n        \"\"\"\n\n        # embed a matplotlib axis (self.axs)\n        self.mplWindow2() # assigns (self.fig, self.axs)\n\n        # plot a white line with raw data\n        self._lineRaw, = self.axs.plot([], [], '-w', linewidth=0.5)\n\n        # plot red circles with spike threshold\n        self._lineDetection, = self.axs.plot([], [], 'ro')\n\n    def replot(self):\n\"\"\"Replot the widget. Usually when the file is switched\n        \"\"\"\n        # get the x/y values from the recording\n        sweepX = self.getSweep('x')\n        sweepY = self.getSweep('y')\n\n        # update plot of raw data\n        self._lineRaw.set_data(sweepX, sweepY)\n\n        # update plot of spike threshold\n        thresholdSec = self.ba.getStat('thresholdSec')\n        thresholdVal = self.ba.getStat('thresholdVal')\n        self._lineDetection.set_data(thresholdSec, thresholdVal)\n\n        # make sure the matplotlib axis auto scale\n        self.axs.relim()\n        self.axs.autoscale_view(True,True,True)\n\n        # plt.draw()\n        self.static_canvas.draw()\n</code></pre>"},{"location":"api/writing-new-analysis/","title":"Writing New Analysis","text":""},{"location":"api/writing-new-analysis/#how-to-extend-the-analysis-of-sanpy-with-user-specified-analysis","title":"How to extend the analysis of SanPy with user specified analysis","text":"<p>The core analysis algorithm of SanPy can be easily extended by the user.</p> <p>1) Derive a class from sanpy.user_analysis.baseUserAnalysis</p> <p>To Be continued, stand by !!!</p>"},{"location":"api/fileloader/fileLoader_abf/","title":"fileLoader_abf","text":""},{"location":"api/fileloader/fileLoader_abf/#sanpy.fileloaders.fileLoader_abf-classes","title":"Classes","text":""},{"location":"api/fileloader/fileLoader_abf/#sanpy.fileloaders.fileLoader_abf.fileLoader_abf","title":"<code>fileLoader_abf</code>","text":"<p>         Bases: <code>fileLoader_base</code></p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_abf.py</code> <pre><code>class fileLoader_abf(fileLoader_base):\n    loadFileType = \"abf\"\n\n    # @property\n    # def loadFileType(self):\n    #     return 'abf'\n\n    def loadFile(self):\n        self._loadAbf()\n\n    def _loadAbf(\n        self, byteStream=None, loadData: bool = True, stimulusFileFolder: str = None\n    ):\n\"\"\"Load pyAbf from path.\"\"\"\n        try:\n            # logger.info(f'loadData:{loadData}')\n            if byteStream is not None:\n                logger.info(\"Loading byte stream\")\n                self._abf = pyabf.ABF(byteStream)\n                self._isBytesIO = True\n            else:\n                # logger.info(f'Loading file: {self.filepath}')\n                self._abf = pyabf.ABF(\n                    self.filepath,\n                    loadData=loadData,\n                    stimulusFileFolder=stimulusFileFolder,\n                )\n\n        except NotImplementedError as e:\n            logger.error(f\"    did not load abf file: {self.filepath}\")\n            logger.error(f\"      NotImplementedError exception was: {e}\")\n            self._loadError = True\n            self._abf = None\n\n        except Exception as e:\n            # some abf files throw: 'unpack requires a buffer of 234 bytes'\n            # 'ABF' object has no attribute 'sweepEpochs'\n            logger.error(f\"    did not load abf file: {self.filepath}\")\n            logger.error(f\"        unknown Exception was: {e}\")\n            self._loadError = True\n            self._abf = None\n\n        if loadData:\n            try:\n                _tmp = self._abf.sweepEpochs.p1s\n            except AttributeError as e:\n                logger.warning(\n                    f\"    did not find epochTable loadData:{loadData}: {e} in file {self.filepath}\"\n                )\n            else:\n                _numSweeps = len(self._abf.sweepList)\n                self._epochTableList = [None] * _numSweeps\n                for _sweepIdx in range(_numSweeps):\n                    self._abf.setSweep(_sweepIdx)\n                    self._epochTableList[_sweepIdx] = sanpy.fileloaders.epochTable(\n                        self._abf\n                    )\n                self._abf.setSweep(0)\n\n            self._sweepList = self._abf.sweepList\n            self._sweepLengthSec = (\n                self._abf.sweepLengthSec\n            )  # assuming all sweeps have the same duration\n\n            # on load, sweep is 0\n            if loadData:\n                _numRows = self._abf.sweepX.shape[0]\n                numSweeps = len(self._sweepList)\n                self._sweepX = np.zeros((_numRows, 1))\n                self._sweepY = np.zeros((_numRows, numSweeps))\n                self._sweepC = np.zeros((_numRows, numSweeps))\n\n                _channel = 0\n                for sweep in self._sweepList:\n                    self._abf.setSweep(sweepNumber=sweep, channel=_channel)\n                    if sweep == 0:\n                        self._sweepX[\n                            :, sweep\n                        ] = self._abf.sweepX  # &lt;class 'numpy.ndarray'&gt;, (60000,)\n                    self._sweepY[:, sweep] = self._abf.sweepY\n                    try:\n                        self._sweepC[:, sweep] = self._abf.sweepC\n                    except ValueError as e:\n                        # pyabf will raise this error if it is an atf file\n                        logger.warning(\n                            f\"    exception fetching sweepC for sweep {sweep} with {self.numSweeps}: {e}\"\n                        )\n                        #\n                        # if we were recorded with a stimulus file abf\n                        # needed to assign stimulusWaveformFromFile\n                        try:\n                            tmpSweepC = self._abf.sweepC\n                            self._sweepC[:, sweep] = self._abf.sweepC\n                        except ValueError as e:\n                            logger.warning(f\"ba has no sweep {sweep} sweepC ???\")\n\n                # not needed\n                self._abf.setSweep(0)\n\n            # get v from pyAbf\n            self._dataPointsPerMs = self._abf.dataPointsPerMs\n\n            # turned back on when implementing Santana rabbit Ca kymographs\n            abfDateTime = self._abf.abfDateTime  # 2019-01-14 15:20:48.196000\n            self._acqDate = abfDateTime.strftime(\"%Y-%m-%d\")\n            self._acqTime = abfDateTime.strftime(\"%H:%M:%S\")\n\n            self._numChannels = len(self._abf.adcUnits)\n            if self._numChannels &gt; 1:\n                logger.warning(\n                    f\"    SanPy does not work with multi-channel recordings numChannels is {self._numChannels} {self._path}\"\n                )\n                # logger.warning('    Will default to channel 0')\n\n            # self.sweepUnitsY = self.adcUnits[channel]\n            channel = 0\n            # dacUnits = self._abf.dacUnits[channel]\n            adcUnits = self._abf.adcUnits[channel]\n            # print('  adcUnits:', adcUnits)  # 'mV'\n            self._sweepLabelY = adcUnits\n            self._sweepLabelX = \"sec\"\n\n            # self._sweepLabelX = self._abf.sweepLabelX\n            # self._sweepLabelY = self._abf.sweepLabelY\n            if self._sweepLabelY in [\"pA\", \"nA\"]:\n                self._recordingMode = recordingModes.vclamp  # 'V-Clamp'\n                # self._sweepY_label = self._abf.sweepUnitsY\n            elif self._sweepLabelY in [\"mV\"]:\n                self._recordingMode = recordingModes.iclamp  #'I-Clamp'\n                # self._sweepY_label = self._abf.sweepUnitsY\n            else:\n                logger.warning(f'did not understand adcUnit \"{adcUnits}\"')\n\n        #\n        self.myFileType = \"abf\"\n\n        # base sanpy does not keep the abf around\n        # logger.warning('[[[TURNED BACK ON]]] I turned off assigning self._abf=None for stoch-res stim file load')\n        self._abf = None\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/","title":"fileLoader_base","text":""},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base-classes","title":"Classes","text":""},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base","title":"<code>fileLoader_base</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Abstract base class to derive file loaders.</p> <p>For some working examples of derived classes, see fileLoader_abf and fileLoader_csv</p> <p>To create a file loader</p> <p>1) derive a class from fileLoader_base and define <code>loadFileType</code></p> <pre><code>class myFileLoader(fileLoader_base):\n    loadFileType = 'the_file_extension_this_will_load'\n</code></pre> <p>2) Define a <code>loadFile</code> function</p> <pre><code>def loadFile(self):\n    # load the data from self.filepath and create sweepX and sweepY\n    # specify what was loaded\n    self.setLoadedData(sweepX, sweepY)\n</code></pre> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>class fileLoader_base(ABC):\n\"\"\"Abstract base class to derive file loaders.\n\n    For some working examples of derived classes, see\n    [fileLoader_abf](../../api/fileloader/fileLoader_abf.md) and\n    [fileLoader_csv](../../api/fileloader/fileLoader_csv.md)\n\n    To create a file loader\n\n    1) derive a class from fileLoader_base and define `loadFileType`\n\n        class myFileLoader(fileLoader_base):\n            loadFileType = 'the_file_extension_this_will_load'\n\n    2) Define a `loadFile` function\n\n        def loadFile(self):\n            # load the data from self.filepath and create sweepX and sweepY\n            # specify what was loaded\n            self.setLoadedData(sweepX, sweepY)\n\n    \"\"\"\n\n    loadFileType: str = \"\"\n    # @property\n    # @abstractmethod\n    # def loadFileType(self) -&gt; str:\n    #     \"\"\"Derived classes must return the file type to handle.\n    #     For example, 'csv', or 'm', or 'dat'\n    #     \"\"\"\n    #     pass\n\n    @abstractmethod\n    def loadFile(self):\n\"\"\"Derived classes must load the data and call setLoadedData(sweepX, sweepY).\"\"\"\n        pass\n\n    def __init__(self, filepath: str, loadData: bool = True):\n\"\"\"Base class to derive new file loaders.\n\n        Parameters\n        ----------\n        filepath : str\n            File path to load. Will use different derived classes based on extension\n        loadData : bool\n            If True then load raw data, otherwise just load the header.\n        \"\"\"\n\n        super().__init__()\n\n        self._loadError = False\n\n        self._path = filepath\n\n        self._filteredY : np.ndarray = None  # set in _getDerivative\n        self._filteredDeriv : np.ndarray = None\n        self._currentSweep: int = 0\n\n        self._epochTableList: List[sanpy.fileloaders.epochTable] = None\n\n        # load file from inherited class\n        self.loadFile()\n\n        # check our work\n        self._checkLoadedData()\n\n    def __str__(self):\n\"\"\"Get a short string representing this file.\"\"\"\n        txt = f\"file: {self.filename} sweeps: {self.numSweeps} dur (Sec):{self.recordingDur}\"\n        return txt\n\n    def isKymograph(self) -&gt; bool:\n        return isinstance(self, sanpy.fileloaders.fileLoader_tif)\n\n    @property\n    def filepath(self) -&gt; str:\n\"\"\"Get the full file path.\"\"\"\n        return self._path\n\n    @property\n    def filename(self) -&gt; str:\n\"\"\"Get the filename.\"\"\"\n        if self.filepath is None:\n            return None\n        else:\n            return os.path.split(self.filepath)[1]\n\n    @property\n    def numChannels(self) -&gt; int:\n\"\"\"Get the number of channels.\n\n        If more than one channel, must be defined in derived class.\n        \"\"\"\n        return 1\n\n    @property\n    def currentSweep(self) -&gt; int:\n\"\"\"Get the current sweep.\"\"\"\n        return self._currentSweep\n\n    def setSweep(self, currentSweep: int):\n\"\"\"Set the current sweep.\"\"\"\n        if currentSweep &gt; self.numSweeps - 1:\n            logger.error(f\"max sweep is {self.numSweeps-1}, got {currentSweep}\")\n            return\n        self._currentSweep = currentSweep\n\n    @property\n    def recordingMode(self):\n        return self._recordingMode\n\n    # feb 2023, uncommented\n    @property\n    def sweepLabelX(self):\n        return self._sweepLabelX\n\n    @property\n    def sweepLabelY(self):\n        return self._sweepLabelY\n\n    @property\n    def recordingDur(self):\n        return self._sweepLengthSec\n\n    @property\n    def numSweeps(self):\n        return len(self._sweepList)\n\n    @property\n    def sweepList(self):\n        return self._sweepList\n\n    @property\n    def dataPointsPerMs(self):\n        return self._dataPointsPerMs\n\n    @property\n    def acqDate(self):\n        return self._acqDate\n\n    @property\n    def acqTime(self):\n        return self._acqTime\n\n    @property\n    def sweepX(self):\n\"\"\"Get the X-Values for a sweep.\n\n        Notes\n        -----\n        All sweeps are assumed to have the same x-values (seconds).\n        \"\"\"\n        # return self._sweepX[:, self.currentSweep]\n        return self._sweepX[:, 0]\n\n    @property\n    def sweepY(self):\n\"\"\"Get the Y values for the current sweep.\"\"\"\n        return self._sweepY[:, self.currentSweep]\n\n    @property\n    def sweepC(self):\n\"\"\"Get the DAC command for the current sweep.\"\"\"\n        if self._sweepC is None:\n            # return np.zeros_like(self._sweepX[:, self.currentSweep])\n            return np.zeros_like(self._sweepX[:, 0])\n        return self._sweepC[:, self.currentSweep]\n\n    def get_xUnits(self):\n        return self._sweepLabelX\n\n    def get_yUnits(self):\n        return self._sweepLabelY\n\n    @property\n    def filteredDeriv(self) -&gt; Optional[np.ndarray]:\n\"\"\"Get the filtered first derivative of sweepY.\"\"\"\n        if self._filteredDeriv is not None:\n            return self._filteredDeriv[:, self.currentSweep]\n        else:\n            return None\n\n    def _getDerivative(\n        self,\n        medianFilter: int = 0,\n        SavitzkyGolay_pnts: int = 5,\n        SavitzkyGolay_poly: int = 2,\n    ):\n\"\"\"Get filtered version of recording and derivative of recording (used for I-Clamp).\n\n            By default we will use a SavitzkyGolay filter with 5 points and a 2nd order polynomial.\n\n        Parameters\n        ----------\n        medianFilter : int\n            Median filter box with. Must be odd, specify 0 for no median filter\n        SavitzkyGolay_pnts : int\n            Specify 0 for no filter.\n        SavitzkyGolay_poly : int\n\n        Notes\n        -----\n        Creates:\n            self._filteredVm\n            self._filteredDeriv\n        \"\"\"\n\n        # logger.info(f'{self.filename} medianFilter:{medianFilter} SavitzkyGolay_pnts:{SavitzkyGolay_pnts} SavitzkyGolay_poly:{SavitzkyGolay_poly}')\n\n        if not isinstance(medianFilter, int):\n            logger.error(f\"expecting int medianFilter, got: {medianFilter}\")\n\n        if medianFilter &gt; 0:\n            if not medianFilter % 2:\n                medianFilter += 1\n                logger.warning(\n                    \"Please use an odd value for the median filter, set medianFilter: {medianFilter}\"\n                )\n            medianFilter = int(medianFilter)\n            self._filteredY = scipy.signal.medfilt2d(self._sweepY, [medianFilter, 1])\n        elif SavitzkyGolay_pnts &gt; 0:\n            self._filteredY = scipy.signal.savgol_filter(\n                self._sweepY,\n                SavitzkyGolay_pnts,\n                SavitzkyGolay_poly,\n                axis=0,\n                mode=\"nearest\",\n            )\n        else:\n            self._filteredY = self.sweepY\n\n        self._filteredDeriv = np.diff(self._filteredY, axis=0)\n\n        # filter the derivative\n        if medianFilter &gt; 0:\n            if not medianFilter % 2:\n                medianFilter += 1\n                print(\n                    f\"Please use an odd value for the median filter, set medianFilter: {medianFilter}\"\n                )\n            medianFilter = int(medianFilter)\n            self._filteredDeriv = scipy.signal.medfilt2d(\n                self._filteredDeriv, [medianFilter, 1]\n            )\n        elif SavitzkyGolay_pnts &gt; 0:\n            self._filteredDeriv = scipy.signal.savgol_filter(\n                self._filteredDeriv,\n                SavitzkyGolay_pnts,\n                SavitzkyGolay_poly,\n                axis=0,\n                mode=\"nearest\",\n            )\n        else:\n            # self._filteredDeriv = self.filteredDeriv\n            pass\n\n        # mV/ms\n        dataPointsPerMs = self.dataPointsPerMs\n        self._filteredDeriv = self._filteredDeriv * dataPointsPerMs  # / 1000\n\n        # insert an initial point (rw) so it is the same length as raw data in abf.sweepY\n        # three options (concatenate, insert, vstack), could only get vstack working\n        rowOfZeros = np.zeros(self.numSweeps)\n\n        # logger.info(f' dataPointsPerMs:{dataPointsPerMs}')\n        # logger.info(f' self.numSweeps:{self.numSweeps}')\n        # logger.info(f' rowOfZeros:{rowOfZeros.shape}')\n        # logger.info(f' 1 - _filteredDeriv:{self._filteredDeriv.shape}')\n\n        # rowZero = 0\n        self._filteredDeriv = np.vstack([rowOfZeros, self._filteredDeriv])\n\n        # logger.info(f'  sweepX:{self.sweepX.shape}')\n        # logger.info(f'  sweepY:{self.sweepY.shape}')\n        # logger.info(f'  _filteredY:{self._filteredY.shape}')\n        # logger.info(f'  2- _filteredDeriv:{self._filteredDeriv.shape}')\n\n    @property\n    def sweepY_filtered(self) -&gt; np.ndarray:\n\"\"\"Get a filtered version of sweepY.\"\"\"\n        if self._filteredY is not None:\n            return self._filteredY[:, self.currentSweep]\n\n    @property\n    def recordingFrequency(self) -&gt; int:\n\"\"\"Convenience for dataPointsPerMs, recording frequency in kHz.\"\"\"\n        return self.dataPointsPerMs\n\n    def pnt2Sec_(self, pnt: int) -&gt; float:\n\"\"\"Convert a point to seconds using dataPointsPerMs.\n\n        Parameters\n        ----------\n        pnt : int\n\n        Returns\n        -------\n        float\n            The point in seconds (s)\n        \"\"\"\n        if pnt is None:\n            # return math.isnan(pnt)\n            return math.nan\n        else:\n            return pnt / self.dataPointsPerMs / 1000\n\n    def pnt2Ms_(self, pnt: int) -&gt; float:\n\"\"\"\n        Convert a point to milliseconds (ms) using `self.dataPointsPerMs`\n\n        Parameters\n        ----------\n        pnt : int\n\n        Returns\n        -------\n        float\n            The point in milliseconds (ms)\n        \"\"\"\n        return pnt / self.dataPointsPerMs\n\n    def ms2Pnt_(self, ms: float) -&gt; int:\n\"\"\"\n        Convert milliseconds (ms) to point in recording using `self.dataPointsPerMs`\n\n        Parameters\n        ----------\n        ms : float\n            The ms into the recording\n\n        Returns\n        -------\n        int\n            The point in the recording corresponding to ms\n        \"\"\"\n        theRet = ms * self.dataPointsPerMs\n        theRet = round(theRet)\n        return theRet\n\n    def getEpochTable(self, sweep: int):\n\"\"\"Only proper abf files will have an epoch table.\n\n        TODO: Make all file loders have an epoch table.\n            Make API so derived file loaders can create their own\n        \"\"\"\n        if self._epochTableList is not None:\n            return self._epochTableList[sweep]\n        else:\n            return None\n\n    @property\n    def numEpochs(self) -&gt; Optional[int]:\n\"\"\"Get the number of epochs.\n\n        Epochs are mostly for pClamp abf files. We are assuming each sweep has the same namber of epochs.\n        \"\"\"\n        if self._epochTableList is not None:\n            return self._epochTableList[0].numEpochs()\n\n    def _checkLoadedData(self):\n        # TODO: check all the member vraiables are correct\n        # set error if they are not\n        pass\n\n    def setLoadedData(\n        self,\n        sweepX: np.ndarray,\n        sweepY: np.ndarray,\n        sweepC: Optional[np.ndarray] = None,\n        recordingMode: recordingModes = recordingModes.iclamp,\n        xLabel: str = \"\",\n        yLabel: str = \"\",\n    ):\n\"\"\"Derived classes call this function once the data is loaded in loadFile().\n\n        Parameters\n        ----------\n        sweepX : np.ndarray\n            Time values\n        sweepY : np.ndarray\n            Recording values, mV or pA\n        sweepC : np.ndarray\n            (optional) DAC stimulus, pA or mV\n        recordingMode : recordingModes\n            (optional) Defaults to recordingModes.iclamp)\n        xLabel : str\n            (optional) str for x-axis label\n        yLabel : str\n            (optional) str for y-axis label\n\n        Notes\n        -----\n        - Number of sweeps: sweepY.shape[1]\n        - Sweep Length (sec): sweepX[-1,0]\n        - Data Points Per Millisecond: 1 / ((sweepX[1,0] - sweepX[0,0]) * 1000)\n        \"\"\"\n        self._sweepX = sweepX\n        self._sweepY = sweepY\n        self._sweepC = sweepC\n\n        self._numSweeps: int = self._sweepY.shape[1]\n        self._sweepList: List[int] = list(range(self._numSweeps))\n\n        self._sweepLengthSec: float = self._sweepX[-1, 0]  # from 0 to last sample point\n\n        dtSeconds = self._sweepX[1, 0] - self._sweepX[0, 0]  # seconds per sample\n        dtSeconds = float(dtSeconds)\n        dtMilliseconds = dtSeconds * 1000\n        _dataPointsPerMs = int(1 / dtMilliseconds)\n        # logger.info(f'dtSeconds:{dtSeconds} dtMilliseconds:{dtMilliseconds} _dataPointsPerMs:{_dataPointsPerMs}')\n        self._dataPointsPerMs: int = _dataPointsPerMs\n\n        self._recordingMode: recordingModes = recordingMode\n        self._sweepLabelX: str = xLabel\n        self._sweepLabelY: str = yLabel\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base-attributes","title":"Attributes","text":""},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.currentSweep","title":"<code>currentSweep: int</code>  <code>property</code>","text":"<p>Get the current sweep.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.filename","title":"<code>filename: str</code>  <code>property</code>","text":"<p>Get the filename.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.filepath","title":"<code>filepath: str</code>  <code>property</code>","text":"<p>Get the full file path.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.filteredDeriv","title":"<code>filteredDeriv: Optional[np.ndarray]</code>  <code>property</code>","text":"<p>Get the filtered first derivative of sweepY.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.numChannels","title":"<code>numChannels: int</code>  <code>property</code>","text":"<p>Get the number of channels.</p> <p>If more than one channel, must be defined in derived class.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.numEpochs","title":"<code>numEpochs: Optional[int]</code>  <code>property</code>","text":"<p>Get the number of epochs.</p> <p>Epochs are mostly for pClamp abf files. We are assuming each sweep has the same namber of epochs.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.recordingFrequency","title":"<code>recordingFrequency: int</code>  <code>property</code>","text":"<p>Convenience for dataPointsPerMs, recording frequency in kHz.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.sweepC","title":"<code>sweepC</code>  <code>property</code>","text":"<p>Get the DAC command for the current sweep.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.sweepX","title":"<code>sweepX</code>  <code>property</code>","text":"<p>Get the X-Values for a sweep.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.sweepX--notes","title":"Notes","text":"<p>All sweeps are assumed to have the same x-values (seconds).</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.sweepY","title":"<code>sweepY</code>  <code>property</code>","text":"<p>Get the Y values for the current sweep.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.sweepY_filtered","title":"<code>sweepY_filtered: np.ndarray</code>  <code>property</code>","text":"<p>Get a filtered version of sweepY.</p>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base-functions","title":"Functions","text":""},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.__init__","title":"<code>__init__(filepath, loadData=True)</code>","text":"<p>Base class to derive new file loaders.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>File path to load. Will use different derived classes based on extension</p> required <code>loadData</code> <code>bool</code> <p>If True then load raw data, otherwise just load the header.</p> <code>True</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>def __init__(self, filepath: str, loadData: bool = True):\n\"\"\"Base class to derive new file loaders.\n\n    Parameters\n    ----------\n    filepath : str\n        File path to load. Will use different derived classes based on extension\n    loadData : bool\n        If True then load raw data, otherwise just load the header.\n    \"\"\"\n\n    super().__init__()\n\n    self._loadError = False\n\n    self._path = filepath\n\n    self._filteredY : np.ndarray = None  # set in _getDerivative\n    self._filteredDeriv : np.ndarray = None\n    self._currentSweep: int = 0\n\n    self._epochTableList: List[sanpy.fileloaders.epochTable] = None\n\n    # load file from inherited class\n    self.loadFile()\n\n    # check our work\n    self._checkLoadedData()\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.__str__","title":"<code>__str__()</code>","text":"<p>Get a short string representing this file.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>def __str__(self):\n\"\"\"Get a short string representing this file.\"\"\"\n    txt = f\"file: {self.filename} sweeps: {self.numSweeps} dur (Sec):{self.recordingDur}\"\n    return txt\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.getEpochTable","title":"<code>getEpochTable(sweep)</code>","text":"<p>Only proper abf files will have an epoch table.</p> <p>TODO: Make all file loders have an epoch table.     Make API so derived file loaders can create their own</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>def getEpochTable(self, sweep: int):\n\"\"\"Only proper abf files will have an epoch table.\n\n    TODO: Make all file loders have an epoch table.\n        Make API so derived file loaders can create their own\n    \"\"\"\n    if self._epochTableList is not None:\n        return self._epochTableList[sweep]\n    else:\n        return None\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.loadFile","title":"<code>loadFile()</code>  <code>abstractmethod</code>","text":"<p>Derived classes must load the data and call setLoadedData(sweepX, sweepY).</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>@abstractmethod\ndef loadFile(self):\n\"\"\"Derived classes must load the data and call setLoadedData(sweepX, sweepY).\"\"\"\n    pass\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.ms2Pnt_","title":"<code>ms2Pnt_(ms)</code>","text":"<p>Convert milliseconds (ms) to point in recording using <code>self.dataPointsPerMs</code></p> <p>Parameters:</p> Name Type Description Default <code>ms</code> <code>float</code> <p>The ms into the recording</p> required <p>Returns:</p> Type Description <code>int</code> <p>The point in the recording corresponding to ms</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>def ms2Pnt_(self, ms: float) -&gt; int:\n\"\"\"\n    Convert milliseconds (ms) to point in recording using `self.dataPointsPerMs`\n\n    Parameters\n    ----------\n    ms : float\n        The ms into the recording\n\n    Returns\n    -------\n    int\n        The point in the recording corresponding to ms\n    \"\"\"\n    theRet = ms * self.dataPointsPerMs\n    theRet = round(theRet)\n    return theRet\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.pnt2Ms_","title":"<code>pnt2Ms_(pnt)</code>","text":"<p>Convert a point to milliseconds (ms) using <code>self.dataPointsPerMs</code></p> <p>Parameters:</p> Name Type Description Default <code>pnt</code> <code>int</code> required <p>Returns:</p> Type Description <code>float</code> <p>The point in milliseconds (ms)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>def pnt2Ms_(self, pnt: int) -&gt; float:\n\"\"\"\n    Convert a point to milliseconds (ms) using `self.dataPointsPerMs`\n\n    Parameters\n    ----------\n    pnt : int\n\n    Returns\n    -------\n    float\n        The point in milliseconds (ms)\n    \"\"\"\n    return pnt / self.dataPointsPerMs\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.pnt2Sec_","title":"<code>pnt2Sec_(pnt)</code>","text":"<p>Convert a point to seconds using dataPointsPerMs.</p> <p>Parameters:</p> Name Type Description Default <code>pnt</code> <code>int</code> required <p>Returns:</p> Type Description <code>float</code> <p>The point in seconds (s)</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>def pnt2Sec_(self, pnt: int) -&gt; float:\n\"\"\"Convert a point to seconds using dataPointsPerMs.\n\n    Parameters\n    ----------\n    pnt : int\n\n    Returns\n    -------\n    float\n        The point in seconds (s)\n    \"\"\"\n    if pnt is None:\n        # return math.isnan(pnt)\n        return math.nan\n    else:\n        return pnt / self.dataPointsPerMs / 1000\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.setLoadedData","title":"<code>setLoadedData(sweepX, sweepY, sweepC=None, recordingMode=recordingModes.iclamp, xLabel='', yLabel='')</code>","text":"<p>Derived classes call this function once the data is loaded in loadFile().</p> <p>Parameters:</p> Name Type Description Default <code>sweepX</code> <code>np.ndarray</code> <p>Time values</p> required <code>sweepY</code> <code>np.ndarray</code> <p>Recording values, mV or pA</p> required <code>sweepC</code> <code>np.ndarray</code> <p>(optional) DAC stimulus, pA or mV</p> <code>None</code> <code>recordingMode</code> <code>recordingModes</code> <p>(optional) Defaults to recordingModes.iclamp)</p> <code>recordingModes.iclamp</code> <code>xLabel</code> <code>str</code> <p>(optional) str for x-axis label</p> <code>''</code> <code>yLabel</code> <code>str</code> <p>(optional) str for y-axis label</p> <code>''</code>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.setLoadedData--notes","title":"Notes","text":"<ul> <li>Number of sweeps: sweepY.shape[1]</li> <li>Sweep Length (sec): sweepX[-1,0]</li> <li>Data Points Per Millisecond: 1 / ((sweepX[1,0] - sweepX[0,0]) * 1000)</li> </ul> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>def setLoadedData(\n    self,\n    sweepX: np.ndarray,\n    sweepY: np.ndarray,\n    sweepC: Optional[np.ndarray] = None,\n    recordingMode: recordingModes = recordingModes.iclamp,\n    xLabel: str = \"\",\n    yLabel: str = \"\",\n):\n\"\"\"Derived classes call this function once the data is loaded in loadFile().\n\n    Parameters\n    ----------\n    sweepX : np.ndarray\n        Time values\n    sweepY : np.ndarray\n        Recording values, mV or pA\n    sweepC : np.ndarray\n        (optional) DAC stimulus, pA or mV\n    recordingMode : recordingModes\n        (optional) Defaults to recordingModes.iclamp)\n    xLabel : str\n        (optional) str for x-axis label\n    yLabel : str\n        (optional) str for y-axis label\n\n    Notes\n    -----\n    - Number of sweeps: sweepY.shape[1]\n    - Sweep Length (sec): sweepX[-1,0]\n    - Data Points Per Millisecond: 1 / ((sweepX[1,0] - sweepX[0,0]) * 1000)\n    \"\"\"\n    self._sweepX = sweepX\n    self._sweepY = sweepY\n    self._sweepC = sweepC\n\n    self._numSweeps: int = self._sweepY.shape[1]\n    self._sweepList: List[int] = list(range(self._numSweeps))\n\n    self._sweepLengthSec: float = self._sweepX[-1, 0]  # from 0 to last sample point\n\n    dtSeconds = self._sweepX[1, 0] - self._sweepX[0, 0]  # seconds per sample\n    dtSeconds = float(dtSeconds)\n    dtMilliseconds = dtSeconds * 1000\n    _dataPointsPerMs = int(1 / dtMilliseconds)\n    # logger.info(f'dtSeconds:{dtSeconds} dtMilliseconds:{dtMilliseconds} _dataPointsPerMs:{_dataPointsPerMs}')\n    self._dataPointsPerMs: int = _dataPointsPerMs\n\n    self._recordingMode: recordingModes = recordingMode\n    self._sweepLabelX: str = xLabel\n    self._sweepLabelY: str = yLabel\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.fileLoader_base.setSweep","title":"<code>setSweep(currentSweep)</code>","text":"<p>Set the current sweep.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>def setSweep(self, currentSweep: int):\n\"\"\"Set the current sweep.\"\"\"\n    if currentSweep &gt; self.numSweeps - 1:\n        logger.error(f\"max sweep is {self.numSweeps-1}, got {currentSweep}\")\n        return\n    self._currentSweep = currentSweep\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.recordingModes","title":"<code>recordingModes</code>","text":"<p>         Bases: <code>enum.Enum</code></p> <p>Recording modes for I-Clamp, V-Clamp, and unknown.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>class recordingModes(enum.Enum):\n\"\"\"Recording modes for I-Clamp, V-Clamp, and unknown.\"\"\"\n\n    iclamp = \"I-Clamp\"\n    vclamp = \"V-Clamp\"\n    kymograph = \"Kymograph\"\n    unknown = \"unknown\"\n</code></pre>"},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base-functions","title":"Functions","text":""},{"location":"api/fileloader/fileLoader_base/#sanpy.fileloaders.fileLoader_base.getFileLoaders","title":"<code>getFileLoaders(verbose=False)</code>","text":"<p>Load file loaders from both</p> <p>1) Module sanpy.fileloaders</p> <p>2) Folder /Documents/SanPy/File Loaders <p>Each file loader is a class derived from fileLoader_base</p> <p>See: sanpy.interface.bPlugins.loadPlugins()</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of file loaders.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_base.py</code> <pre><code>def getFileLoaders(verbose: bool = False) -&gt; dict:\n\"\"\"Load file loaders from both\n\n    1) Module sanpy.fileloaders\n\n    2) Folder &lt;user&gt;/Documents/SanPy/File Loaders\n\n    Each file loader is a class derived from [fileLoader_base](../../api/fileloader/fileLoader_base.md)\n\n    See: sanpy.interface.bPlugins.loadPlugins()\n\n    Returns\n    -------\n    dict\n        A dictionary of file loaders.\n    \"\"\"\n    retDict = {}\n\n    ignoreModuleList = [\"fileLoader_base\", \"recordingModes\"]\n\n    #\n    # system file loaders from sanpy.fileloaders\n    loadedList = []\n    for moduleName, obj in inspect.getmembers(sanpy.fileloaders):\n        if inspect.isclass(obj):\n            if verbose:\n                logger.info(f\"moduleName:{moduleName}\")\n            if moduleName in ignoreModuleList:\n                continue\n            loadedList.append(moduleName)\n            fullModuleName = \"sanpy.fileloaders.\" + moduleName\n            # filetype is a static str, e.g. the extension to load\n            try:\n                filetype = obj.loadFileType\n            except AttributeError as e:\n                logger.warning(f'Did not load \"{moduleName}\", no \"filetype\" attribute')\n                continue\n            oneLoaderDict = {\n                \"fileLoaderClass\": moduleName,\n                \"type\": \"system\",\n                \"module\": fullModuleName,\n                \"path\": \"\",\n                \"constructor\": obj,\n                #'filetype': filetype\n            }\n            if filetype in retDict.keys():\n                logger.warning(\n                    f'loader already added \"{moduleName}\" filetype:\"{filetype}\"'\n                )\n                logger.warning(f\"  this loader will overwrite the previous loader.\")\n            retDict[filetype] = oneLoaderDict\n\n    # logger.info(f'Loaded system file loaders:')\n    # for k,v in retDict.keys():\n    #     logger.info(f'    {k}:{v}')\n    # # sort\n    # retDict = dict(sorted(retDict.items()))\n\n    #\n    # user plugins from files in folder \"&lt;user&gt;/SanPy/file loaders\"\n    fileLoaderFolder = sanpy._util._getUserFileLoaderFolder()\n    loadedModuleList = []\n    if os.path.isdir(fileLoaderFolder):\n        files = glob.glob(os.path.join(fileLoaderFolder, \"*.py\"))\n    else:\n        # no user file loader folder ???\n        files = []\n\n    for file in files:\n        if file.endswith(\"__init__.py\"):\n            continue\n\n        moduleName = os.path.split(file)[1]\n        moduleName = os.path.splitext(moduleName)[0]\n        fullModuleName = \"sanpy.fileloaders.\" + moduleName\n\n        loadedModule = sanpy._util._module_from_file(fullModuleName, file)\n\n        try:\n            oneConstructor = getattr(loadedModule, moduleName)\n        except AttributeError as e:\n            logger.error(\n                f'Did not load file loader, make sure file name and class name are the same:\"{moduleName}\"'\n            )\n        else:\n            # filetype is a static str, e.g. the extension to load\n            try:\n                filetype = oneConstructor.loadFileType\n            except AttributeError as e:\n                logger.warning(f'Did not load \"{moduleName}\", no \"filetype\" attribute')\n                continue\n            oneLoaderDict = {\n                \"fileLoaderClass\": moduleName,\n                \"type\": \"user\",\n                \"module\": fullModuleName,\n                \"path\": file,\n                \"constructor\": oneConstructor,\n                #'filetype': filetype\n            }\n            if filetype in retDict.keys():\n                logger.warning(\n                    f'loader already added \"{moduleName}\" handleExtension:\"{filetype}\"'\n                )\n                logger.warning(f\"  this loader will overwrite the previous loader.\")\n            retDict[filetype] = oneLoaderDict\n\n    if verbose:\n        logger.info(f\"Loaded {len(retDict.keys())} file loaders:\")\n        for k, v in retDict.items():\n            # logger.info(f'    {k}:{v}')\n            logger.info(f\"  {k}\")\n            for k2, v2 in v.items():\n                logger.info(f\"    {k2}: {v2}\")\n\n    # sort\n    # retDict = dict(sorted(retDict.items()))\n\n    return retDict\n</code></pre>"},{"location":"api/fileloader/fileLoader_csv/","title":"fileLoader_csv","text":""},{"location":"api/fileloader/fileLoader_csv/#sanpy.fileloaders.fileLoader_csv-classes","title":"Classes","text":""},{"location":"api/fileloader/fileLoader_csv/#sanpy.fileloaders.fileLoader_csv.fileLoader_csv","title":"<code>fileLoader_csv</code>","text":"<p>         Bases: <code>fileLoader_base</code></p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_csv.py</code> <pre><code>class fileLoader_csv(fileLoader_base):\n    loadFileType = \"csv\"\n\n    # @property\n    # def loadFileType(self):\n    #     return 'csv'\n\n    def loadFile(self):\n\"\"\"Load file and call setLoadedData().\n\n        Use self.filepath for the file\n\n        Column 0 is seconds\n        Column 1 is recording in ['mV', 'pA']\n        \"\"\"\n        # load the csv file\n        try:\n            _df = pd.read_csv(self.filepath)\n        except (pd.errors.EmptyDataError):\n            self._loadError = True\n            return\n\n        _columns = _df.columns\n        _numColumns = len(_columns)\n        if _numColumns &lt; 2:\n            logger.error(f\"expecting 2 or more columns but got {_numColumns}\")\n            self._loadError = True\n            return\n\n        _numSamples = len(_df)\n        _numSweeps = _numColumns - 1  # assuming no DAC columns\n\n        # TODO: check that the columns we will read are float (not str or object)\n        #\n        # make sweepX (assuming all sweeps have the same sweepX)\n        sweepX = np.ndarray((_numSamples, 1))\n        try:\n            sweepX[:, 0] = _df[_columns[0]].to_numpy()\n        except ValueError as e:\n            # raise ValueError\n            logger.error(f\"ValueError assigning the first column\")\n            self._loadError = True\n            return\n\n        # make sweepY to hold (samples, sweeps) values, the values in each sweep are different\n        sweepY = np.ndarray((_numSamples, _numSweeps))\n        for sweep in range(_numSweeps):\n            colIdx = sweep + 1\n            sweepY[:, sweep] = _df[_columns[colIdx]].to_numpy()\n\n        # sweepC = None  # not defined\n\n        # determine recording mode from name of column 1\n        _tmpColName = _columns[1].replace(\"_0\", \"\")\n        if _tmpColName in [\"pA\", \"nA\"]:\n            _recordingMode = recordingModes.vclamp\n        elif _tmpColName in [\"mV\", \"mv\"]:\n            _recordingMode = recordingModes.iclamp\n        else:\n            logger.warning(\n                f\"did not infer recording mode from column name {_tmpColName}\"\n            )\n            _recordingMode = recordingModes.unknown\n\n        xLabel = _columns[0]\n        yLabel = _tmpColName  # _columns[1]\n\n        self.setLoadedData(\n            sweepX=sweepX,\n            sweepY=sweepY,\n            # sweepC = sweepC,\n            xLabel=xLabel,\n            yLabel=yLabel,\n        )\n</code></pre>"},{"location":"api/fileloader/fileLoader_csv/#sanpy.fileloaders.fileLoader_csv.fileLoader_csv-functions","title":"Functions","text":""},{"location":"api/fileloader/fileLoader_csv/#sanpy.fileloaders.fileLoader_csv.fileLoader_csv.loadFile","title":"<code>loadFile()</code>","text":"<p>Load file and call setLoadedData().</p> <p>Use self.filepath for the file</p> <p>Column 0 is seconds Column 1 is recording in ['mV', 'pA']</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/fileloaders/fileLoader_csv.py</code> <pre><code>def loadFile(self):\n\"\"\"Load file and call setLoadedData().\n\n    Use self.filepath for the file\n\n    Column 0 is seconds\n    Column 1 is recording in ['mV', 'pA']\n    \"\"\"\n    # load the csv file\n    try:\n        _df = pd.read_csv(self.filepath)\n    except (pd.errors.EmptyDataError):\n        self._loadError = True\n        return\n\n    _columns = _df.columns\n    _numColumns = len(_columns)\n    if _numColumns &lt; 2:\n        logger.error(f\"expecting 2 or more columns but got {_numColumns}\")\n        self._loadError = True\n        return\n\n    _numSamples = len(_df)\n    _numSweeps = _numColumns - 1  # assuming no DAC columns\n\n    # TODO: check that the columns we will read are float (not str or object)\n    #\n    # make sweepX (assuming all sweeps have the same sweepX)\n    sweepX = np.ndarray((_numSamples, 1))\n    try:\n        sweepX[:, 0] = _df[_columns[0]].to_numpy()\n    except ValueError as e:\n        # raise ValueError\n        logger.error(f\"ValueError assigning the first column\")\n        self._loadError = True\n        return\n\n    # make sweepY to hold (samples, sweeps) values, the values in each sweep are different\n    sweepY = np.ndarray((_numSamples, _numSweeps))\n    for sweep in range(_numSweeps):\n        colIdx = sweep + 1\n        sweepY[:, sweep] = _df[_columns[colIdx]].to_numpy()\n\n    # sweepC = None  # not defined\n\n    # determine recording mode from name of column 1\n    _tmpColName = _columns[1].replace(\"_0\", \"\")\n    if _tmpColName in [\"pA\", \"nA\"]:\n        _recordingMode = recordingModes.vclamp\n    elif _tmpColName in [\"mV\", \"mv\"]:\n        _recordingMode = recordingModes.iclamp\n    else:\n        logger.warning(\n            f\"did not infer recording mode from column name {_tmpColName}\"\n        )\n        _recordingMode = recordingModes.unknown\n\n    xLabel = _columns[0]\n    yLabel = _tmpColName  # _columns[1]\n\n    self.setLoadedData(\n        sweepX=sweepX,\n        sweepY=sweepY,\n        # sweepC = sweepC,\n        xLabel=xLabel,\n        yLabel=yLabel,\n    )\n</code></pre>"},{"location":"api/interface/sanpy_app/","title":"sanp_app","text":""},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app-classes","title":"Classes","text":""},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow","title":"<code>SanPyWindow</code>","text":"<p>         Bases: <code>QtWidgets.QMainWindow</code></p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>class SanPyWindow(QtWidgets.QMainWindow):\n    # TODO: define parameter block for all signals.\n\n    signalSetXAxis = QtCore.Signal(object)\n\"\"\"Emit set axis.\"\"\"\n\n    signalSwitchFile = QtCore.Signal(object, object)\n\"\"\"Emit on switch file.\"\"\"\n\n    signalSelectSweep = QtCore.Signal(object, object)  # (ba, sweepNumber)\n\"\"\"Emit set sweep.\"\"\"\n\n    signalUpdateAnalysis = QtCore.Signal(object)\n\"\"\"Emit on detect.\"\"\"\n\n    signalSelectSpike = QtCore.Signal(object)\n\"\"\"Emit spike selection.\"\"\"\n\n    signalSelectSpikeList = QtCore.Signal(object)\n\"\"\"Emit spike list selection.\"\"\"\n\n    def __init__(self, path=None, parent=None):\n\"\"\"\n        Parameters\n        ----------\n        path : str\n            Full path to folder with raw files (abf,csv,tif).\n        \"\"\"\n\n        super().__init__(parent)\n\n        logger.info(f\"Constructing SanPyWindow\")\n        date_time_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        logger.info(f'{date_time_str}')\n\n        _version = self._getVersionInfo()\n        for k,v in _version.items():\n            logger.info(f'{k}: {v}')\n\n        self.setAcceptDrops(True)\n\n        # TODO: if first time run (no &lt;user&gt;/Documents/SanPy) then warn user to quit and restart\n\n        # create directories in &lt;user&gt;/Documents and add to python path\n        firstTimeRunning = sanpy._util.addUserPath()\n        if firstTimeRunning:\n            logger.info(\"  We created &lt;user&gt;/Documents/Sanpy and need to restart\")\n\n        self._fileLoaderDict = sanpy.fileloaders.getFileLoaders()\n        self._detectionClass = sanpy.bDetection()\n\n        # create an empty model for file list\n        dfEmpty = pd.DataFrame(columns=sanpy.analysisDir.sanpyColumns.keys())\n        self.myModel = sanpy.interface.bFileTable.pandasModel(dfEmpty)\n\n        self.fileFromDatabase = True  # if False then from folder\n\n        self.startSec = None\n        self.stopSec = None\n\n        # TODO: put font size in options file\n        # removed mar 26 2023\n\"\"\"\n        myFontSize = 10\n        myFont = self.font();\n        myFont.setPointSize(myFontSize)\n        self.setFont(myFont)\n        \"\"\"\n\n        if path is not None and os.path.isdir(path):\n            windowTitle = f\"SanPy {path}\"\n        else:\n            windowTitle = \"SanPy\"\n        self.setWindowTitle(windowTitle)\n\n        self._rowHeight = 11\n\n        # path to loaded folder (using bAnalysisDir)\n        self.configDict: sanpy.interface.preferences = sanpy.interface.preferences(self)\n        self.myAnalysisDir = None\n        lastPath = self.configDict.getMostRecentFolder()\n        logger.info(f'  preferences lastPath is \"{lastPath}\"')\n        if path is not None:\n            self.path = path\n        elif lastPath is not None and os.path.isdir(lastPath):\n            self.path = lastPath\n        else:\n            self.path = None\n\n        # TODO: refactor dark to light theme\n        self.useDarkStyle = self.configDict[\"useDarkStyle\"]\n        # self.useDarkStyle = True\n        self.toggleStyleSheet(self.useDarkStyle, buildingInterface=True)\n\n        #\n        # set window geometry\n        self.setMinimumSize(640, 480)\n        self.left = self.configDict[\"windowGeometry\"][\"x\"]\n        self.top = self.configDict[\"windowGeometry\"][\"y\"]\n        self.width = self.configDict[\"windowGeometry\"][\"width\"]\n        self.height = self.configDict[\"windowGeometry\"][\"height\"]\n        self.setGeometry(self.left, self.top, self.width, self.height)\n\n        self.myPlugins = sanpy.interface.bPlugins(sanpyApp=self)\n\n        # order matter, _buildMenus uses objects created in _buildUI\n        self._buildUI()\n        self._buildMenus()\n\n        # 20210803, loadFolder was above? Still works down here\n        # needed to update detection widget after buildUI()\n        if self.path is not None and len(self.path) &gt; 0:\n            self.slot_loadFolder(self.path)\n\n        # self.raise_()  # bring to front, raise is a python keyword\n        # self.activateWindow()  # bring to front\n\n        self.slot_updateStatus(\"Ready\")\n        logger.info(\"SanPy started\")\n\n    def getDetectionClass(self):\n        return self._detectionClass\n\n    def getFileLoaderDict(self):\n        return self._fileLoaderDict\n\n    def dragEnterEvent(self, event):\n        logger.info(\"\")\n        if event.mimeData().hasUrls():\n            event.accept()\n        else:\n            event.ignore()\n\n    def dropEvent(self, event):\n        logger.info(\"\")\n        folders = [u.toLocalFile() for u in event.mimeData().urls()]\n        if len(folders) &gt; 1:\n            return\n        oneFolder = folders[0]\n        if os.path.isdir(oneFolder):\n            self.slot_loadFolder(path=oneFolder)\n\n    def _promptIfDirty(self) -&gt; bool:\n\"\"\"Prompt user if there is unsaved analysis.\n\n        If this return False, do not proceed with caller action.\n        e.g. on 'load folder'\n\n        If this returns True then proceed with caller action\n        \"\"\"\n        acceptAndContinue = True\n        if self.myAnalysisDir is not None:\n            tableIsDirty = self.myAnalysisDir.isDirty\n            analysisIsDirty = self.myAnalysisDir.hasDirty()\n            if tableIsDirty or analysisIsDirty:\n                userResp = sanpy.interface.bDialog.yesNoCancelDialog(\n                    \"There is analysis that is not saved.\\nDo you want to save?\"\n                )\n                if userResp == QtWidgets.QMessageBox.Yes:\n                    self.saveFilesTable()\n                    acceptAndContinue = True\n                elif userResp == QtWidgets.QMessageBox.No:\n                    acceptAndContinue = True\n                else:  # userResp == QtWidgets.QMessageBox.Cancel:\n                    acceptAndContinue = False\n        return acceptAndContinue\n\n    def closeEvent(self, event):\n\"\"\"Called when user closes main window or selects quit.\n\n        Parameters\n        ----------\n        event : PyQt5.QtGui.QCloseEvent\n        \"\"\"\n\n        logger.info(event)\n\n        # check if our table view has been edited by user and warn\n        doQuit = True\n        alreadyAsked = False\n        # self.myAnalysisDir is only defined after we load a folder\n        if self.myAnalysisDir is not None:\n            tableIsDirty = self.myAnalysisDir.isDirty\n            analysisIsDirty = self.myAnalysisDir.hasDirty()\n            if tableIsDirty or analysisIsDirty:\n                alreadyAsked = True\n                userResp = sanpy.interface.bDialog.yesNoCancelDialog(\n                    \"There is analysis that is not saved.\\nDo you want to save?\"\n                )\n                if userResp == QtWidgets.QMessageBox.Yes:\n                    self.saveFilesTable()\n                    event.accept()\n                elif userResp == QtWidgets.QMessageBox.No:\n                    event.accept()\n                else:\n                    event.ignore()\n                    doQuit = False\n        if doQuit:\n            if not alreadyAsked:\n                userResp = sanpy.interface.bDialog.okCancelDialog(\n                    \"Are you sure you want to quit SanPy?\", informativeText=None\n                )\n                if userResp == QtWidgets.QMessageBox.Cancel:\n                    event.ignore()\n                    doQuit = False\n\n            if doQuit:\n                logger.info(\"SanPy is quiting\")\n                QtCore.QCoreApplication.quit()\n\n    def getOptions(self):\n        return self.configDict\n\n    def getWindowGeometry(self):\n\"\"\"Get the current window position.\"\"\"\n        myRect = self.geometry()\n        left = myRect.left()\n        top = myRect.top()\n        width = myRect.width()\n        height = myRect.height()\n        return left, top, width, height\n\n    def toggleStyleSheet(self, doDark=None, buildingInterface=False):\n        logger.info(\"\")\n        if doDark is None:\n            doDark = not self.useDarkStyle\n        self.useDarkStyle = doDark\n        if doDark:\n            # v1\n            # self.setStyleSheet(qdarkstyle.load_stylesheet(qt_api='pyqt5'))\n            # v2\n            qdarktheme.setup_theme(\"dark\")\n\n            pg.setConfigOption(\"background\", \"k\")\n            pg.setConfigOption(\"foreground\", \"w\")\n        else:\n            # v1\n            # self.setStyleSheet('')\n            # v2\n            qdarktheme.setup_theme(\"light\")\n\n            pg.setConfigOption(\"background\", \"w\")\n            pg.setConfigOption(\"foreground\", \"k\")\n\n        self.configDict[\"useDarkStyle\"] = self.useDarkStyle\n\n        if not buildingInterface:\n            # self.myScatterPlotWidget.defaultPlotLayout()\n            # self.myScatterPlotWidget.buildUI(doRebuild=True)\n            self.myDetectionWidget.mySetTheme()\n\n        if buildingInterface:\n            pass\n        else:\n            pass\n            # msg = QtWidgets.QMessageBox()\n            # msg.setIcon(QtWidgets.QMessageBox.Warning)\n            # msg.setText(\"Theme Changed\")\n            # msg.setInformativeText('Please restart SanPy for changes to take effect.')\n            # msg.setWindowTitle(\"Theme Changed\")\n            # retval = msg.exec_()\n\n            # self.configDict.save()\n\n    def slot_loadFolder(self, path=\"\", folderDepth=None):\n\"\"\"Load a folder of raw data files.\n\n        Parameters\n        ----------\n        path : str\n        folderDepth : int or None\n        \"\"\"\n\n        if folderDepth is None:\n            # get the depth from file list widget\n            folderDepth = self._fileListWidget.getDepth()\n\n        logger.info(f\"Loading depth:{folderDepth} path: {path}\")\n\n        # if folder is already loaded, ask to save\n        acceptAndContinue = self._promptIfDirty()\n        if not acceptAndContinue:\n            return\n\n        # ask user for folder\n        if path is None or isinstance(path, bool) or len(path) == 0:\n            path = str(\n                QtWidgets.QFileDialog.getExistingDirectory(\n                    self, \"Select Directory With Recordings\"\n                )\n            )\n            if len(path) == 0:\n                return\n        elif os.path.isdir(path):\n            pass\n        else:\n            logger.warning(f'    Did not load path \"{path}\"')\n            return\n\n        self.path = path  # path to loaded bAnalysisDir folder\n\n        # logger.info(f'Loading path: {path}')\n\n        # will create/load hd5 file for folder\n        self.myAnalysisDir = sanpy.analysisDir(\n            path, folderDepth=folderDepth, myApp=self\n        )\n\n        # set myAnalysisDir to file list model\n        self.myModel = sanpy.interface.bFileTable.pandasModel(self.myAnalysisDir)\n        # self.myModel.signalMyDataChanged.connect(self.slot_dataChanged)\n        # self.myModel.signalMyDataChanged.connect(self.myDetectionWidget.slot_dataChanged)\n\n        # try:\n        if 1:\n            self._fileListWidget.mySetModel(self.myModel)\n            self.myModel.signalMyDataChanged.connect(\n                self.myDetectionWidget.slot_dataChanged\n            )\n\"\"\"\n        except (AttributeError) as e:\n            # needed when we call loadFolder from __init__\n            # logger.warning('OK: no tableView during load folder')\n            pass\n        \"\"\"\n\n        # set window title\n        if self.path is not None and os.path.isdir(self.path):\n            windowTitle = f\"SanPy: {self.path}\"\n        else:\n            windowTitle = \"SanPy\"\n        self.setWindowTitle(windowTitle)\n\n        # add to preferences recent folders\n        self.configDict.addFolder(path)\n\n        # save preferences\n        # self.configDict.save()\n\n'''\n    def slot_dataChanged(self, columnName, value, rowDict):\n        \"\"\"User has edited main file table.\n        Update detection widget for columns (Start(s), Stop(s), dvdtThreshold, mvThreshold)\n        \"\"\"\n        logger.info(f'{columnName} {value}')\n        print('  ', rowDict)\n    '''\n\n    def selectSpike(self, spikeNumber, doZoom=False):\n        eDict = {\n            \"spikeNumber\": spikeNumber,\n            \"doZoom\": doZoom,\n            \"ba\": self.get_bAnalysis(),\n        }\n        self.signalSelectSpike.emit(eDict)\n\n    def selectSpikeList(self, spikeList: List[int], doZoom: bool = False):\n        eDict = {\n            \"spikeList\": spikeList,\n            \"doZoom\": doZoom,\n            \"ba\": self.get_bAnalysis(),\n        }\n        logger.info(f'--&gt;&gt; emit signalSelectSpikeList {eDict}')\n        self.signalSelectSpikeList.emit(eDict)\n\n    def mySignal(self, this, data=None):\n\"\"\"Receive signals from children widgets.\n\n        Parameters\n        ----------\n        this : str\n            The signal name\n        data : type depends on signal (this)\n            For example, signal 'set x axis' uses data=[min,max]\n        \"\"\"\n        # print('=== sanpy_app.mySignal() \"' + this +'\"')\n\n        if this == \"select spike\":\n            logger.warning('\\n\\nTODO: GET RID OF \"select spike\"\\n\\n')\n            spikeNumber = data[\"spikeNumber\"]\n            doZoom = data[\"isShift\"]\n            self.selectSpike(spikeNumber, doZoom=doZoom)\n            # self.signalSelectSpike.emit(data)\n\n        elif this == \"set x axis\":\n            logger.info(f'\"set x axis\" {data}')\n\n            self.startSec = data[0]\n            self.stopSec = data[1]\n            # old\n            # self.myScatterPlotWidget.selectXRange(data[0], data[1])\n            # new\n            logger.info(f'\"--&gt;&gt; emit signalSetXAxis set full x axis\" {data[0]} {data[1]}')\n            self.signalSetXAxis.emit([data[0], data[1]])  # emits to scatter plot ONLY\n\n        elif this == \"set full x axis\":\n            self.startSec = 0\n            if self.get_bAnalysis() is not None:\n                self.stopSec = self.get_bAnalysis().fileLoader.recordingDur\n            else:\n                self.stopSec = None\n            logger.info(f'\"--&gt;&gt; emit signalSetXAxis set full x axis\" {self.startSec} {self.stopSec}')\n            self.signalSetXAxis.emit(\n                [self.startSec, self.stopSec]\n            )  # emits to scatter plot ONLY\n\n        elif this == \"cancel all selections\":\n            self.selectSpike(None)\n            self.selectSpikeList([])\n\n        else:\n            logger.warning(f'Did not understand this: \"{this}\"')\n\n    def old_keyPressEvent(self, event):\n\"\"\"Respond to key press\n\n        TODO: does not seem to work?\n        \"\"\"\n        key = event.key()\n        text = event.text()\n        logger.info(f\"text:{text} key:{key} event:{event}\")\n\n        # handled in bDetectionWidget\n        # set full axis\n        # if key in [70, 82]: # 'r' or 'f'\n        # if key in [QtCore.Qt.Key.Key_R, QtCore.Qt.Key.Key_F]:\n        #     self.myDetectionWidget.setAxisFull()\n\n\"\"\"\n        if key in [QtCore.Qt.Key.Key_P]: # 'r' or 'f'\n            self.myDetectionWidget.myPrint()\n        \"\"\"\n\n        # handled in bDetectionWidget\n        # cancel all selections\n        # if key == QtCore.Qt.Key.Key_Escape:\n        #     self.mySignal('cancel all selections')\n\n        # handled in bDetectionWidget\n        # hide detection widget\n        # if text == 'h':\n        #     if self.myDetectionWidget.detectToolbarWidget.isVisible():\n        #         self.myDetectionWidget.detectToolbarWidget.hide()\n        #     else:\n        #         self.myDetectionWidget.detectToolbarWidget.show()\n\n        # user can copy this to the clipboard\n        # print file list model\n        # this is df updated as user updates table\n        # if text == 'p':\n        #     print(self.myModel)\n        #     print(self.myModel._data)\n\n        #\n        event.accept()\n\n    def get_bAnalysis(self):\n        return self.myDetectionWidget.ba\n\n    def getSelectedFileDict(self):\n\"\"\"\n        Used by detection widget to get info in selected file.\n\n        todo: remove, pass this dict in signal emit from file table\n        \"\"\"\n\n        fileDict = self._fileListWidget.getTableView().getSelectedRowDict()\n        return fileDict\n\n        # was this\n\"\"\"\n        selectedRows = self._fileListWidget.selectionModel().selectedRows()\n        if len(selectedRows) == 0:\n            return None\n        else:\n            selectedItem = selectedRows[0]\n            selectedRow = selectedItem.row()\n\n        rowDict = self.myModel.myGetRowDict(selectedRow)\n        return rowDict\n        \"\"\"\n\n    def slot_fileTableClicked(self, row, rowDict, selectingAgain):\n\"\"\"Respond to selections in file table.\"\"\"\n\n\"\"\"\n        row (int):\n        rowDict (dict):\n        selectingAgain (bool): True if row was already selected\n        \"\"\"\n\n        if selectingAgain:\n            self.slot_updateStatus(f'Refreshing file \"{rowDict[\"File\"]}\"')\n        else:\n            self.slot_updateStatus(f'Loading file \"{rowDict[\"File\"]}\" ... please wait')\n\n        # TODO: try and remove this\n        self.startSec = rowDict[\"Start(s)\"]\n        self.stopSec = rowDict[\"Stop(s)\"]\n\n        # This will load if necc, otherwise just fetch a pointer\n        if self.myAnalysisDir is not None:\n            ba = self.myAnalysisDir.getAnalysis(row)  # if None then problem loading\n\n            if ba is not None:\n                self.signalSwitchFile.emit(ba, rowDict)\n                if selectingAgain:\n                    pass\n                else:\n                    self.slot_updateStatus(\n                        f'Loaded file \"{ba.fileLoader.filename}\"'\n                    )  # this will load ba if necc\n\n    def _buildMenus(self):\n        mainMenu = self.menuBar()\n\n        #self.aboutAction = QtWidgets.QAction(\"&amp;About\", self)\n\n        # load\n        loadFolderAction = QtWidgets.QAction(\"Load Folder ...\", self)\n        loadFolderAction.setShortcut(\"Ctrl+O\")\n        loadFolderAction.triggered.connect(self.slot_loadFolder)\n\n        # open recent (submenu)\n        self.openRecentMenu = QtWidgets.QMenu(\"Load Recent ...\")\n        self.openRecentMenu.aboutToShow.connect(self._refreshOpenRecent)\n\n        saveDatabaseAction = QtWidgets.QAction(\"Save Folder Analysis\", self)\n        saveDatabaseAction.setShortcut(\"Ctrl+S\")\n        saveDatabaseAction.triggered.connect(self.saveFilesTable)\n\n        # buildDatabaseAction = QtWidgets.QAction('Build Big Database ...', self)\n        # buildDatabaseAction.triggered.connect(self.buildDatabase)\n\n        savePreferencesAction = QtWidgets.QAction(\"Save Preferences\", self)\n        savePreferencesAction.triggered.connect(self.configDict.save)\n\n        # showLogAction = QtWidgets.QAction(\"Show Log\", self)\n        # showLogAction.triggered.connect(self.openLog)\n\n        fileMenu = mainMenu.addMenu(\"&amp;File\")\n\n        fileMenu.addAction(loadFolderAction)\n        fileMenu.addMenu(self.openRecentMenu)\n\n        fileMenu.addSeparator()\n        fileMenu.addAction(saveDatabaseAction)\n\n        fileMenu.addSeparator()\n        # fileMenu.addAction(buildDatabaseAction)\n        # fileMenu.addSeparator()\n        fileMenu.addAction(savePreferencesAction)\n\n        # fileMenu.addSeparator()\n        # fileMenu.addAction(showLogAction)\n\n        # view menu to toggle widgets on/off\n        self.viewMenu = mainMenu.addMenu(\"&amp;View\")\n        self.viewMenu.aboutToShow.connect(self._refreshViewMenu)\n        self._refreshViewMenu()\n        # self._populateViewMenu()\n\n        self.windowsMenu = mainMenu.addMenu('&amp;Window')\n        self.windowsMenu.aboutToShow.connect(self._refreshWindowsMenu)\n        self._refreshWindowsMenu()\n\n        #\n        # plugins menu\n        pluginsMenu = mainMenu.addMenu(\"&amp;Plugins\")\n        # list of plugin names\n        # pluginList = self.myPlugins.pluginList()\n        # each key is the name of theplugin\n        pluginDict = self.myPlugins.pluginDict\n        # print('pluginDict:', pluginDict)\n        _foundUserPlugin = False\n        for __humanName, v in pluginDict.items():\n            if not v[\"showInMenu\"]:\n                continue\n\n            # logger.info(f'adding plugin: {plugin}')\n\n            sanpyPluginAction = QtWidgets.QAction(__humanName, self)\n\n            # TODO: Add spacer between system and user plugins\n            # fileMenu.addSeparator()\n\n\"\"\"\n            type = self.myPlugins.getType(plugin)\n            if type == 'system':\n                print(plugin, 'system --&gt;&gt; bold')\n                f = sanpyPluginAction.font()\n                f.setBold(True);\n                f.setItalic(True);\n                sanpyPluginAction.setFont(f);\n            \"\"\"\n\n            # print(v['type'])\n            if v[\"type\"] == \"user\":\n                if not _foundUserPlugin:\n                    pluginsMenu.addSeparator()\n                    _foundUserPlugin = True\n                _font = sanpyPluginAction.font()\n                # _font.setBold(True)\n                _font.setItalic(True)\n                sanpyPluginAction.setFont(_font)\n\n            sanpyPluginAction.triggered.connect(\n                lambda checked, pluginName=__humanName: self.sanpyPlugin_action(\n                    pluginName\n                )\n            )\n            pluginsMenu.addAction(sanpyPluginAction)\n\n\"\"\"\n        pluginDir = os.path.join(self._getBundledDir(), 'plugins', '*.txt')\n        pluginList = glob.glob(pluginDir)\n        logger.info(f'pluginList: {pluginList}')\n        pluginsMenu = mainMenu.addMenu('&amp;Plugins')\n        oneAction = 'plotRecording'\n        sanpyPluginAction = QtWidgets.QAction(oneAction, self)\n        #sanpyPluginAction.triggered.connect(self.sanpyPlugin_action)\n        sanpyPluginAction.triggered.connect(lambda checked, oneAction=oneAction: self.sanpyPlugin_action(oneAction))\n        pluginsMenu.addAction(sanpyPluginAction)\n        \"\"\"\n\n        #\n        # a dynamic menu to show open plugins\n        # self.windowsMenu = mainMenu.addMenu('&amp;Windows')\n        # self.windowsMenu.aboutToShow.connect(self._populateOpenPlugins)\n\n\"\"\"\n        # windows menu to toggle scatter plot widget\n        windowsMenu = mainMenu.addMenu('&amp;Windows')\n        mainWindowAction = QtWidgets.QAction('Main', self)\n        #\n        openScatterAction = QtWidgets.QAction('Scatter Plot', self)\n        openScatterAction.triggered.connect(self.openScatterWindow)\n        #mainWindowAction.triggered.connect(self.toggleStyleSheet)\n        mainWindowAction.setCheckable(True)\n        mainWindowAction.setChecked(True)\n        windowsMenu.addAction(mainWindowAction)\n        windowsMenu.addAction(openScatterAction)\n        \"\"\"\n\n        # help menu\n        helpMenu = mainMenu.addMenu(\"&amp;Help\")\n\n        name = \"SanPy Help (Opens In Browser)\"\n        action = QtWidgets.QAction(name, self)\n        action.triggered.connect(partial(self._onHelpMenuAction, name))\n        helpMenu.addAction(action)\n\n        # this actually does not show up in the help menu!\n        # PyQt reroutes it to the main python/SanPy menu\n        name = \"About SanPy\"\n        action = QtWidgets.QAction(name, self)\n        action.triggered.connect(self._onAboutMenuAction)\n        helpMenu.addAction(action)\n\n        # like the help menu, this gets rerouted to the main python/sanp menu\n        name = \"Preferences ...\"\n        action = QtWidgets.QAction(name, self)\n        action.triggered.connect(self._onPreferencesMenuAction)\n        helpMenu.addAction(action)\n\n    def _onHelpMenuAction(self, name: str):\n        if name == \"SanPy Help (Opens In Browser)\":\n            url = \"https://cudmore.github.io/SanPy/desktop-application\"\n            webbrowser.open(url, new=2)\n\n    def _onPreferencesMenuAction(self):\n        logger.info('')\n\n    def _onAboutMenuAction(self):\n\"\"\"Show a dialog with help.\n        \"\"\"\n        print(self._getVersionInfo())\n\n        dlg = QtWidgets.QDialog(self)\n        dlg.setWindowTitle('About SanPy')\n\n        vLayout = QtWidgets.QVBoxLayout()\n\n        _versionInfo = self._getVersionInfo()\n        for k,v in _versionInfo.items():\n            aText = k + ' ' + str(v)\n            aLabel = QtWidgets.QLabel(aText)\n\n            if 'https' in v:\n                aLabel.setText(f'{k} &lt;a href=\"{v}\"&gt;{v}&lt;/a&gt;')\n                aLabel.setTextFormat(QtCore.Qt.RichText)\n                aLabel.setTextInteractionFlags(QtCore.Qt.TextBrowserInteraction)\n                aLabel.setOpenExternalLinks(True)\n\n            if k == 'email':\n                # &lt;a href = \"mailto: abc@example.com\"&gt;Send Email&lt;/a&gt;\n                aLabel.setText(f'{k} &lt;a href=\"mailto:{v}\"&gt;{v}&lt;/a&gt;')\n                aLabel.setTextFormat(QtCore.Qt.RichText)\n                aLabel.setTextInteractionFlags(QtCore.Qt.TextBrowserInteraction)\n                aLabel.setOpenExternalLinks(True)\n\n            vLayout.addWidget(aLabel)\n\n        dlg.setLayout(vLayout)\n\n        dlg.exec()\n\n    def _getVersionInfo(self) -&gt; dict:\n        retDict = {}\n\n        #import platform\n        _platform = platform.machine()\n        # arm64\n        # x86_64\n\n        # from sanpy.version import __version__\n\n        # retDict['SanPy version'] = __version__\n        retDict['SanPy version'] = sanpy.__version__\n        retDict['Python version'] = platform.python_version()\n        retDict['Python platform'] = _platform  # platform.platform()\n        retDict['PyQt version'] = QtCore.__version__  # when using import qtpy\n        # retDict['Bundle folder'] = sanpy._util.getBundledDir()\n        # retDict['Log file'] = sanpy.sanpyLogger.getLoggerFile()\n        retDict['GitHub'] = 'https://github.com/cudmore/sanpy'\n        retDict['Documentation'] = 'https://cudmore.github.io/SanPy/'\n        retDict['email'] = 'rhcudmore@ucdavis.edu'\n\n        return retDict\n\n    def _refreshOpenRecent(self):\n\"\"\"Dynamically generate the open recent file menu.\"\"\"\n        self.openRecentMenu.clear()\n        for recentFolder in self.configDict.getRecentFolder():\n            loadFolderAction = QtWidgets.QAction(recentFolder, self)\n            # loadFolderAction.setShortcut('Ctrl+O')\n            loadFolderAction.triggered.connect(\n                partial(self.slot_loadFolder, recentFolder)\n            )\n\n            self.openRecentMenu.addAction(loadFolderAction)\n\n    def _refreshWindowsMenu(self):\n        self.windowsMenu.clear()\n\n        name = \"SanPy Window\"\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(self.isActiveWindow())\n        action.triggered.connect(partial(self._windowsMenuAction, self, name))\n        self.windowsMenu.addAction(action)\n\n        for _widget in QtWidgets.QApplication.topLevelWidgets():\n            if 'sanpy.interface.plugins' in str(type(_widget)):\n                myHumanName = _widget.myHumanName\n                print(f'{myHumanName} {_widget}')\n                action = QtWidgets.QAction(myHumanName, self, checkable=True)\n                action.setChecked(_widget.isActiveWindow())\n                action.triggered.connect(partial(self._windowsMenuAction, _widget, myHumanName))\n                self.windowsMenu.addAction(action)\n\n    def _refreshViewMenu(self):\n\"\"\"Dynamically create the main 'View' menu each time it is selected.\"\"\"\n\n        self.viewMenu.clear()\n\n        self.viewMenu.addSeparator()\n\n        key1 = \"filePanels\"\n        name = \"File Panel\"\n        checkedMainPanel = self.configDict[key1][\"File Panel\"]\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checkedMainPanel)\n        action.setShortcut(QtGui.QKeySequence(\"F\"))\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        self.viewMenu.addAction(action)\n\n        self.viewMenu.addSeparator()\n\n        key1 = \"detectionPanels\"\n\n        name = \"Detection Panel\"\n        checkedMainPanel = self.configDict[key1][\"Detection Panel\"]\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checkedMainPanel)\n        action.setShortcut(QtGui.QKeySequence(\"D\"))\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        self.viewMenu.addAction(action)\n\n        self.viewMenu.addSeparator()\n\n        name = \"Detection\"\n        checked = self.configDict[\"detectionPanels\"][name]\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checked)\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        action.setEnabled(checkedMainPanel)\n        self.viewMenu.addAction(action)\n\n        name = \"Display\"\n        checked = self.configDict[\"detectionPanels\"][name]\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checked)\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        action.setEnabled(checkedMainPanel)\n        self.viewMenu.addAction(action)\n\n        # mar 11\n        name = \"Set Spikes\"\n        checked = self.configDict[\"detectionPanels\"][name]\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checked)\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        action.setEnabled(checkedMainPanel)\n        self.viewMenu.addAction(action)\n\n        name = \"Plot Options\"\n        checked = self.configDict[\"detectionPanels\"][name]\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checked)\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        action.setEnabled(checkedMainPanel)\n        self.viewMenu.addAction(action)\n\n        self.viewMenu.addSeparator()\n\n        # traces (globalvm, dvdt, dac)\n        key1 = \"rawDataPanels\"\n\n        name = \"Full Recording\"\n        checked = self.configDict[key1][name]\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checked)\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        self.viewMenu.addAction(action)\n\n        name = \"Derivative\"\n        checked = self.configDict[key1][name]\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checked)\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        self.viewMenu.addAction(action)\n\n        name = \"DAC\"\n        checked = self.configDict[key1][name]\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checked)\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        self.viewMenu.addAction(action)\n\n        self.viewMenu.addSeparator()\n\n        # show/hide plugin 1/2 dock widgets\n        key1 = \"pluginDocks\"\n        name = \"Plugins 1\"\n        # checkedMainPanel = self.configDict[key1]['File Panel']\n        _isVisible = self.pluginDock1.isVisible()  # assuming we _buildUI\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(_isVisible)\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        self.viewMenu.addAction(action)\n\n\"\"\"\n        key1 = 'pluginDocks'\n        name = 'Plugins 2'\n        _isVisible = self.pluginDock2.isVisible()  # assuming we _buildUI\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(_isVisible)\n        action.triggered.connect(partial(self._viewMenuAction, key1, name))\n        self.viewMenu.addAction(action)\n        \"\"\"\n\n        self.viewMenu.addSeparator()\n\n        # TODO: refactor switching themes\n        name = \"Dark Theme\"\n        checked = self.useDarkStyle\n        action = QtWidgets.QAction(name, self, checkable=True)\n        action.setChecked(checked)\n        # action.setEnabled(False)\n        action.triggered.connect(partial(self._viewMenuAction, \"Dark Theme\", name))\n        self.viewMenu.addAction(action)\n\n    def _windowsMenuAction(self, widget, name, isChecked):\n\"\"\"\n        Parameters\n        ----------\n        widget : QtWidgets.QWidget\n            Either self or an open plugin widget\n        name : str\n            Name of the window\n        \"\"\"\n\n        # don't toggle visibility\n        # widget.setVisible(not widget.isVisible())\n\n        QtWidgets.QApplication.setActiveWindow(widget)\n        widget.activateWindow()\n        widget.raise_()\n\n    def _viewMenuAction(self, key1, name, isChecked):\n\"\"\"Respond to user selection in view menu.\"\"\"\n        logger.info(f\"{key1}, {name}, {isChecked}\")\n\n        try:\n            self.configDict[key1][name] = isChecked\n        except KeyError as e:\n            pass\n\n        if key1 == \"filePanels\":\n            self.toggleInterface(name, isChecked)\n\n        elif key1 == \"pluginDocks\":\n            self.toggleInterface(name, isChecked)\n\n        elif key1 == \"rawDataPanels\":\n            # self.toggleInterface(name, isChecked)\n            self.myDetectionWidget.toggleInterface(name, isChecked)\n\n        elif key1 == \"detectionPanels\":\n            self.myDetectionWidget.toggleInterface(name, isChecked)\n\n        elif key1 == \"Dark Theme\":\n            # doDark = not self.useDarkStyle\n            # self.toggleStyleSheet(doDark=doDark)\n            self.toggleStyleSheet()\n        else:\n            logger.warning(f'  no action for key1: \"{key1}\"')\n\n    def toggleInterface(self, name, on):\n\"\"\"Toggle named interface widgets show and hide.\n\n        Parameters\n        ----------\n        name : str\n            Name of the widget\n        on : bool\n            If True then show, otherwise hide.\n        \"\"\"\n        if name == \"File Panel\":\n            self._fileListWidget.setVisible(on)\n            # if on:\n            #     self.fileDock.show()\n            # else:\n            #     self.fileDock.hide()\n        elif name == \"Plugins 1\":\n            if on:\n                self.pluginDock1.show()\n            else:\n                self.pluginDock1.hide()\n        elif name == \"Plugins 2\":\n            if on:\n                self.pluginDock2.show()\n            else:\n                self.pluginDock2.hide()\n\n    def old_populateOpenPlugins(self):\n\"\"\"Depreciated. Was to be a dynamic menu to show open plugins.\"\"\"\n        self.windowsMenu.clear()\n        actions = []\n        for plugin in self.myPlugins._openSet:\n            name = plugin.myHumanName\n            windowTitle = plugin.windowTitle\n            action = QtWidgets.QAction(windowTitle, self)\n            action.triggered.connect(\n                partial(self.old_showOpenPlugin, name, plugin, windowTitle)\n            )\n            actions.append(action)\n        self.windowsMenu.addActions(actions)\n\n    def old_showOpenPlugin(self, name, plugin, windowTitle, selected):\n        logger.info(name)\n        logger.info(plugin)\n        logger.info(windowTitle)\n        logger.info(selected)\n        plugin.bringToFront()\n\n    def _buildUI(self):\n\"\"\" \"\n        File List : sanpy.interface.fileListWidget\n        Detection Widget: sanpy.interface.bDetectionWidget\n        \"\"\"\n        # self.toggleStyleSheet(buildingInterface=True)\n\n        self.statusBar = QtWidgets.QStatusBar()\n        self.setStatusBar(self.statusBar)\n\n        # typical wrapper for PyQt, we can't use setLayout(), we need to use setCentralWidget()\n        _mainWidget = QtWidgets.QWidget()\n        _mainVLayout = QtWidgets.QVBoxLayout()\n        _mainWidget.setLayout(_mainVLayout)\n        self.setCentralWidget(_mainWidget)\n\n        #\n        # list of files (in a dock)\n        self._fileListWidget = sanpy.interface.fileListWidget(self.myModel)\n        # self._fileListWidget.signalUpdateStatus.connect(self.slot_updateStatus)  # never used\n        self._fileListWidget.signalLoadFolder.connect(self.slot_loadFolder)\n        self._fileListWidget.getTableView().signalSelectRow.connect(\n            self.slot_fileTableClicked\n        )\n        # self._fileListWidget.getTableView().signalSetDefaultDetection.connect(self.slot_setDetectionParams)\n\n        # update dvdtThreshold, mvThreshold Start(s), Stop(s)\n        self.signalUpdateAnalysis.connect(\n            self._fileListWidget.getTableView().slot_detect\n        )\n        # self.myDetectionWidget.signalDetect.connect(self._fileListWidget.slot_detect)\n\n        # file list as a widget\n        #_mainVLayout.addWidget(self._fileListWidget)\n\n        # file list as a dock\n        self.fileDock = QtWidgets.QDockWidget('Files',self)\n        self.fileDock.setWidget(self._fileListWidget)\n        self.fileDock.setFeatures(QtWidgets.QDockWidget.NoDockWidgetFeatures | \\\n                                  QtWidgets.QDockWidget.DockWidgetVerticalTitleBar)\n        self.fileDock.setFloating(False)\n        self.fileDock.setTitleBarWidget(QtWidgets.QWidget())\n        self.addDockWidget(QtCore.Qt.TopDockWidgetArea, self.fileDock)\n\n        #\n        # Detection widget\n        baNone = None\n        self.myDetectionWidget = sanpy.interface.bDetectionWidget(\n            ba=baNone, mainWindow=self\n        )\n\n        # show/hide\n        on = self.configDict[\"detectionPanels\"][\"Detection Panel\"]\n        self.myDetectionWidget.toggleInterface(\"Detection Panel\", on)\n\n        # (1) detection widget in main v layout\n        _mainVLayout.addWidget(self.myDetectionWidget)\n\n        # myDetectionWidget listens to self\n        self.signalSwitchFile.connect(self.myDetectionWidget.slot_switchFile)\n        self.signalSelectSpike.connect(self.myDetectionWidget.slot_selectSpike)\n        self.signalSelectSpikeList.connect(self.myDetectionWidget.slot_selectSpikeList)\n        self.signalUpdateAnalysis.connect(self.myDetectionWidget.slot_updateAnalysis)\n\n        # self listens to myDetectionWidget\n        self.myDetectionWidget.signalSelectSpike.connect(self.slot_selectSpike)\n        self.myDetectionWidget.signalSelectSpikeList.connect(self.slot_selectSpikeList)\n        self.myDetectionWidget.signalSelectSweep.connect(self.slot_selectSweep)\n        self.myDetectionWidget.signalDetect.connect(self.slot_detect)\n\n        # (2) detection widget as a dock\n        #  detection widget has left panel of controls and right panel of plots\n        #  just make left controls a dock widget\n        # self.detectionDock = QtWidgets.QDockWidget('Detection',self)\n        # self.detectionDock.setWidget(self.myDetectionWidget)\n        # self.detectionDock.setFeatures(QtWidgets.QDockWidget.NoDockWidgetFeatures | \\\n        #                           QtWidgets.QDockWidget.DockWidgetVerticalTitleBar)\n        # self.detectionDock.setFloating(False)\n        # self.detectionDock.setTitleBarWidget(QtWidgets.QWidget())\n        # self.addDockWidget(QtCore.Qt.LeftDockWidgetArea, self.detectionDock)\n\n        # self.setLayout(_mainVLayout)\n\n        #\n        # 2x docks for plugins\n        self.myPluginTab1 = QtWidgets.QTabWidget()\n        self.myPluginTab1.setMovable(True)\n        self.myPluginTab1.setTabsClosable(True)\n        self.myPluginTab1.tabCloseRequested.connect(\n            partial(self.slot_closeTab, sender=self.myPluginTab1)\n        )\n        self.myPluginTab1.currentChanged.connect(\n            partial(self.slot_changeTab, sender=self.myPluginTab1)\n        )\n        # re-wire right-click\n        self.myPluginTab1.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)\n        self.myPluginTab1.customContextMenuRequested.connect(\n            partial(self.on_plugin_contextMenu, sender=self.myPluginTab1)\n        )\n\n        _openPlugins = self.configDict[\"pluginPanels\"]  # dict of\n        for _openPlugin, _externalWindow in _openPlugins.items():\n            _externalWindow = _externalWindow[\"externalWindow\"]\n            logger.info(\n                f\"  _openPlugin:{_openPlugin} _externalWindow:{_externalWindow}\"\n            )\n            _oneOpenPlugin = self.myPlugins.runPlugin(_openPlugin, ba=None, show=True)\n            if _oneOpenPlugin is not None:\n                if _externalWindow:\n                    # april 30, 2023. Removed! We were opening plugins twice\n                    # self.sanpyPlugin_action(_openPlugin)\n                    pass\n                else:\n                    # on add tab, the QTabWIdget makes a copy !!!\n                    self.myPluginTab1.addTab(_oneOpenPlugin, _oneOpenPlugin.myHumanName)\n\n        self.pluginDock1 = QtWidgets.QDockWidget(\"Plugins\", self)\n        self.pluginDock1.setWidget(self.myPluginTab1)\n        self.pluginDock1.setVisible(self.myPluginTab1.count() &gt; 0)\n        self.pluginDock1.setFloating(False)\n        self.pluginDock1.dockLocationChanged.connect(\n            partial(self.slot_dockLocationChanged, self.pluginDock1)\n        )\n        self.addDockWidget(QtCore.Qt.RightDockWidgetArea, self.pluginDock1)\n\n        #\n        # tabs\n\"\"\"\n        self.myPluginTab2 = QtWidgets.QTabWidget()\n        self.myPluginTab2.setMovable(True)\n        self.myPluginTab2.setTabsClosable(True)\n        self.myPluginTab2.tabCloseRequested.connect(partial(self.slot_closeTab, sender=self.myPluginTab2))\n        self.myPluginTab2.currentChanged.connect(partial(self.slot_changeTab, sender=self.myPluginTab2))\n        # re-wire right-click\n        self.myPluginTab2.setContextMenuPolicy(QtCore.Qt.CustomContextMenu);\n        self.myPluginTab2.customContextMenuRequested.connect(partial(self.on_plugin_contextMenu, sender=self.myPluginTab2))\n\n        self.pluginDock2 = QtWidgets.QDockWidget('Plugins 2',self)\n        self.pluginDock2.setWidget(self.myPluginTab2)\n        self.pluginDock2.setFloating(False)\n        self.pluginDock2.hide() # initially hide 'Plugins 2'\n        self.pluginDock2.dockLocationChanged.connect(partial(self.slot_dockLocationChanged, self.pluginDock2))\n        self.addDockWidget(QtCore.Qt.RightDockWidgetArea, self.pluginDock2)\n        \"\"\"\n\n    def sanpyPlugin_action(self, pluginName):\n\"\"\"Responds to main menu 'Plugins'.\n\n        Run a plugin using curent ba.\n\n        Notes:\n            See also on_plugin_contextMenu for running a plugin in a tab\n        \"\"\"\n        logger.info(f'opening pluginName: \"{pluginName}\"')\n        ba = self.get_bAnalysis()\n\n        # run the plugin\n        _runningPlugin = self.myPlugins.runPlugin(pluginName, ba)\n\n        ltwhTuple = _runningPlugin.getWindowGeometry()\n\n        # add plugin to preferences so it opens next time we run the app\n        if _runningPlugin is not None:\n            self.configDict.addPlugin(\n                _runningPlugin.getHumanName(), externalWindow=True, ltwhTuple=ltwhTuple\n            )\n\n    def slot_updateAnalysis(self, sDict : dict):\n\"\"\"Respond to both detect and user setting columns in ba.\n\n        sDict : dict\n            setSpikeStatEvent = {}\n            setSpikeStatEvent['ba'] = self.ba\n            setSpikeStatEvent[\"spikeList\"] = self.getSelectedSpikes()\n            setSpikeStatEvent[\"colStr\"] = colStr\n            setSpikeStatEvent[\"value\"] = value\n        \"\"\"\n\n        logger.info('')\n\n        # do the actual update\n        ba = sDict['ba']\n        spikeList = sDict['spikeList']\n        colStr = sDict['colStr']\n        value = sDict['value']\n        if spikeList is not None and colStr is not None and value is not None:\n            logger.info(f'setting backend: {spikeList} colStr: {colStr} to value:{value}')\n            ba.setSpikeStat(spikeList, colStr, value)\n\n        self.signalUpdateAnalysis.emit(sDict)\n\n    def slot_selectSpike(self, sDict):\n        spikeNumber = sDict[\"spikeNumber\"]\n        doZoom = sDict[\"doZoom\"]\n        self.selectSpike(spikeNumber, doZoom)\n\n    def slot_selectSpikeList(self, sDict):\n        spikeList = sDict[\"spikeList\"]\n        doZoom = sDict[\"doZoom\"]\n        self.selectSpikeList(spikeList, doZoom)\n\n    def slot_selectSweep(self, ba, sweepNumber):\n\"\"\"Set view to new sweep.\n\n        Parameters\n        ----------\n        ba : sanpy.bAnalysis\n        sweepNumber : int\n        \"\"\"\n        self.signalSelectSweep.emit(ba, sweepNumber)\n\n    def saveFilesTable(self):\n\"\"\"Save the folder hdf5 file.\"\"\"\n        # logger.info('')\n        self.myAnalysisDir.saveHdf()\n        self.slot_updateStatus(f\"Save analysis for folder: {self.myAnalysisDir.path}\")\n\n    def slot_updateStatus(self, text: str):\n\"\"\"Update the bottom status bar with new str\"\"\"\n        logger.info(text)\n\n        # having trouble with an immediate update?\n        self.statusBar.showMessage(text)\n        self.statusBar.repaint()\n        # self.statusBar.update()\n        self.repaint()\n        # self.update()\n        QtWidgets.qApp.processEvents()\n\n    def _old_slot_setDetectionParams(self, row, cellType):\n\"\"\"Set detection parameters to presets.\n\n        Parameters\n        ----------\n        row : int\n            Selected row in file table\n        cellType : str\n            One of ('SA Node Params', 'Ventricular Params', 'Neuron Params')\n        \"\"\"\n        logger.info(f\"row:{row} cellType:{cellType}\")\n        self.myModel.mySetDetectionParams(row, cellType)\n\n    def slot_detect(self, ba):\n\"\"\"Respond to spike detection.\n\n        Usually comes from the sanpy.interface.bDetectionWidget\n        \"\"\"\n\n        setSpikeStatEvent = {}\n        setSpikeStatEvent['ba'] = ba\n        setSpikeStatEvent[\"spikeList\"] = None  # self.getSelectedSpikes()\n        setSpikeStatEvent[\"colStr\"] = None  # colStr\n        setSpikeStatEvent[\"value\"] = None  # value\n\n        # sweep number does not change\n        self.signalUpdateAnalysis.emit(setSpikeStatEvent)\n\n        self.slot_updateStatus(f\"Detected {ba.numSpikes} spikes\")\n\n    def on_plugin_contextMenu(self, point, sender):\n\"\"\"On right-click in dock, build a menu of plugins.\n\n        On user selection, run the plugin in a tab.\n\n        Notes:\n            See also sanpyPlugin_action for running a plugin outside a tab (via main plugin menu)\n\n        Parameters\n        ----------\n        point :QtCore.QPoint)\n            Not used\n        sender : QTabWidget\n        \"\"\"\n        # logger.info(f'point:{point}, sender:{sender}')\n\n        # list of available plugins\n        pluginList = self.myPlugins.pluginList()\n\n        contextMenu = QtWidgets.QMenu(self)\n\n        for plugin in pluginList:\n            contextMenu.addAction(plugin)\n\n        # get current mouse/cursor position\n        # not sure what 'point' parameter is?\n        pos = QtGui.QCursor.pos()\n        action = contextMenu.exec_(pos)\n\n        if action is None:\n            # no menu selected\n            return\n\n        pluginName = action.text()\n        ba = self.get_bAnalysis()\n        newPlugin = self.myPlugins.runPlugin(pluginName, ba, show=False)\n\n        # only add if plugin wants to be shown\n        if not newPlugin.getInitError() and newPlugin.getShowSelf():\n            # add tab\n\n            # 1) either this\n            # newPlugin.insertIntoScrollArea()\n\"\"\"\n            scrollArea = newPlugin.insertIntoScrollArea()\n            if scrollArea is not None:\n                newTabIndex = sender.addTab(scrollArea, pluginName)\n            else:\n                newTabIndex = sender.addTab(newPlugin, pluginName)\n            \"\"\"\n            # 2) or this\n            # newTabIndex = sender.addTab(newPlugin, pluginName)  # addTab takes ownership\n            newTabIndex = sender.addTab(\n                newPlugin.getWidget(), pluginName\n            )  # addTab takes ownership\n\n            # widgetPointer = sender.widget(newTabIndex)\n            # widgetPointer.insertIntoScrollArea()\n\n            # bring tab to front\n            sender.setCurrentIndex(newTabIndex)\n\n            ltwhTuple = newPlugin.getWindowGeometry()\n\n            if newPlugin is not None:\n                self.configDict.addPlugin(\n                    newPlugin.getHumanName(), externalWindow=False, ltwhTuple=ltwhTuple\n                )\n\n    def slot_dockLocationChanged(self, dock, area):\n\"\"\"Top level dock changed\n\n        Parameters\n        ----------\n        dock : xxx\n        area : enum QtCore.Qt.DockWidgetArea\n            Basically left/top/right/bottom.\n\n        Not triggered when user 'floats' a dock (See self.slot_topLevelChanged())\n        \"\"\"\n        logger.info(f'not implemented, dock:\"{dock.windowTitle()}\" area enum: {area}')\n        return\n\n    def on_fileDock_visibilityChanged(self, visible: bool):\n\"\"\"The file dock visibility was changed.\"\"\"\n        self._viewMenuAction(\"filePanels\", \"File Panel\", visible)\n\n    def slot_topLevelChanged(self, topLevel):\n\"\"\"\n        topLevel (bool): True if the dock widget is now floating; otherwise False.\n\n        This is triggered twice, once while dragging and once when finished\n        \"\"\"\n        sender = self.sender()  # PyQt5.QtWidgets.QDockWidget\n        logger.info(f\"topLevel:{topLevel} sender:{sender}\")\n        return\n\n    def slot_closeTab(self, index, sender):\n\"\"\"Close an open plugin tab.\n\n        Parameters\n        ----------\n        index : int\n            The index into sender that gives us the tab, sender.widget(index)\n        sender : PyQt5.QtWidgets.QTabWidget\n            The tab group where a single tab was was closed\n        \"\"\"\n\n        logger.info(f\"index:{index} sender:{type(sender)}\")\n\n        # remove plugin from self.xxx\n        # pluginInstancePointer is full class to actual plugin, like\n        # sanpy.interface.plugins.detectionParams.detectionParams\n        pluginInstancePointer = sender.widget(index)\n        logger.info(f\"  closing pluginInstancePointer:{type(pluginInstancePointer)}\")\n\n        # remove from preferences\n        # if pluginInstancePointer is not None:\n        #     self.configDict.removePlugin(pluginInstancePointer.getHumanName())\n\n        self.myPlugins.slot_closeWindow(pluginInstancePointer)\n\n        # remove the tab\n        sender.removeTab(index)\n\n    def slot_changeTab(self, index, sender):\n\"\"\"User brought a different tab to the front\n\n        Make sure only front tab (plugins) receive signals\n        \"\"\"\n        logger.info(f\"not implemented, index:{index} sender:{sender}\")\n        pass\n\n    def _old_openLog(self):\n\"\"\"Open sanpy.log\"\"\"\n        logFilePath = sanpy.sanpyLogger.getLoggerFile()\n        logFilePath = \"file://\" + logFilePath\n        url = QtCore.QUrl(logFilePath)\n        QtGui.QDesktopServices.openUrl(url)\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow-attributes","title":"Attributes","text":""},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.signalSelectSpike","title":"<code>signalSelectSpike = QtCore.Signal(object)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Emit spike selection.</p>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.signalSelectSpikeList","title":"<code>signalSelectSpikeList = QtCore.Signal(object)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Emit spike list selection.</p>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.signalSelectSweep","title":"<code>signalSelectSweep = QtCore.Signal(object, object)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Emit set sweep.</p>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.signalSetXAxis","title":"<code>signalSetXAxis = QtCore.Signal(object)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Emit set axis.</p>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.signalSwitchFile","title":"<code>signalSwitchFile = QtCore.Signal(object, object)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Emit on switch file.</p>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.signalUpdateAnalysis","title":"<code>signalUpdateAnalysis = QtCore.Signal(object)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Emit on detect.</p>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.stopSec","title":"<code>stopSec = None</code>  <code>instance-attribute</code>","text":"<p>myFontSize = 10 myFont = self.font(); myFont.setPointSize(myFontSize) self.setFont(myFont)</p>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow-functions","title":"Functions","text":""},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.__init__","title":"<code>__init__(path=None, parent=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Full path to folder with raw files (abf,csv,tif).</p> <code>None</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def __init__(self, path=None, parent=None):\n\"\"\"\n    Parameters\n    ----------\n    path : str\n        Full path to folder with raw files (abf,csv,tif).\n    \"\"\"\n\n    super().__init__(parent)\n\n    logger.info(f\"Constructing SanPyWindow\")\n    date_time_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    logger.info(f'{date_time_str}')\n\n    _version = self._getVersionInfo()\n    for k,v in _version.items():\n        logger.info(f'{k}: {v}')\n\n    self.setAcceptDrops(True)\n\n    # TODO: if first time run (no &lt;user&gt;/Documents/SanPy) then warn user to quit and restart\n\n    # create directories in &lt;user&gt;/Documents and add to python path\n    firstTimeRunning = sanpy._util.addUserPath()\n    if firstTimeRunning:\n        logger.info(\"  We created &lt;user&gt;/Documents/Sanpy and need to restart\")\n\n    self._fileLoaderDict = sanpy.fileloaders.getFileLoaders()\n    self._detectionClass = sanpy.bDetection()\n\n    # create an empty model for file list\n    dfEmpty = pd.DataFrame(columns=sanpy.analysisDir.sanpyColumns.keys())\n    self.myModel = sanpy.interface.bFileTable.pandasModel(dfEmpty)\n\n    self.fileFromDatabase = True  # if False then from folder\n\n    self.startSec = None\n    self.stopSec = None\n\n    # TODO: put font size in options file\n    # removed mar 26 2023\n\"\"\"\n    myFontSize = 10\n    myFont = self.font();\n    myFont.setPointSize(myFontSize)\n    self.setFont(myFont)\n    \"\"\"\n\n    if path is not None and os.path.isdir(path):\n        windowTitle = f\"SanPy {path}\"\n    else:\n        windowTitle = \"SanPy\"\n    self.setWindowTitle(windowTitle)\n\n    self._rowHeight = 11\n\n    # path to loaded folder (using bAnalysisDir)\n    self.configDict: sanpy.interface.preferences = sanpy.interface.preferences(self)\n    self.myAnalysisDir = None\n    lastPath = self.configDict.getMostRecentFolder()\n    logger.info(f'  preferences lastPath is \"{lastPath}\"')\n    if path is not None:\n        self.path = path\n    elif lastPath is not None and os.path.isdir(lastPath):\n        self.path = lastPath\n    else:\n        self.path = None\n\n    # TODO: refactor dark to light theme\n    self.useDarkStyle = self.configDict[\"useDarkStyle\"]\n    # self.useDarkStyle = True\n    self.toggleStyleSheet(self.useDarkStyle, buildingInterface=True)\n\n    #\n    # set window geometry\n    self.setMinimumSize(640, 480)\n    self.left = self.configDict[\"windowGeometry\"][\"x\"]\n    self.top = self.configDict[\"windowGeometry\"][\"y\"]\n    self.width = self.configDict[\"windowGeometry\"][\"width\"]\n    self.height = self.configDict[\"windowGeometry\"][\"height\"]\n    self.setGeometry(self.left, self.top, self.width, self.height)\n\n    self.myPlugins = sanpy.interface.bPlugins(sanpyApp=self)\n\n    # order matter, _buildMenus uses objects created in _buildUI\n    self._buildUI()\n    self._buildMenus()\n\n    # 20210803, loadFolder was above? Still works down here\n    # needed to update detection widget after buildUI()\n    if self.path is not None and len(self.path) &gt; 0:\n        self.slot_loadFolder(self.path)\n\n    # self.raise_()  # bring to front, raise is a python keyword\n    # self.activateWindow()  # bring to front\n\n    self.slot_updateStatus(\"Ready\")\n    logger.info(\"SanPy started\")\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.closeEvent","title":"<code>closeEvent(event)</code>","text":"<p>Called when user closes main window or selects quit.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>PyQt5.QtGui.QCloseEvent</code> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def closeEvent(self, event):\n\"\"\"Called when user closes main window or selects quit.\n\n    Parameters\n    ----------\n    event : PyQt5.QtGui.QCloseEvent\n    \"\"\"\n\n    logger.info(event)\n\n    # check if our table view has been edited by user and warn\n    doQuit = True\n    alreadyAsked = False\n    # self.myAnalysisDir is only defined after we load a folder\n    if self.myAnalysisDir is not None:\n        tableIsDirty = self.myAnalysisDir.isDirty\n        analysisIsDirty = self.myAnalysisDir.hasDirty()\n        if tableIsDirty or analysisIsDirty:\n            alreadyAsked = True\n            userResp = sanpy.interface.bDialog.yesNoCancelDialog(\n                \"There is analysis that is not saved.\\nDo you want to save?\"\n            )\n            if userResp == QtWidgets.QMessageBox.Yes:\n                self.saveFilesTable()\n                event.accept()\n            elif userResp == QtWidgets.QMessageBox.No:\n                event.accept()\n            else:\n                event.ignore()\n                doQuit = False\n    if doQuit:\n        if not alreadyAsked:\n            userResp = sanpy.interface.bDialog.okCancelDialog(\n                \"Are you sure you want to quit SanPy?\", informativeText=None\n            )\n            if userResp == QtWidgets.QMessageBox.Cancel:\n                event.ignore()\n                doQuit = False\n\n        if doQuit:\n            logger.info(\"SanPy is quiting\")\n            QtCore.QCoreApplication.quit()\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.getSelectedFileDict","title":"<code>getSelectedFileDict()</code>","text":"<p>Used by detection widget to get info in selected file.</p> <p>todo: remove, pass this dict in signal emit from file table</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def getSelectedFileDict(self):\n\"\"\"\n    Used by detection widget to get info in selected file.\n\n    todo: remove, pass this dict in signal emit from file table\n    \"\"\"\n\n    fileDict = self._fileListWidget.getTableView().getSelectedRowDict()\n    return fileDict\n\n    # was this\n\"\"\"\n    selectedRows = self._fileListWidget.selectionModel().selectedRows()\n    if len(selectedRows) == 0:\n        return None\n    else:\n        selectedItem = selectedRows[0]\n        selectedRow = selectedItem.row()\n\n    rowDict = self.myModel.myGetRowDict(selectedRow)\n    return rowDict\n    \"\"\"\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.getWindowGeometry","title":"<code>getWindowGeometry()</code>","text":"<p>Get the current window position.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def getWindowGeometry(self):\n\"\"\"Get the current window position.\"\"\"\n    myRect = self.geometry()\n    left = myRect.left()\n    top = myRect.top()\n    width = myRect.width()\n    height = myRect.height()\n    return left, top, width, height\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.mySignal","title":"<code>mySignal(this, data=None)</code>","text":"<p>Receive signals from children widgets.</p> <p>Parameters:</p> Name Type Description Default <code>this</code> <code>str</code> <p>The signal name</p> required <code>data</code> <code>type depends on signal (this)</code> <p>For example, signal 'set x axis' uses data=[min,max]</p> <code>None</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def mySignal(self, this, data=None):\n\"\"\"Receive signals from children widgets.\n\n    Parameters\n    ----------\n    this : str\n        The signal name\n    data : type depends on signal (this)\n        For example, signal 'set x axis' uses data=[min,max]\n    \"\"\"\n    # print('=== sanpy_app.mySignal() \"' + this +'\"')\n\n    if this == \"select spike\":\n        logger.warning('\\n\\nTODO: GET RID OF \"select spike\"\\n\\n')\n        spikeNumber = data[\"spikeNumber\"]\n        doZoom = data[\"isShift\"]\n        self.selectSpike(spikeNumber, doZoom=doZoom)\n        # self.signalSelectSpike.emit(data)\n\n    elif this == \"set x axis\":\n        logger.info(f'\"set x axis\" {data}')\n\n        self.startSec = data[0]\n        self.stopSec = data[1]\n        # old\n        # self.myScatterPlotWidget.selectXRange(data[0], data[1])\n        # new\n        logger.info(f'\"--&gt;&gt; emit signalSetXAxis set full x axis\" {data[0]} {data[1]}')\n        self.signalSetXAxis.emit([data[0], data[1]])  # emits to scatter plot ONLY\n\n    elif this == \"set full x axis\":\n        self.startSec = 0\n        if self.get_bAnalysis() is not None:\n            self.stopSec = self.get_bAnalysis().fileLoader.recordingDur\n        else:\n            self.stopSec = None\n        logger.info(f'\"--&gt;&gt; emit signalSetXAxis set full x axis\" {self.startSec} {self.stopSec}')\n        self.signalSetXAxis.emit(\n            [self.startSec, self.stopSec]\n        )  # emits to scatter plot ONLY\n\n    elif this == \"cancel all selections\":\n        self.selectSpike(None)\n        self.selectSpikeList([])\n\n    else:\n        logger.warning(f'Did not understand this: \"{this}\"')\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.old_keyPressEvent","title":"<code>old_keyPressEvent(event)</code>","text":"<p>Respond to key press</p> <p>TODO: does not seem to work?</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def old_keyPressEvent(self, event):\n\"\"\"Respond to key press\n\n    TODO: does not seem to work?\n    \"\"\"\n    key = event.key()\n    text = event.text()\n    logger.info(f\"text:{text} key:{key} event:{event}\")\n\n    # handled in bDetectionWidget\n    # set full axis\n    # if key in [70, 82]: # 'r' or 'f'\n    # if key in [QtCore.Qt.Key.Key_R, QtCore.Qt.Key.Key_F]:\n    #     self.myDetectionWidget.setAxisFull()\n\n\"\"\"\n    if key in [QtCore.Qt.Key.Key_P]: # 'r' or 'f'\n        self.myDetectionWidget.myPrint()\n    \"\"\"\n\n    # handled in bDetectionWidget\n    # cancel all selections\n    # if key == QtCore.Qt.Key.Key_Escape:\n    #     self.mySignal('cancel all selections')\n\n    # handled in bDetectionWidget\n    # hide detection widget\n    # if text == 'h':\n    #     if self.myDetectionWidget.detectToolbarWidget.isVisible():\n    #         self.myDetectionWidget.detectToolbarWidget.hide()\n    #     else:\n    #         self.myDetectionWidget.detectToolbarWidget.show()\n\n    # user can copy this to the clipboard\n    # print file list model\n    # this is df updated as user updates table\n    # if text == 'p':\n    #     print(self.myModel)\n    #     print(self.myModel._data)\n\n    #\n    event.accept()\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.old_populateOpenPlugins","title":"<code>old_populateOpenPlugins()</code>","text":"<p>Depreciated. Was to be a dynamic menu to show open plugins.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def old_populateOpenPlugins(self):\n\"\"\"Depreciated. Was to be a dynamic menu to show open plugins.\"\"\"\n    self.windowsMenu.clear()\n    actions = []\n    for plugin in self.myPlugins._openSet:\n        name = plugin.myHumanName\n        windowTitle = plugin.windowTitle\n        action = QtWidgets.QAction(windowTitle, self)\n        action.triggered.connect(\n            partial(self.old_showOpenPlugin, name, plugin, windowTitle)\n        )\n        actions.append(action)\n    self.windowsMenu.addActions(actions)\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.on_fileDock_visibilityChanged","title":"<code>on_fileDock_visibilityChanged(visible)</code>","text":"<p>The file dock visibility was changed.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def on_fileDock_visibilityChanged(self, visible: bool):\n\"\"\"The file dock visibility was changed.\"\"\"\n    self._viewMenuAction(\"filePanels\", \"File Panel\", visible)\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.on_plugin_contextMenu","title":"<code>on_plugin_contextMenu(point, sender)</code>","text":"<p>On right-click in dock, build a menu of plugins.</p> <p>On user selection, run the plugin in a tab.</p> <p>Notes:     See also sanpyPlugin_action for running a plugin outside a tab (via main plugin menu)</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <p>Not used</p> required <code>sender</code> <code>QTabWidget</code> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def on_plugin_contextMenu(self, point, sender):\n\"\"\"On right-click in dock, build a menu of plugins.\n\n    On user selection, run the plugin in a tab.\n\n    Notes:\n        See also sanpyPlugin_action for running a plugin outside a tab (via main plugin menu)\n\n    Parameters\n    ----------\n    point :QtCore.QPoint)\n        Not used\n    sender : QTabWidget\n    \"\"\"\n    # logger.info(f'point:{point}, sender:{sender}')\n\n    # list of available plugins\n    pluginList = self.myPlugins.pluginList()\n\n    contextMenu = QtWidgets.QMenu(self)\n\n    for plugin in pluginList:\n        contextMenu.addAction(plugin)\n\n    # get current mouse/cursor position\n    # not sure what 'point' parameter is?\n    pos = QtGui.QCursor.pos()\n    action = contextMenu.exec_(pos)\n\n    if action is None:\n        # no menu selected\n        return\n\n    pluginName = action.text()\n    ba = self.get_bAnalysis()\n    newPlugin = self.myPlugins.runPlugin(pluginName, ba, show=False)\n\n    # only add if plugin wants to be shown\n    if not newPlugin.getInitError() and newPlugin.getShowSelf():\n        # add tab\n\n        # 1) either this\n        # newPlugin.insertIntoScrollArea()\n\"\"\"\n        scrollArea = newPlugin.insertIntoScrollArea()\n        if scrollArea is not None:\n            newTabIndex = sender.addTab(scrollArea, pluginName)\n        else:\n            newTabIndex = sender.addTab(newPlugin, pluginName)\n        \"\"\"\n        # 2) or this\n        # newTabIndex = sender.addTab(newPlugin, pluginName)  # addTab takes ownership\n        newTabIndex = sender.addTab(\n            newPlugin.getWidget(), pluginName\n        )  # addTab takes ownership\n\n        # widgetPointer = sender.widget(newTabIndex)\n        # widgetPointer.insertIntoScrollArea()\n\n        # bring tab to front\n        sender.setCurrentIndex(newTabIndex)\n\n        ltwhTuple = newPlugin.getWindowGeometry()\n\n        if newPlugin is not None:\n            self.configDict.addPlugin(\n                newPlugin.getHumanName(), externalWindow=False, ltwhTuple=ltwhTuple\n            )\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.sanpyPlugin_action","title":"<code>sanpyPlugin_action(pluginName)</code>","text":"<p>Responds to main menu 'Plugins'.</p> <p>Run a plugin using curent ba.</p> <p>Notes:     See also on_plugin_contextMenu for running a plugin in a tab</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def sanpyPlugin_action(self, pluginName):\n\"\"\"Responds to main menu 'Plugins'.\n\n    Run a plugin using curent ba.\n\n    Notes:\n        See also on_plugin_contextMenu for running a plugin in a tab\n    \"\"\"\n    logger.info(f'opening pluginName: \"{pluginName}\"')\n    ba = self.get_bAnalysis()\n\n    # run the plugin\n    _runningPlugin = self.myPlugins.runPlugin(pluginName, ba)\n\n    ltwhTuple = _runningPlugin.getWindowGeometry()\n\n    # add plugin to preferences so it opens next time we run the app\n    if _runningPlugin is not None:\n        self.configDict.addPlugin(\n            _runningPlugin.getHumanName(), externalWindow=True, ltwhTuple=ltwhTuple\n        )\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.saveFilesTable","title":"<code>saveFilesTable()</code>","text":"<p>Save the folder hdf5 file.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def saveFilesTable(self):\n\"\"\"Save the folder hdf5 file.\"\"\"\n    # logger.info('')\n    self.myAnalysisDir.saveHdf()\n    self.slot_updateStatus(f\"Save analysis for folder: {self.myAnalysisDir.path}\")\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_changeTab","title":"<code>slot_changeTab(index, sender)</code>","text":"<p>User brought a different tab to the front</p> <p>Make sure only front tab (plugins) receive signals</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_changeTab(self, index, sender):\n\"\"\"User brought a different tab to the front\n\n    Make sure only front tab (plugins) receive signals\n    \"\"\"\n    logger.info(f\"not implemented, index:{index} sender:{sender}\")\n    pass\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_closeTab","title":"<code>slot_closeTab(index, sender)</code>","text":"<p>Close an open plugin tab.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>The index into sender that gives us the tab, sender.widget(index)</p> required <code>sender</code> <code>PyQt5.QtWidgets.QTabWidget</code> <p>The tab group where a single tab was was closed</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_closeTab(self, index, sender):\n\"\"\"Close an open plugin tab.\n\n    Parameters\n    ----------\n    index : int\n        The index into sender that gives us the tab, sender.widget(index)\n    sender : PyQt5.QtWidgets.QTabWidget\n        The tab group where a single tab was was closed\n    \"\"\"\n\n    logger.info(f\"index:{index} sender:{type(sender)}\")\n\n    # remove plugin from self.xxx\n    # pluginInstancePointer is full class to actual plugin, like\n    # sanpy.interface.plugins.detectionParams.detectionParams\n    pluginInstancePointer = sender.widget(index)\n    logger.info(f\"  closing pluginInstancePointer:{type(pluginInstancePointer)}\")\n\n    # remove from preferences\n    # if pluginInstancePointer is not None:\n    #     self.configDict.removePlugin(pluginInstancePointer.getHumanName())\n\n    self.myPlugins.slot_closeWindow(pluginInstancePointer)\n\n    # remove the tab\n    sender.removeTab(index)\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_detect","title":"<code>slot_detect(ba)</code>","text":"<p>Respond to spike detection.</p> <p>Usually comes from the sanpy.interface.bDetectionWidget</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_detect(self, ba):\n\"\"\"Respond to spike detection.\n\n    Usually comes from the sanpy.interface.bDetectionWidget\n    \"\"\"\n\n    setSpikeStatEvent = {}\n    setSpikeStatEvent['ba'] = ba\n    setSpikeStatEvent[\"spikeList\"] = None  # self.getSelectedSpikes()\n    setSpikeStatEvent[\"colStr\"] = None  # colStr\n    setSpikeStatEvent[\"value\"] = None  # value\n\n    # sweep number does not change\n    self.signalUpdateAnalysis.emit(setSpikeStatEvent)\n\n    self.slot_updateStatus(f\"Detected {ba.numSpikes} spikes\")\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_dockLocationChanged","title":"<code>slot_dockLocationChanged(dock, area)</code>","text":"<p>Top level dock changed</p> <p>Parameters:</p> Name Type Description Default <code>dock</code> <code>xxx</code> required <code>area</code> <code>enum QtCore.Qt.DockWidgetArea</code> <p>Basically left/top/right/bottom.</p> required <p>Not triggered when user 'floats' a dock (See self.slot_topLevelChanged())</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_dockLocationChanged(self, dock, area):\n\"\"\"Top level dock changed\n\n    Parameters\n    ----------\n    dock : xxx\n    area : enum QtCore.Qt.DockWidgetArea\n        Basically left/top/right/bottom.\n\n    Not triggered when user 'floats' a dock (See self.slot_topLevelChanged())\n    \"\"\"\n    logger.info(f'not implemented, dock:\"{dock.windowTitle()}\" area enum: {area}')\n    return\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_fileTableClicked","title":"<code>slot_fileTableClicked(row, rowDict, selectingAgain)</code>","text":"<p>Respond to selections in file table.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_fileTableClicked(self, row, rowDict, selectingAgain):\n\"\"\"Respond to selections in file table.\"\"\"\n\n\"\"\"\n    row (int):\n    rowDict (dict):\n    selectingAgain (bool): True if row was already selected\n    \"\"\"\n\n    if selectingAgain:\n        self.slot_updateStatus(f'Refreshing file \"{rowDict[\"File\"]}\"')\n    else:\n        self.slot_updateStatus(f'Loading file \"{rowDict[\"File\"]}\" ... please wait')\n\n    # TODO: try and remove this\n    self.startSec = rowDict[\"Start(s)\"]\n    self.stopSec = rowDict[\"Stop(s)\"]\n\n    # This will load if necc, otherwise just fetch a pointer\n    if self.myAnalysisDir is not None:\n        ba = self.myAnalysisDir.getAnalysis(row)  # if None then problem loading\n\n        if ba is not None:\n            self.signalSwitchFile.emit(ba, rowDict)\n            if selectingAgain:\n                pass\n            else:\n                self.slot_updateStatus(\n                    f'Loaded file \"{ba.fileLoader.filename}\"'\n                )  # this will load ba if necc\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_loadFolder","title":"<code>slot_loadFolder(path='', folderDepth=None)</code>","text":"<p>Load a folder of raw data files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <code>''</code> <code>folderDepth</code> <code>int or None</code> <code>None</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_loadFolder(self, path=\"\", folderDepth=None):\n\"\"\"Load a folder of raw data files.\n\n    Parameters\n    ----------\n    path : str\n    folderDepth : int or None\n    \"\"\"\n\n    if folderDepth is None:\n        # get the depth from file list widget\n        folderDepth = self._fileListWidget.getDepth()\n\n    logger.info(f\"Loading depth:{folderDepth} path: {path}\")\n\n    # if folder is already loaded, ask to save\n    acceptAndContinue = self._promptIfDirty()\n    if not acceptAndContinue:\n        return\n\n    # ask user for folder\n    if path is None or isinstance(path, bool) or len(path) == 0:\n        path = str(\n            QtWidgets.QFileDialog.getExistingDirectory(\n                self, \"Select Directory With Recordings\"\n            )\n        )\n        if len(path) == 0:\n            return\n    elif os.path.isdir(path):\n        pass\n    else:\n        logger.warning(f'    Did not load path \"{path}\"')\n        return\n\n    self.path = path  # path to loaded bAnalysisDir folder\n\n    # logger.info(f'Loading path: {path}')\n\n    # will create/load hd5 file for folder\n    self.myAnalysisDir = sanpy.analysisDir(\n        path, folderDepth=folderDepth, myApp=self\n    )\n\n    # set myAnalysisDir to file list model\n    self.myModel = sanpy.interface.bFileTable.pandasModel(self.myAnalysisDir)\n    # self.myModel.signalMyDataChanged.connect(self.slot_dataChanged)\n    # self.myModel.signalMyDataChanged.connect(self.myDetectionWidget.slot_dataChanged)\n\n    # try:\n    if 1:\n        self._fileListWidget.mySetModel(self.myModel)\n        self.myModel.signalMyDataChanged.connect(\n            self.myDetectionWidget.slot_dataChanged\n        )\n\"\"\"\n    except (AttributeError) as e:\n        # needed when we call loadFolder from __init__\n        # logger.warning('OK: no tableView during load folder')\n        pass\n    \"\"\"\n\n    # set window title\n    if self.path is not None and os.path.isdir(self.path):\n        windowTitle = f\"SanPy: {self.path}\"\n    else:\n        windowTitle = \"SanPy\"\n    self.setWindowTitle(windowTitle)\n\n    # add to preferences recent folders\n    self.configDict.addFolder(path)\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_selectSweep","title":"<code>slot_selectSweep(ba, sweepNumber)</code>","text":"<p>Set view to new sweep.</p> <p>Parameters:</p> Name Type Description Default <code>ba</code> <code>sanpy.bAnalysis</code> required <code>sweepNumber</code> <code>int</code> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_selectSweep(self, ba, sweepNumber):\n\"\"\"Set view to new sweep.\n\n    Parameters\n    ----------\n    ba : sanpy.bAnalysis\n    sweepNumber : int\n    \"\"\"\n    self.signalSelectSweep.emit(ba, sweepNumber)\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_topLevelChanged","title":"<code>slot_topLevelChanged(topLevel)</code>","text":"<p>topLevel (bool): True if the dock widget is now floating; otherwise False.</p> <p>This is triggered twice, once while dragging and once when finished</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_topLevelChanged(self, topLevel):\n\"\"\"\n    topLevel (bool): True if the dock widget is now floating; otherwise False.\n\n    This is triggered twice, once while dragging and once when finished\n    \"\"\"\n    sender = self.sender()  # PyQt5.QtWidgets.QDockWidget\n    logger.info(f\"topLevel:{topLevel} sender:{sender}\")\n    return\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_updateAnalysis","title":"<code>slot_updateAnalysis(sDict)</code>","text":"<p>Respond to both detect and user setting columns in ba.</p> <p>sDict : dict     setSpikeStatEvent = {}     setSpikeStatEvent['ba'] = self.ba     setSpikeStatEvent[\"spikeList\"] = self.getSelectedSpikes()     setSpikeStatEvent[\"colStr\"] = colStr     setSpikeStatEvent[\"value\"] = value</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_updateAnalysis(self, sDict : dict):\n\"\"\"Respond to both detect and user setting columns in ba.\n\n    sDict : dict\n        setSpikeStatEvent = {}\n        setSpikeStatEvent['ba'] = self.ba\n        setSpikeStatEvent[\"spikeList\"] = self.getSelectedSpikes()\n        setSpikeStatEvent[\"colStr\"] = colStr\n        setSpikeStatEvent[\"value\"] = value\n    \"\"\"\n\n    logger.info('')\n\n    # do the actual update\n    ba = sDict['ba']\n    spikeList = sDict['spikeList']\n    colStr = sDict['colStr']\n    value = sDict['value']\n    if spikeList is not None and colStr is not None and value is not None:\n        logger.info(f'setting backend: {spikeList} colStr: {colStr} to value:{value}')\n        ba.setSpikeStat(spikeList, colStr, value)\n\n    self.signalUpdateAnalysis.emit(sDict)\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.slot_updateStatus","title":"<code>slot_updateStatus(text)</code>","text":"<p>Update the bottom status bar with new str</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def slot_updateStatus(self, text: str):\n\"\"\"Update the bottom status bar with new str\"\"\"\n    logger.info(text)\n\n    # having trouble with an immediate update?\n    self.statusBar.showMessage(text)\n    self.statusBar.repaint()\n    # self.statusBar.update()\n    self.repaint()\n    # self.update()\n    QtWidgets.qApp.processEvents()\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.SanPyWindow.toggleInterface","title":"<code>toggleInterface(name, on)</code>","text":"<p>Toggle named interface widgets show and hide.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the widget</p> required <code>on</code> <code>bool</code> <p>If True then show, otherwise hide.</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def toggleInterface(self, name, on):\n\"\"\"Toggle named interface widgets show and hide.\n\n    Parameters\n    ----------\n    name : str\n        Name of the widget\n    on : bool\n        If True then show, otherwise hide.\n    \"\"\"\n    if name == \"File Panel\":\n        self._fileListWidget.setVisible(on)\n        # if on:\n        #     self.fileDock.show()\n        # else:\n        #     self.fileDock.hide()\n    elif name == \"Plugins 1\":\n        if on:\n            self.pluginDock1.show()\n        else:\n            self.pluginDock1.hide()\n    elif name == \"Plugins 2\":\n        if on:\n            self.pluginDock2.show()\n        else:\n            self.pluginDock2.hide()\n</code></pre>"},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app-functions","title":"Functions","text":""},{"location":"api/interface/sanpy_app/#sanpy.interface.sanpy_app.main","title":"<code>main()</code>","text":"<p>Main entry point for the SanPy desktop app.</p> <p>Configured in setup.py</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/sanpy_app.py</code> <pre><code>def main():\n\"\"\"Main entry point for the SanPy desktop app.\n\n    Configured in setup.py\n    \"\"\"\n    logger.info(f\"Starting sanpy_app.py in main()\")\n    # date_time_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    # logger.info(f'    {date_time_str}')\n\n    # _version = _getVersionInfo()\n    # for k,v in _version.items():\n    #     logger.info(f'{k} {v}')\n\n'''\n    logger.info(f'    Python version is {platform.python_version()}')\n    logger.info(f'    Python platform is {platform.platform()}')\n\n    # when using import PyQt5\n    #logger.info(f\"    PyQt version is {QtCore.QT_VERSION_STR}\")\n    # when using import qtpy\n    logger.info(f\"    PyQt version is {QtCore.__version__}\")\n\n    bundle_dir = sanpy._util.getBundledDir()\n    logger.info(f'    bundle_dir is \"{bundle_dir}\"')\n\n    _logFilePath = sanpy.sanpyLogger.getLoggerFile()\n    logger.info(f\"    logging to file {_logFilePath}\")\n    '''\n\n    # for qdarkstyle\n    # os.environ['PYQTGRAPH_QT_LIB'] = 'PyQt5'\n\n    app = QtWidgets.QApplication(sys.argv)\n\n    app.setQuitOnLastWindowClosed(True)\n\n    # for manuscript we need to allow user to set light/dark theme\n    # was this\n    # v1\n    # app.setStyleSheet(qdarkstyle.load_stylesheet(qt_api=os.environ['PYQTGRAPH_QT_LIB']))\n    # v2\n    qdarktheme.setup_theme()\n\n    appIconPath = getAppIconPath()    \n    if os.path.isfile(appIconPath):\n        logger.info(f'  app.setWindowIcon with: \"{appIconPath}\"')\n        app.setWindowIcon(QtGui.QIcon(appIconPath))\n    else:\n        logger.warning(f\"    Did not find appIconPath: {appIconPath}\")\n\n    w = SanPyWindow()\n\n    w.show()\n    w.raise_()  # bring to front, raise is a python keyword\n    w.activateWindow()  # bring to front\n\n    sys.exit(app.exec_())\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/","title":"sanpyPlugin","text":"<p>         Bases: <code>QtWidgets.QWidget</code></p> <p>Base class for all SanPy plugins.</p> <p>Provides general purpose API to build plugings including:</p> <ul> <li>Open PyQt and Matplotlib plots</li> <li> <p>Set up signal/slots to communicate with the main SanPy app:</p> <ul> <li>file is changed</li> <li>detection is run</li> <li>spike is selected</li> <li>axis is changed</li> </ul> </li> </ul> <p>Users derive from this class to create new plugins.</p> <p>Examples:</p> <p>Run a plugin with the following code</p> <pre><code>import sys\nfrom PyQt5 import QtCore, QtWidgets, QtGui\nimport sanpy\nimport sanpy.interface\n\n# load sample data\npath = '../../../data/19114001.abf'\nba = sanpy.bAnalysis(path)\n\n# get presets detection parameters for 'SA Node'\n_dDict = sanpy.bDetection().getDetectionDict('SA Node')\n\n# spike detect\nba.spikeDetect(_dDict)\n\n# create a PyQt application\napp = QtWidgets.QApplication([])\n\n# open the interface for the 'plotScatter' plugin.\nsa = sanpy.interface.plugins.plotScatter(ba=ba, startStop=None)\n\nsys.exit(app.exec_())\n</code></pre> <p>Attributes:</p> Name Type Description <code>signalCloseWindow</code> <code>QtCore.pyqtSignal</code> <p>Signal emitted when the plugin window is closed.</p> <code>signalSelectSpikeList</code> <code>QtCore.pyqtSignal</code> <p>Signal emitted when spikes are selected in the plugin.</p> <code>ba</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>class sanpyPlugin(QtWidgets.QWidget):\n\"\"\"Base class for all SanPy plugins.\n\n    Provides general purpose API to build plugings including:\n\n    - Open PyQt and Matplotlib plots\n    - Set up signal/slots to communicate with the main SanPy app:\n\n        - file is changed\n        - detection is run\n        - spike is selected\n        - axis is changed\n\n    Users derive from this class to create new plugins.\n\n    Examples\n    --------\n    Run a plugin with the following code\n\n    ```python\n    import sys\n    from PyQt5 import QtCore, QtWidgets, QtGui\n    import sanpy\n    import sanpy.interface\n\n    # load sample data\n    path = '../../../data/19114001.abf'\n    ba = sanpy.bAnalysis(path)\n\n    # get presets detection parameters for 'SA Node'\n    _dDict = sanpy.bDetection().getDetectionDict('SA Node')\n\n    # spike detect\n    ba.spikeDetect(_dDict)\n\n    # create a PyQt application\n    app = QtWidgets.QApplication([])\n\n    # open the interface for the 'plotScatter' plugin.\n    sa = sanpy.interface.plugins.plotScatter(ba=ba, startStop=None)\n\n    sys.exit(app.exec_())\n    ```\n\n    Attributes\n    ----------\n    signalCloseWindow : QtCore.pyqtSignal\n        Signal emitted when the plugin window is closed.\n    signalSelectSpikeList : QtCore.pyqtSignal\n        Signal emitted when spikes are selected in the plugin.\n    ba\n    \"\"\"\n\n    signalCloseWindow = QtCore.pyqtSignal(object)\n\"\"\"Emit signal on window close.\"\"\"\n\n    # signalSelectSpike = QtCore.pyqtSignal(object)\n\"\"\"Emit signal on spike selection.\"\"\"\n\n    signalSelectSpikeList = QtCore.pyqtSignal(object)\n\"\"\"Emit signal on spike selection.\"\"\"\n\n    signalDetect = QtCore.pyqtSignal(object)\n\"\"\"Emit signal on spike selection.\"\"\"\n\n    myHumanName = \"UNDEFINED-PLUGIN-NAME\"\n\"\"\"Each derived class needs to define this.\"\"\"\n\n    #signalSetSpikeStat = QtCore.Signal(dict)\n    signalUpdateAnalysis = QtCore.Signal(dict)\n\"\"\"Set stats (columns) for a list of spikes.\"\"\"\n\n    # mar 11, if True then show in menus\n    showInMenu = True\n\n    responseTypes = ResponseType\n\"\"\"Defines how a plugin will response to interface changes. Includes (switchFile, analysisChange, selectSpike, setAxis).\"\"\"\n\n    def __init__(\n        self,\n        ba: Optional[sanpy.bAnalysis] = None,\n        bPlugin: Optional[\"sanpy.interface.bPlugin\"] = None,\n        startStop: Optional[List[float]] = None,\n        options=None,\n        parent=None,\n    ):\n\"\"\"\n        Parameters\n        ----------\n        ba : sanpy.bAnalysis\n            Object representing one file.\n        bPlugin : \"sanpy.interface.bPlugin\"\n            Used in PyQt to get SanPy App and to setup signal/slot.\n        startStop : list(float)\n            Start and stop (s) of x-axis.\n        options : dict\n            Depreciated.\n            Dictionary of optional plugins.\n                Used by 'plot tool' to plot a pool using app analysisDir dfMaster.\n        \"\"\"\n        super().__init__(parent)\n\n        self.setAttribute(QtCore.Qt.WA_DeleteOnClose)\n\n        # does not work, key press gets called first?\n        # self._closeAction = QtWidgets.QAction(\"Exit Application\", self)\n        # self._closeAction.setShortcut('Ctrl+W')\n        # self._closeAction.triggered.connect(self.close)\n\n        # derived classes will set this in init (see kymographPlugin)\n        self._initError: bool = False\n\n        # underlying bAnalaysis\n        self._ba: sanpy.bAnalysis = ba\n\n        # the sweep number of the sanpy.bAnalaysis\n        self._sweepNumber: Union[int, str] = \"All\"\n        self._epochNumber: Union[int, str] = \"All\"\n\n        self._bPlugins: \"sanpy.interface.bPlugin\" = bPlugin\n        # pointer to object, send signal back on close\n\n        self.darkTheme = True\n        if self.getSanPyApp() is not None:\n            _useDarkStyle = self.getSanPyApp().useDarkStyle\n            self.darkTheme = _useDarkStyle\n\n        # to show as a widget\n        self._showSelf: bool = True\n\n        self._blockSlots = False\n\n        # the start and stop secinds to display\n        self._startSec: Optional[float] = None\n        self._stopSec: Optional[float] = None\n        if startStop is not None:\n            self._startSec = startStop[0]\n            self._stopSec = startStop[1]\n\n        # keep track of spike selection\n        self._selectedSpikeList: List[int] = []\n\n        # build a dict of boolean from ResponseType enum class\n        # Things to respond to like switch file, set sweep, etc\n        self._responseOptions: dict = {}\n        for option in self.responseTypes:\n            # print(type(option))\n            self._responseOptions[option.name] = True\n\n        # mar 26 2023 was this\n        # doDark = self.getSanPyApp().useDarkStyle\n        # if doDark and qdarkstyle is not None:\n        #     self.setStyleSheet(qdarkstyle.load_stylesheet(qt_api='pyqt5'))\n        # else:\n        #     self.setStyleSheet(\"\")\n\n        # created in mplWindow2()\n        # these are causing really freaking annoying failures on GitHub !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n        # self.fig : \"matplotlib.figure.Figure\" = None\n        # self.axs : \"matplotlib.axes._axes.Axes\" = None\n        # self.mplToolbar : \"matplotlib.backends.backend_qt.NavigationToolbar2QT\" = None\n        self.fig = None\n        self.axs = None\n        self.mplToolbar = None\n\n        self.keyIsDown = None\n\n        self.winWidth_inches = 4  # used by mpl\n        self.winHeight_inches = 4\n\n        # connect self to main app with signals/slots\n        self._installSignalSlot()\n\n        self._mySetWindowTitle()\n\n        # all plugin widgets always have a single QtWidgetQVBoxLayout\n        # both widget and layouts can be added to this\n        self._vBoxLayout = self.makeVLayout()\n\n        # the top toolbar is always present\n        self._blockComboBox: bool = False\n        self._topToolbarWidget = self._buildTopToolbarWidget()\n\n        # if ba has &gt; 1 sweep or &gt; 2 epochs then show top toolbar\n        _showTop = False\n        if self.ba is not None:\n            _numEpochs = self.ba.fileLoader.numEpochs  # can be None\n            _showTop = self.ba.fileLoader.numSweeps&gt;1\n            _showTop = _showTop | _numEpochs is not None and _numEpochs&gt;2\n        self.toggleTopToobar(_showTop)  # initially hidden\n\n        self._updateTopToolbar()\n        self._vBoxLayout.addWidget(self._topToolbarWidget)\n\n    def _myClassName(self):\n        return self.__class__.__name__\n\n    def getPenColor(self) -&gt; str:\n\"\"\"Get pen color for pyqtgraph traces based on dark theme.\"\"\"\n        if self.darkTheme:\n            return \"w\"\n        else:\n            return \"k\"\n\n    def getStat(self, stat: str, getFullList : bool = False) -&gt; list:\n\"\"\"Convenianece function to get a stat from underling sanpy.bAnalysis.\n\n        Parameters\n        ----------\n        stat : str\n            Stat to get, corresponds to a column in sanpy.bAnalysis\n        \"\"\"\n        return self.ba.getStat(\n            stat, sweepNumber=self.sweepNumber,\n            epochNumber=self.epochNumber,\n            getFullList=getFullList\n        )\n\n    @property\n    def responseOptions(self):\n        return self._responseOptions\n\n    def toggleTopToobar(self, visible: bool = None):\n\"\"\"Toggle or set the top toolbar.\n\n        Parameters\n        ----------\n        visible : bool or None\n            If None then toggle, otherwise set to `visible`.\n        \"\"\"\n        if visible is None:\n            visible = not self._topToolbarWidget.isVisible()\n        self._topToolbarWidget.setVisible(visible)\n\n    def getVBoxLayout(self):\n\"\"\"Get the main PyQt.QWidgets.QVBoxLayout\n\n        Derived plugins can add to this with addWidget() and addLayout()\n        \"\"\"\n        return self._vBoxLayout\n\n    def getSelectedSpikes(self) -&gt; List[int]:\n\"\"\"Get the currently selected spikes.\"\"\"\n        return self._selectedSpikeList\n\n    def setSelectedSpikes(self, spikes: List[int]):\n\"\"\"Set the currently selected spikes.\n\n        Parameters\n        ----------\n        spikes : list of int\n        \"\"\"\n        self._selectedSpikeList = spikes\n\n    def getHumanName(self):\n\"\"\"Get the human readable name for the plugin.\n\n        Each plugin needs a unique name specified in the static property `myHumanName`.\n\n        This is used to display the plugin in the menus.\n        \"\"\"\n        return self.myHumanName\n\n    def getInitError(self):\n        return self._initError\n\n    def getWidget(self):\n\"\"\"Over-ride if plugin makes its own PyQt widget.\n\n        By default, all plugins inherit from PyQt.QWidgets.QWidget\n        \"\"\"\n        return self\n\n    def getShowSelf(self):\n        return self._showSelf\n\n    def setShowSelf(self, show: bool):\n        self._showSelf = show\n\n    @property\n    def sweepNumber(self):\n\"\"\"Get the current sweep number, can be 'All'.\"\"\"\n        return self._sweepNumber\n\n    @property\n    def epochNumber(self):\n\"\"\"Get the current epoch number, can be 'All'.\"\"\"\n        return self._epochNumber\n\n    def getSweep(self, type: str):\n\"\"\"Get the raw data from a sweep.\n\n        Parameters\n        ----------\n        type : str\n            The sweep type from ('X', 'Y', 'C', 'filteredDeriv', 'filteredVm')\n        \"\"\"\n        theRet = None\n        type = type.upper()\n        if self.ba is None:\n            return theRet\n        if type == \"X\":\n            theRet = self.ba.fileLoader.sweepX\n        elif type == \"Y\":\n            theRet = self.ba.fileLoader.sweepY\n        elif type == \"C\":\n            theRet = self.ba.fileLoader.sweepC\n        elif type == \"filteredDeriv\":\n            theRet = self.ba.fileLoader.filteredDeriv\n        elif type == \"filteredVm\":\n            theRet = self.ba.fileLoader.sweepY_filtered\n        else:\n            logger.error(f'Did not understand type: \"{type}\"')\n\n        return theRet\n\n    @property\n    def ba(self):\n\"\"\"Get the current sanpy.bAnalysis object.\n\n        Returns\n        -------\n        sanpy.bAnalysis\n            The underlying bAnalysis object\n        \"\"\"\n        return self._ba\n\n    def get_bPlugins(self) -&gt; \"sanpy.interface.bPlugins\":\n\"\"\"Get the SanPy app bPlugin object.\n\n        Returns\n        -------\n        sanpy.interface.bPlugins\n        \"\"\"\n        return self._bPlugins\n\n    def getSanPyApp(self) -&gt; \"sanpy.interface.sanpy_app\":\n\"\"\"Return underlying SanPy app.\n\n        Only exists if running in SanPy Qt Gui\n\n        Returns\n        -------\n        sanpy.interface.sanpy_app\n        \"\"\"\n        if self._bPlugins is not None:\n            return self._bPlugins.getSanPyApp()\n\n    def _installSignalSlot(self):\n\"\"\"Set up PyQt signals/slots.\n\n        Be sure to call _disconnectSignalSlot() on plugin destruction.\n        \"\"\"\n        app = self.getSanPyApp()\n        if app is not None:\n            # receive spike selection\n            app.signalSelectSpikeList.connect(self.slot_selectSpikeList)\n\n            # receive update analysis (both file change and detect)\n            app.signalUpdateAnalysis.connect(self.slot_updateAnalysis)\n            self.signalUpdateAnalysis.connect(app.slot_updateAnalysis)\n\n            app.signalSwitchFile.connect(self.slot_switchFile)\n\n            # recieve set sweep\n            app.signalSelectSweep.connect(self.slot_setSweep)\n\n            # recieve set x axis\n            app.signalSetXAxis.connect(self.slot_set_x_axis)\n\n            # emit when we spike detect (used in detectionParams plugin)\n            self.signalDetect.connect(app.slot_detect)\n\n            self.signalSelectSpikeList.connect(app.slot_selectSpikeList)\n\n        bPlugins = self.get_bPlugins()\n        if bPlugins is not None:\n            # emit spike selection\n            # self.signalSelectSpike.connect(bPlugins.slot_selectSpike)\n\n            # removed april 29\n            #self.signalSelectSpikeList.connect(bPlugins.slot_selectSpikeList)\n\n            # emit on close window\n            self.signalCloseWindow.connect(bPlugins.slot_closeWindow)\n\n        # connect to self\n        # self.signalSelectSpike.connect(self.slot_selectSpike)\n        # self.signalSelectSpikeList.connect(self.slot_selectSpikeList)\n\n    def _disconnectSignalSlot(self):\n\"\"\"Disconnect PyQt signal/slot on destruction.\"\"\"\n        app = self.getSanPyApp()\n        if app is not None:\n            # receive spike selection\n            # app.signalSelectSpike.disconnect(self.slot_selectSpike)\n            # receive update analysis (both file change and detect)\n            app.signalSwitchFile.disconnect(self.slot_switchFile)\n            app.signalUpdateAnalysis.disconnect(self.slot_updateAnalysis)\n            # recieve set sweep\n            app.signalSelectSweep.disconnect(self.slot_setSweep)\n            # recieve set x axis\n            app.signalSetXAxis.disconnect(self.slot_set_x_axis)\n\n    def toggleResponseOptions(self, thisOption: ResponseType, newValue: bool = None):\n\"\"\"Set underlying responseOptions based on name of thisOption.\n\n        Parameters\n        ----------\n        thisOption : ResponseType\n        newValue : Optional[bool]\n            If boolean then set, if None then toggle.\n        \"\"\"\n        # logger.info(f'{thisOption} {newValue}')\n        if newValue is None:\n            newValue = not self.responseOptions[thisOption.name]\n        self.responseOptions[thisOption.name] = newValue\n\n    def _getResponseOption(self, thisOption: ResponseType) -&gt; str:\n\"\"\"Get the state of a plot option from responseOptions.\n\n        Parameters\n        ----------\n        thisOption : ResponseType\n        \"\"\"\n        return self.responseOptions[thisOption.name]\n\n    def plot(self):\n\"\"\"Derived class adds code to plot.\"\"\"\n        pass\n\n    def replot(self):\n\"\"\"Derived class adds code to replot.\"\"\"\n        pass\n\n    def old_selectSpike(self, sDict=None):\n\"\"\"Derived class adds code to select spike from sDict.\"\"\"\n        pass\n\n    def selectSpikeList(self):\n\"\"\"Derived class adds code to select spike from sDict.\n\n        Get selected spike list with getSelectedSpikes()\n        \"\"\"\n        pass\n\n    def getStartStop(self):\n\"\"\"Get current start stop of interface.\n\n        Returns:\n            tuple: (start, stop) in seconds. Can be None\n        \"\"\"\n        return self._startSec, self._stopSec\n\n    def keyReleaseEvent(self, event):\n        self.keyIsDown = None\n\n    def keyPressEvent(self, event):\n\"\"\"Handle key press events.\n\n        On 'ctrl+c' will copy-to-clipboard.\n\n        On 'esc' emits signalSelectSpikeList.\n\n        Parameters\n        ----------\n        event : Union[QtGui.QKeyEvent, matplotlib.backend_bases.KeyEvent]\n            Either a PyQt or matplotlib key press event.\n        \"\"\"\n        isQt = isinstance(event, QtGui.QKeyEvent)\n        isMpl = isinstance(event, mpl.backend_bases.KeyEvent)\n\n        key = None\n        text = None\n        doCopy = False\n        doClose = False\n        if isQt:\n            key = event.key()\n            text = event.text()\n            doCopy = event.matches(QtGui.QKeySequence.Copy)\n            doClose = event.matches(QtGui.QKeySequence.Close)\n        elif isMpl:\n            # q will quit !!!!\n            text = event.key\n            doCopy = text in [\"ctrl+c\", \"cmd+c\"]\n            doClose = text in [\"ctrl+w\", \"cmd+w\"]\n            logger.info(f'mpl key: \"{text}\"')\n        else:\n            logger.warning(f\"Unknown event type: {type(event)}\")\n            return\n\n        self.keyIsDown = text\n\n        if doCopy:\n            self.copyToClipboard()\n        elif doClose:\n            self.close()\n        elif key == QtCore.Qt.Key_Escape or text == \"esc\" or text == \"escape\":\n            # single spike\n            # sDict = {\n            #     'spikeNumber': None,\n            #     'doZoom': False,\n            #     'ba': self.ba,\n\n            # }\n            # self.signalSelectSpike.emit(sDict)\n            # spike list\n            sDict = {\n                \"spikeList\": [],\n                \"doZoom\": False,\n                \"ba\": self.ba,\n            }\n            self.signalSelectSpikeList.emit(sDict)\n        elif key == QtCore.Qt.Key_T or text == \"t\":\n            self.toggleTopToobar()\n        elif text == \"\":\n            pass\n\n        # critical difference between mpl and qt\n        if isMpl:\n            return text\n        else:\n            # return event\n            return\n\n    def copyToClipboard(self, df=None):\n\"\"\"Derived classes add code to copy plugin to clipboard.\"\"\"\n        if df is None:\n            return\n\n        logger.info(\"\")\n        if self.ba is None:\n            return\n\n        fileName = self.ba.fileLoader.filename\n        fileName += \".csv\"\n        savePath = fileName\n        options = QtWidgets.QFileDialog.Options()\n        fileName, _ = QtWidgets.QFileDialog.getSaveFileName(\n            self, \"Save .csv file\", savePath, \"CSV Files (*.csv)\", options=options\n        )\n        if not fileName:\n            return\n\n        logger.info(f'Saving: \"{fileName}\"')\n        df.to_csv(fileName, index=False)\n\n    def saveResultsFigure(self, pgPlot=None):\n\"\"\"In derived, add code to save main figure to file.\n\n        In derived, pass in a pg plot from a view and we will save it.\n        \"\"\"\n        if pgPlot is None:\n            return\n\n        exporter = pg.exporters.ImageExporter(pgPlot)\n        # print(f'exporter: {type(exporter)}')\n        # print('getSupportedImageFormats:', exporter.getSupportedImageFormats())\n        # set export parameters if needed\n\n        # (width, height, antialias, background, invertvalue)\n        exporter.parameters()[\n            \"width\"\n        ] = 1000  # (note this also affects height parameter)\n\n        # ask user for file\n        fileName = self.ba.fileLoader.filename\n        fileName += \".png\"\n        savePath = fileName\n        options = QtWidgets.QFileDialog.Options()\n        fileName, _ = QtWidgets.QFileDialog.getSaveFileName(\n            self, \"Save .png file\", savePath, \"CSV Files (*.png)\", options=options\n        )\n        if not fileName:\n            return\n\n        # save to file\n        logger.info(f\"Saving to: {fileName}\")\n        exporter.export(fileName)\n\n    def bringToFront(self):\n\"\"\"Bring the widget to the front.\"\"\"\n        if not self._showSelf:\n            return\n\n        # Qt\n        self.getWidget().show()\n        self.getWidget().activateWindow()\n\n        # Matplotlib\n        if self.fig is not None:\n            FigureManagerQT = self.fig.canvas.manager\n            FigureManagerQT.window.activateWindow()\n            FigureManagerQT.window.raise_()\n\n    def makeVLayout(self):\n\"\"\"Make a PyQt QVBoxLayout.\"\"\"\n        vBoxLayout = QtWidgets.QVBoxLayout()\n        self.setLayout(vBoxLayout)\n        return vBoxLayout\n\n    def mplWindow2(self, numRow=1, numCol=1, addToLayout: bool = True):\n\"\"\"Make a matplotlib figure, canvas, and axis.\n\n        Parameters\n        ----------\n        numRow : int\n        numCol : int\n        addToLayout : bool\n            If true then add widget to main `getVBoxLayou()`.\n\n        Returns\n        -------\n        self.static_canvas, self.mplToolbar\n\n        \"\"\"\n        # plt.style.use('dark_background')\n        if self.darkTheme:\n            plt.style.use(\"dark_background\")\n        else:\n            plt.rcParams.update(plt.rcParamsDefault)\n\n        # this is dangerous, collides with self.mplWindow()\n        # these are causing really freaking annoying failures on GitHub !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n        # self.fig : \"matplotlib.figure.Figure\" = mpl.figure.Figure()\n        self.fig = mpl.figure.Figure()\n\n        # not working\n        # self.fig.canvas.mpl_connect('key_press_event', self.keyPressEvent)\n\n        self.static_canvas = backend_qt5agg.FigureCanvas(self.fig)\n        self.static_canvas.setFocusPolicy(\n            QtCore.Qt.ClickFocus\n        )  # this is really triccky and annoying\n        self.static_canvas.setFocus()\n        self.fig.canvas.mpl_connect(\"key_press_event\", self.keyPressEvent)\n\n        self.axs = [None] * numRow  # empty list\n        if numRow == 1 and numCol == 1:\n            _static_ax = self.static_canvas.figure.subplots()\n            self.axs = _static_ax\n            # print('self.axs:', type(self.axs))\n        else:\n            for idx in range(numRow):\n                plotNum = idx + 1\n                # print('mplWindow2()', idx)\n                self.axs[idx] = self.static_canvas.figure.add_subplot(\n                    numRow, 1, plotNum\n                )\n\n        # does not work\n        # self.static_canvas.mpl_connect('key_press_event', self.keyPressEvent)\n\n        # pick_event assumes 'picker=5' in any .plot()\n        # does this need to be a member? I think so?\n        self._cid = self.static_canvas.mpl_connect(\"pick_event\", self.spike_pick_event)\n\n        # matplotlib plot tools toolbar (zoom, pan, save, etc)\n        # from matplotlib.backends.backend_qt5agg import NavigationToolbar2QT as NavigationToolbar\n        self.mplToolbar = mpl.backends.backend_qt5agg.NavigationToolbar2QT(\n            self.static_canvas, self.static_canvas\n        )\n\n        # layout = QtWidgets.QVBoxLayout()\n        if addToLayout:\n            layout = self.getVBoxLayout()\n            layout.addWidget(self.static_canvas)\n            layout.addWidget(self.mplToolbar)\n        else:\n            return self.static_canvas, self.mplToolbar\n\n    def _mySetWindowTitle(self):\n\"\"\"Set the window title based on ba.\"\"\"\n        if self.ba is not None:\n            fileName = self.ba.fileLoader.filename\n        else:\n            fileName = \"\"\n        _windowTitle = self.myHumanName + \":\" + fileName\n\n        # mpl\n        if self.fig is not None:\n            if self.fig.canvas.manager is not None:\n                self.fig.canvas.manager.set_window_title(_windowTitle)\n\n        # pyqt\n        # self.mainWidget._mySetWindowTitle(self.windowTitle)\n        self.getWidget().setWindowTitle(_windowTitle)\n\n    def spike_pick_event(self, event):\n\"\"\"Respond to user clicks in mpl plot\n\n        Assumes plot(..., picker=5)\n\n        Parameters\n        ----------\n        event : matplotlib.backend_bases.PickEvent\n            PickEvent with plot indices in ind[]\n        \"\"\"\n        if len(event.ind) &lt; 1:\n            return\n\n        # logger.info(f'{event.ind}')\n\n        spikeNumber = event.ind[0]\n\n        doZoom = False\n        modifiers = QtWidgets.QApplication.keyboardModifiers()\n        if modifiers == QtCore.Qt.ShiftModifier:\n            doZoom = True\n\n        logger.info(\n            f\"got {len(event.ind)} candidates, first is spike:{spikeNumber} doZoom:{doZoom}\"\n        )\n\n        # propagate a signal to parent\n        # TODO: use class SpikeSelectEvent()\n        sDict = {\n            \"spikeList\": [spikeNumber],\n            \"doZoom\": doZoom,\n            \"ba\": self.ba,\n        }\n        self.signalSelectSpikeList.emit(sDict)\n\n    def closeEvent(self, event):\n\"\"\"Called when window is closed.\n\n        Signal close event back to parent bPlugin object.\n\n        Parameters\n        ----------\n        event Union[matplotlib.backend_bases.CloseEvent, PyQt5.QtGui.QCloseEvent]\n            The close event from either PyQt or matplotlib\n        \"\"\"\n        logger.info(f\"  --&gt;&gt; emit signalCloseWindow(self)\")\n        self.signalCloseWindow.emit(self)\n\n    def slot_switchFile(\n        self, ba: sanpy.bAnalysis, rowDict: Optional[dict] = None, replot: bool = True\n    ):\n\"\"\"Respond to switch file.\n\n        Parameters\n        ----------\n        rowDict : dict\n            Optional, assumes rowDict has keys ['Start(s)', 'Stop(s)']\n        ba : sanpy.bAnalysis\n            The new bAnalysis file to switch to\n        replot : bool\n            If true then call replot()\n        \"\"\"\n        if not self._getResponseOption(self.responseTypes.switchFile):\n            return\n\n        if ba is None:\n            return\n\n        # don't respond if we are already using ba\n        if self._ba == ba:\n            return\n\n        self._ba = ba\n        # self.fileRowDict = rowDict  # for detectionParams plugin\n\n        # rest sweep and epoch\n        self._sweepNumber = 0\n        self._epochNumber = 'All'\n\n        # reset start/stop\n        startSec = None\n        stopSec = None\n        if rowDict is not None:\n            startSec = rowDict[\"Start(s)\"]\n            stopSec = rowDict[\"Stop(s)\"]\n            if math.isnan(startSec):\n                startSec = None\n            if math.isnan(stopSec):\n                stopSec = None\n        self._startSec = startSec\n        self._stopSec = stopSec\n\n        # reset spike and spike list selection\n        self._selectedSpikeList = []\n        self.selectedSpike = None\n\n        # inform derived classes of change\n        # self.old_selectSpike()\n        self.selectSpikeList()\n\n        # set pyqt window title\n        self._mySetWindowTitle()\n\n        self._updateTopToolbar()\n\n        if replot:\n            self.replot()\n\n    def slot_updateAnalysis(self, sDict : dict):\n\"\"\"Respond to new spike detection.\n\n        Parameters\n        ----------\n        sDict : dict\n        \"\"\"\n        logger.info(\"\")\n        if not self._getResponseOption(self.responseTypes.analysisChange):\n            return\n\n        ba = sDict['ba']\n\n        if ba is None:\n            return\n\n        # don't update analysis if we are showing different ba\n        if self._ba != ba:\n            return\n\n        self.replot()\n\n    def slot_setSweep(self, ba: sanpy.bAnalysis, sweepNumber: int):\n\"\"\"Respond to user selecting a sweep.\"\"\"\n\n        if not self._getResponseOption(self.responseTypes.setSweep):\n            return\n\n        logger.info(f\"{self._myClassName()}\")\n\n        if ba is None:\n            return\n\n        # don't respond if we are showing different ba\n        if self._ba != ba:\n            return\n\n        self._sweepNumber = sweepNumber\n\n        # reset selection\n        self._selectedSpikeList = []\n        self.selectedSpike = None\n\n        # update toolbar\n        self._updateTopToolbar()\n\n        self.replot()\n\n    def slot_selectSpikeList(self, eDict: dict):\n\"\"\"Respond to spike selection.\n\n        TODO: convert dict to class spikeSelection\n        \"\"\"\n\n        if self._blockSlots:\n            return\n\n        logger.info(f\"{self._myClassName()} num spikes:{len(eDict['spikeList'])}\")\n\n        # don't respond if we are showing a different ba (bAnalysis)\n        ba = eDict[\"ba\"]\n        if self.ba != ba:\n            return\n\n        spikeList = eDict[\"spikeList\"]\n        self._selectedSpikeList = spikeList  # [] on no selection\n\n        self.selectSpikeList()\n\n    def old_slot_selectSpike(self, eDict):\n\"\"\"Respond to spike selection.\"\"\"\n\n        # don't respond if user/code has turned this off\n        if not self._getResponseOption(self.responseTypes.selectSpike):\n            return\n\n        # don't respond if we are showing a different ba (bAnalysis)\n        ba = eDict[\"ba\"]\n        if self.ba != ba:\n            return\n\n        self.selectedSpike = eDict[\"spikeNumber\"]\n\n        self.old_selectSpike(eDict)\n\n    def slot_set_x_axis(self, startStopList: List[float]):\n\"\"\"Respond to changes in x-axis.\n\n        Parameters\n        ----------\n        startStopList : list(float)\n            Two element list with [start, stop] in seconds\n        \"\"\"\n        if not self._getResponseOption(self.responseTypes.setAxis):\n            return\n\n        # don't set axis if we are showing different ba\n        app = self.getSanPyApp()\n        if app is not None:\n            ba = app.get_bAnalysis()\n            if self._ba != ba:\n                return\n\n        if startStopList is None:\n            self._startSec = None\n            self._stopSec = None\n        else:\n            self._startSec = startStopList[0]\n            self._stopSec = startStopList[1]\n        #\n        # we do not always want to replot on set axis\n        self.setAxis()\n        self.replot()\n\n    def setAxis(self):\n\"\"\"Respond to set axis.\n\n        Some plugins want to replot() when x-axis changes.\n        \"\"\"\n        pass\n\n    def _turnOffAllSignalSlot(self):\n\"\"\"Make plugin not respond to any changes in interface.\"\"\"\n        # turn off all signal/slot\n        switchFile = self.responseTypes.switchFile\n        self.toggleResponseOptions(switchFile, newValue=False)\n\n        setSweep = self.responseTypes.setSweep\n        self.toggleResponseOptions(setSweep, newValue=False)\n\n        analysisChange = self.responseTypes.analysisChange\n        self.toggleResponseOptions(analysisChange, newValue=False)\n\n        selectSpike = self.responseTypes.selectSpike\n        self.toggleResponseOptions(selectSpike, newValue=False)\n\n        setAxis = self.responseTypes.setAxis\n        self.toggleResponseOptions(setAxis, newValue=False)\n\n    def contextMenuEvent(self, event):\n\"\"\"Show popup menu (QComboBox) on mouse right-click.\n\n        This is inherited from QWidget\n        and should only be modified for advanced usage.\n\n        See `prependMenus` for plugins to add items to this contect menu.\n\n        Parameters\n        ----------\n        event : QtGui.QContextMenuEvent\n            Used to position popup\n        \"\"\"\n        if self.mplToolbar is not None:\n            state = self.mplToolbar.mode\n            if state in [\"zoom rect\", \"pan/zoom\"]:\n                # don't process right-click when toolbar is active\n                return\n\n        logger.info(\"\")\n\n        contextMenu = QtWidgets.QMenu(self)\n\n        # prepend any menu from derived classes\n        self.prependMenus(contextMenu)\n\n        switchFile = contextMenu.addAction(\"Switch File\")\n        switchFile.setCheckable(True)\n        switchFile.setChecked(self.responseOptions[\"switchFile\"])\n\n        setSweep = contextMenu.addAction(\"Set Sweep\")\n        setSweep.setCheckable(True)\n        setSweep.setChecked(self.responseOptions[\"setSweep\"])\n\n        analysisChange = contextMenu.addAction(\"Analysis Change\")\n        analysisChange.setCheckable(True)\n        analysisChange.setChecked(self.responseOptions[\"analysisChange\"])\n\n        selectSpike = contextMenu.addAction(\"Select Spike\")\n        selectSpike.setCheckable(True)\n        selectSpike.setChecked(self.responseOptions[\"selectSpike\"])\n\n        axisChange = contextMenu.addAction(\"Axis Change\")\n        axisChange.setCheckable(True)\n        axisChange.setChecked(self.responseOptions[\"setAxis\"])\n\n        contextMenu.addSeparator()\n        copyTable = contextMenu.addAction(\"Copy Results\")\n        saveFigure = contextMenu.addAction(\"Save Figure\")\n\n        contextMenu.addSeparator()\n        showTopToolbar = contextMenu.addAction(\"Toggle Top Toolbar\")\n\n        # contextMenu.addSeparator()\n        # saveTable = contextMenu.addAction(\"Save Table\")\n\n        #\n        # open the menu\n        action = contextMenu.exec_(self.mapToGlobal(event.pos()))\n\n        if action is None:\n            # no menu selected\n            return\n\n        #\n        # handle actions in derived plugins\n        handled = self.handleContextMenu(action)\n\n        if handled:\n            return\n\n        if action == switchFile:\n            self.toggleResponseOptions(self.responseTypes.switchFile)\n        elif action == setSweep:\n            self.toggleResponseOptions(self.responseTypes.setSweep)\n        elif action == analysisChange:\n            self.toggleResponseOptions(self.responseTypes.analysisChange)\n        elif action == selectSpike:\n            self.toggleResponseOptions(self.responseTypes.selectSpike)\n        elif action == axisChange:\n            self.toggleResponseOptions(self.responseTypes.setAxis)\n        elif action == copyTable:\n            self.copyToClipboard()\n        elif action == saveFigure:\n            self.saveResultsFigure()\n        elif action == showTopToolbar:\n            self.toggleTopToobar()\n        # elif action == saveTable:\n        #    #self.saveToFile()\n        #    logger.info('NOT IMPLEMENTED')\n\n        elif action is not None:\n            logger.warning(f'Menu action not taken \"{action.text}\"')\n\n    def prependMenus(self, contextMenu: \"QtWidgets.QMenu\"):\n\"\"\"Prepend menus to mouse right-click contect menu.\n\n        Parameters\n        ----------\n        contextMenu : QtWidgets.QMenu\n        \"\"\"\n        pass\n\n    def handleContextMenu(self, action: \"QtGui.QAction\"):\n\"\"\"Derived plugins need to define this to handle right-click contect menu actions.\n\n        Only needed if `prependMenus` is used.\n\n        Parameters\n        ----------\n        action : QtGui.QAction\n        \"\"\"\n        pass\n\n    def _updateTopToolbar(self):\n\"\"\"Update the top toolbar on state change like switch file.\"\"\"\n\n        if self.ba is None:\n            return\n\n        _sweepList = self.ba.fileLoader.sweepList\n        self._blockComboBox = True\n        self._sweepComboBox.clear()\n        self._sweepComboBox.addItem(\"All\")\n        for _sweep in _sweepList:\n            self._sweepComboBox.addItem(str(_sweep))\n        _enabled = len(_sweepList) &gt; 1\n        self._sweepComboBox.setEnabled(_enabled)\n        if self.sweepNumber == \"All\":\n            self._sweepComboBox.setCurrentIndex(0)\n        else:\n            self._sweepComboBox.setCurrentIndex(self.sweepNumber + 1)\n        self._blockComboBox = False\n\n        # minimum of 2 (never 1 or 0)\n        # because of annoying pClamp default short epoch 0\n        _numEpochs = self.ba.fileLoader.numEpochs\n        if _numEpochs is not None:\n            self._blockComboBox = True\n            self._epochComboBox.clear()\n            self._epochComboBox.addItem(\"All\")\n            for _epoch in range(_numEpochs):\n                self._epochComboBox.addItem(str(_epoch))\n            _enabled = True  # _numEpochs &gt; 2\n            self._epochComboBox.setEnabled(_enabled)\n            if self.epochNumber == \"All\":\n                self._epochComboBox.setCurrentIndex(0)\n            else:\n                self._epochComboBox.setCurrentIndex(self.epochNumber + 1)\n            self._blockComboBox = False\n        else:\n            # no epochs defined\n            self._epochComboBox.setEnabled(False)\n\n        # filename = self.ba.getFileName()\n        # self._fileLabel.setText(filename)\n\n    def _on_sweep_combo_box(self, idx: int):\n\"\"\"Respond to user selecting sweep combobox.\n\n        Notes\n        -----\n        idx 0 is 'All', idx 1 is sweep 0\n        \"\"\"\n        if self._blockComboBox:\n            return\n\n        idx = idx - 1  # first item is always 'All'\n        if idx == -1:\n            idx = \"All\"\n        logger.info(idx)\n        self._sweepNumber = idx\n\n        if self.ba is None:\n            return\n\n        self.replot()\n\n    def _on_epoch_combo_box(self, idx: int):\n\"\"\"Respond to user selecting epoch combobox.\n\n        Notes\n        -----\n        idx 0 is 'All', idx 1 is epoch 0\n        \"\"\"\n        if self._blockComboBox:\n            return\n\n        idx = idx - 1  # first item is always 'All'\n        if idx == -1:\n            idx = \"All\"\n        logger.info(idx)\n        self._epochNumber = idx\n\n        if self.ba is None:\n            return\n\n        self.replot()\n\n    def _buildTopToolbarWidget(self) -&gt; QtWidgets.QWidget:\n\"\"\"Top toolbar to show file, toggle responses on/off, etc\"\"\"\n\n        # TODO: Super annoying that popups come up blank if using AlignLeft ???\n\n        #\n        # first row of controls\n        hLayout0 = QtWidgets.QHBoxLayout()\n\n        # sweep popup\n        aLabel = QtWidgets.QLabel(\"Sweeps\")\n        # hLayout0.addWidget(aLabel, alignment=QtCore.Qt.AlignLeft)\n        hLayout0.addWidget(aLabel)\n        self._sweepComboBox = QtWidgets.QComboBox()\n        self._sweepComboBox.currentIndexChanged.connect(self._on_sweep_combo_box)\n        # hLayout0.addWidget(self._sweepComboBox, alignment=QtCore.Qt.AlignLeft)\n        hLayout0.addWidget(self._sweepComboBox)\n\n        # hLayout0.addStretch()\n\n        # epoch popup\n        aLabel = QtWidgets.QLabel(\"Epochs\")\n        hLayout0.addWidget(aLabel, alignment=QtCore.Qt.AlignLeft)\n        # hLayout0.addWidget(aLabel)\n        self._epochComboBox = QtWidgets.QComboBox()\n        self._epochComboBox.currentIndexChanged.connect(self._on_epoch_combo_box)\n        # hLayout0.addWidget(self._epochComboBox, alignment=QtCore.Qt.AlignLeft)\n        hLayout0.addWidget(self._epochComboBox)\n\n        # update on switch file\n        # self._fileLabel = QtWidgets.QLabel('File')\n        # hLayout0.addWidget(self._fileLabel, alignment=QtCore.Qt.AlignLeft)\n\n        # update for all response types (switch file, set sweep, analyze, ...)\n        # self._numSpikesLabel = QtWidgets.QLabel('unknown spikes')\n        # hLayout0.addWidget(self._numSpikesLabel, alignment=QtCore.Qt.AlignLeft)\n\n        # hLayout0.addStretch()\n\n        #\n        # second row of controls\n        hLayout1 = QtWidgets.QHBoxLayout()\n\n        # a checkbox for each 'respond to' in the ResponseType enum\n        for item in ResponseType:\n            aCheckbox = QtWidgets.QCheckBox(item.value)\n            aCheckbox.setChecked(self.responseOptions[item.name])\n            aCheckbox.stateChanged.connect(\n                functools.partial(self.toggleResponseOptions, item)\n            )\n            hLayout1.addWidget(aCheckbox, alignment=QtCore.Qt.AlignLeft)\n\n        hLayout1.addStretch()\n\n        # toolbar layout needs to be in a widget so it can be hidden\n        _mainWidget = QtWidgets.QWidget()\n        _topToolbarLayout = QtWidgets.QVBoxLayout(_mainWidget)\n        _topToolbarLayout.addLayout(hLayout0)\n        _topToolbarLayout.addLayout(hLayout1)\n\n        return _mainWidget\n\n    # def __on_checkbox_clicked(self, checkBoxName, checkBoxState):\n    #     logger.info(checkBoxName, checkBoxState)\n\n    def getWindowGeometry(self):\n\"\"\"Get the current window position.\"\"\"\n        myRect = self.geometry()\n        left = myRect.left()\n        top = myRect.top()\n        width = myRect.width()\n        height = myRect.height()\n        return left, top, width, height\n</code></pre> <p>         Bases: <code>enum.Enum</code></p> <p>Enum representing the types of events a Plugin will respond to.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>class ResponseType(enum.Enum):\n\"\"\"Enum representing the types of events a Plugin will respond to.\"\"\"\n\n    switchFile = \"Switch File\"\n    setSweep = \"Set Sweep\"\n    analysisChange = \"Analysis Change\"\n    selectSpike = \"Select Spike\"\n    setAxis = \"Set Axis\"\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin-attributes","title":"Attributes","text":""},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.ba","title":"<code>ba</code>  <code>property</code>","text":"<p>Get the current sanpy.bAnalysis object.</p> <p>Returns:</p> Type Description <code>sanpy.bAnalysis</code> <p>The underlying bAnalysis object</p>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.epochNumber","title":"<code>epochNumber</code>  <code>property</code>","text":"<p>Get the current epoch number, can be 'All'.</p>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.myHumanName","title":"<code>myHumanName = 'UNDEFINED-PLUGIN-NAME'</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Each derived class needs to define this.</p>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.responseTypes","title":"<code>responseTypes = ResponseType</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Defines how a plugin will response to interface changes. Includes (switchFile, analysisChange, selectSpike, setAxis).</p>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.signalCloseWindow","title":"<code>signalCloseWindow = QtCore.pyqtSignal(object)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Emit signal on window close.</p>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.signalDetect","title":"<code>signalDetect = QtCore.pyqtSignal(object)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Emit signal on spike selection.</p>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.signalSelectSpikeList","title":"<code>signalSelectSpikeList = QtCore.pyqtSignal(object)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Emit signal on spike selection.</p>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.signalUpdateAnalysis","title":"<code>signalUpdateAnalysis = QtCore.Signal(dict)</code>  <code>instance-attribute</code> <code>class-attribute</code>","text":"<p>Set stats (columns) for a list of spikes.</p>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.sweepNumber","title":"<code>sweepNumber</code>  <code>property</code>","text":"<p>Get the current sweep number, can be 'All'.</p>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin-functions","title":"Functions","text":""},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.__init__","title":"<code>__init__(ba=None, bPlugin=None, startStop=None, options=None, parent=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>ba</code> <code>sanpy.bAnalysis</code> <p>Object representing one file.</p> <code>None</code> <code>bPlugin</code> <code>bPlugin</code> <p>Used in PyQt to get SanPy App and to setup signal/slot.</p> <code>None</code> <code>startStop</code> <code>list(float)</code> <p>Start and stop (s) of x-axis.</p> <code>None</code> <code>options</code> <code>dict</code> <p>Depreciated. Dictionary of optional plugins. Used by 'plot tool' to plot a pool using app analysisDir dfMaster.</p> <code>None</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def __init__(\n    self,\n    ba: Optional[sanpy.bAnalysis] = None,\n    bPlugin: Optional[\"sanpy.interface.bPlugin\"] = None,\n    startStop: Optional[List[float]] = None,\n    options=None,\n    parent=None,\n):\n\"\"\"\n    Parameters\n    ----------\n    ba : sanpy.bAnalysis\n        Object representing one file.\n    bPlugin : \"sanpy.interface.bPlugin\"\n        Used in PyQt to get SanPy App and to setup signal/slot.\n    startStop : list(float)\n        Start and stop (s) of x-axis.\n    options : dict\n        Depreciated.\n        Dictionary of optional plugins.\n            Used by 'plot tool' to plot a pool using app analysisDir dfMaster.\n    \"\"\"\n    super().__init__(parent)\n\n    self.setAttribute(QtCore.Qt.WA_DeleteOnClose)\n\n    # does not work, key press gets called first?\n    # self._closeAction = QtWidgets.QAction(\"Exit Application\", self)\n    # self._closeAction.setShortcut('Ctrl+W')\n    # self._closeAction.triggered.connect(self.close)\n\n    # derived classes will set this in init (see kymographPlugin)\n    self._initError: bool = False\n\n    # underlying bAnalaysis\n    self._ba: sanpy.bAnalysis = ba\n\n    # the sweep number of the sanpy.bAnalaysis\n    self._sweepNumber: Union[int, str] = \"All\"\n    self._epochNumber: Union[int, str] = \"All\"\n\n    self._bPlugins: \"sanpy.interface.bPlugin\" = bPlugin\n    # pointer to object, send signal back on close\n\n    self.darkTheme = True\n    if self.getSanPyApp() is not None:\n        _useDarkStyle = self.getSanPyApp().useDarkStyle\n        self.darkTheme = _useDarkStyle\n\n    # to show as a widget\n    self._showSelf: bool = True\n\n    self._blockSlots = False\n\n    # the start and stop secinds to display\n    self._startSec: Optional[float] = None\n    self._stopSec: Optional[float] = None\n    if startStop is not None:\n        self._startSec = startStop[0]\n        self._stopSec = startStop[1]\n\n    # keep track of spike selection\n    self._selectedSpikeList: List[int] = []\n\n    # build a dict of boolean from ResponseType enum class\n    # Things to respond to like switch file, set sweep, etc\n    self._responseOptions: dict = {}\n    for option in self.responseTypes:\n        # print(type(option))\n        self._responseOptions[option.name] = True\n\n    # mar 26 2023 was this\n    # doDark = self.getSanPyApp().useDarkStyle\n    # if doDark and qdarkstyle is not None:\n    #     self.setStyleSheet(qdarkstyle.load_stylesheet(qt_api='pyqt5'))\n    # else:\n    #     self.setStyleSheet(\"\")\n\n    # created in mplWindow2()\n    # these are causing really freaking annoying failures on GitHub !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n    # self.fig : \"matplotlib.figure.Figure\" = None\n    # self.axs : \"matplotlib.axes._axes.Axes\" = None\n    # self.mplToolbar : \"matplotlib.backends.backend_qt.NavigationToolbar2QT\" = None\n    self.fig = None\n    self.axs = None\n    self.mplToolbar = None\n\n    self.keyIsDown = None\n\n    self.winWidth_inches = 4  # used by mpl\n    self.winHeight_inches = 4\n\n    # connect self to main app with signals/slots\n    self._installSignalSlot()\n\n    self._mySetWindowTitle()\n\n    # all plugin widgets always have a single QtWidgetQVBoxLayout\n    # both widget and layouts can be added to this\n    self._vBoxLayout = self.makeVLayout()\n\n    # the top toolbar is always present\n    self._blockComboBox: bool = False\n    self._topToolbarWidget = self._buildTopToolbarWidget()\n\n    # if ba has &gt; 1 sweep or &gt; 2 epochs then show top toolbar\n    _showTop = False\n    if self.ba is not None:\n        _numEpochs = self.ba.fileLoader.numEpochs  # can be None\n        _showTop = self.ba.fileLoader.numSweeps&gt;1\n        _showTop = _showTop | _numEpochs is not None and _numEpochs&gt;2\n    self.toggleTopToobar(_showTop)  # initially hidden\n\n    self._updateTopToolbar()\n    self._vBoxLayout.addWidget(self._topToolbarWidget)\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.bringToFront","title":"<code>bringToFront()</code>","text":"<p>Bring the widget to the front.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def bringToFront(self):\n\"\"\"Bring the widget to the front.\"\"\"\n    if not self._showSelf:\n        return\n\n    # Qt\n    self.getWidget().show()\n    self.getWidget().activateWindow()\n\n    # Matplotlib\n    if self.fig is not None:\n        FigureManagerQT = self.fig.canvas.manager\n        FigureManagerQT.window.activateWindow()\n        FigureManagerQT.window.raise_()\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.closeEvent","title":"<code>closeEvent(event)</code>","text":"<p>Called when window is closed.</p> <p>Signal close event back to parent bPlugin object.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <p>The close event from either PyQt or matplotlib</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def closeEvent(self, event):\n\"\"\"Called when window is closed.\n\n    Signal close event back to parent bPlugin object.\n\n    Parameters\n    ----------\n    event Union[matplotlib.backend_bases.CloseEvent, PyQt5.QtGui.QCloseEvent]\n        The close event from either PyQt or matplotlib\n    \"\"\"\n    logger.info(f\"  --&gt;&gt; emit signalCloseWindow(self)\")\n    self.signalCloseWindow.emit(self)\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.contextMenuEvent","title":"<code>contextMenuEvent(event)</code>","text":"<p>Show popup menu (QComboBox) on mouse right-click.</p> <p>This is inherited from QWidget and should only be modified for advanced usage.</p> <p>See <code>prependMenus</code> for plugins to add items to this contect menu.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>QtGui.QContextMenuEvent</code> <p>Used to position popup</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def contextMenuEvent(self, event):\n\"\"\"Show popup menu (QComboBox) on mouse right-click.\n\n    This is inherited from QWidget\n    and should only be modified for advanced usage.\n\n    See `prependMenus` for plugins to add items to this contect menu.\n\n    Parameters\n    ----------\n    event : QtGui.QContextMenuEvent\n        Used to position popup\n    \"\"\"\n    if self.mplToolbar is not None:\n        state = self.mplToolbar.mode\n        if state in [\"zoom rect\", \"pan/zoom\"]:\n            # don't process right-click when toolbar is active\n            return\n\n    logger.info(\"\")\n\n    contextMenu = QtWidgets.QMenu(self)\n\n    # prepend any menu from derived classes\n    self.prependMenus(contextMenu)\n\n    switchFile = contextMenu.addAction(\"Switch File\")\n    switchFile.setCheckable(True)\n    switchFile.setChecked(self.responseOptions[\"switchFile\"])\n\n    setSweep = contextMenu.addAction(\"Set Sweep\")\n    setSweep.setCheckable(True)\n    setSweep.setChecked(self.responseOptions[\"setSweep\"])\n\n    analysisChange = contextMenu.addAction(\"Analysis Change\")\n    analysisChange.setCheckable(True)\n    analysisChange.setChecked(self.responseOptions[\"analysisChange\"])\n\n    selectSpike = contextMenu.addAction(\"Select Spike\")\n    selectSpike.setCheckable(True)\n    selectSpike.setChecked(self.responseOptions[\"selectSpike\"])\n\n    axisChange = contextMenu.addAction(\"Axis Change\")\n    axisChange.setCheckable(True)\n    axisChange.setChecked(self.responseOptions[\"setAxis\"])\n\n    contextMenu.addSeparator()\n    copyTable = contextMenu.addAction(\"Copy Results\")\n    saveFigure = contextMenu.addAction(\"Save Figure\")\n\n    contextMenu.addSeparator()\n    showTopToolbar = contextMenu.addAction(\"Toggle Top Toolbar\")\n\n    # contextMenu.addSeparator()\n    # saveTable = contextMenu.addAction(\"Save Table\")\n\n    #\n    # open the menu\n    action = contextMenu.exec_(self.mapToGlobal(event.pos()))\n\n    if action is None:\n        # no menu selected\n        return\n\n    #\n    # handle actions in derived plugins\n    handled = self.handleContextMenu(action)\n\n    if handled:\n        return\n\n    if action == switchFile:\n        self.toggleResponseOptions(self.responseTypes.switchFile)\n    elif action == setSweep:\n        self.toggleResponseOptions(self.responseTypes.setSweep)\n    elif action == analysisChange:\n        self.toggleResponseOptions(self.responseTypes.analysisChange)\n    elif action == selectSpike:\n        self.toggleResponseOptions(self.responseTypes.selectSpike)\n    elif action == axisChange:\n        self.toggleResponseOptions(self.responseTypes.setAxis)\n    elif action == copyTable:\n        self.copyToClipboard()\n    elif action == saveFigure:\n        self.saveResultsFigure()\n    elif action == showTopToolbar:\n        self.toggleTopToobar()\n    # elif action == saveTable:\n    #    #self.saveToFile()\n    #    logger.info('NOT IMPLEMENTED')\n\n    elif action is not None:\n        logger.warning(f'Menu action not taken \"{action.text}\"')\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.copyToClipboard","title":"<code>copyToClipboard(df=None)</code>","text":"<p>Derived classes add code to copy plugin to clipboard.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def copyToClipboard(self, df=None):\n\"\"\"Derived classes add code to copy plugin to clipboard.\"\"\"\n    if df is None:\n        return\n\n    logger.info(\"\")\n    if self.ba is None:\n        return\n\n    fileName = self.ba.fileLoader.filename\n    fileName += \".csv\"\n    savePath = fileName\n    options = QtWidgets.QFileDialog.Options()\n    fileName, _ = QtWidgets.QFileDialog.getSaveFileName(\n        self, \"Save .csv file\", savePath, \"CSV Files (*.csv)\", options=options\n    )\n    if not fileName:\n        return\n\n    logger.info(f'Saving: \"{fileName}\"')\n    df.to_csv(fileName, index=False)\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getHumanName","title":"<code>getHumanName()</code>","text":"<p>Get the human readable name for the plugin.</p> <p>Each plugin needs a unique name specified in the static property <code>myHumanName</code>.</p> <p>This is used to display the plugin in the menus.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getHumanName(self):\n\"\"\"Get the human readable name for the plugin.\n\n    Each plugin needs a unique name specified in the static property `myHumanName`.\n\n    This is used to display the plugin in the menus.\n    \"\"\"\n    return self.myHumanName\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getPenColor","title":"<code>getPenColor()</code>","text":"<p>Get pen color for pyqtgraph traces based on dark theme.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getPenColor(self) -&gt; str:\n\"\"\"Get pen color for pyqtgraph traces based on dark theme.\"\"\"\n    if self.darkTheme:\n        return \"w\"\n    else:\n        return \"k\"\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getSanPyApp","title":"<code>getSanPyApp()</code>","text":"<p>Return underlying SanPy app.</p> <p>Only exists if running in SanPy Qt Gui</p> <p>Returns:</p> Type Description <code>sanpy.interface.sanpy_app</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getSanPyApp(self) -&gt; \"sanpy.interface.sanpy_app\":\n\"\"\"Return underlying SanPy app.\n\n    Only exists if running in SanPy Qt Gui\n\n    Returns\n    -------\n    sanpy.interface.sanpy_app\n    \"\"\"\n    if self._bPlugins is not None:\n        return self._bPlugins.getSanPyApp()\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getSelectedSpikes","title":"<code>getSelectedSpikes()</code>","text":"<p>Get the currently selected spikes.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getSelectedSpikes(self) -&gt; List[int]:\n\"\"\"Get the currently selected spikes.\"\"\"\n    return self._selectedSpikeList\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getStartStop","title":"<code>getStartStop()</code>","text":"<p>Get current start stop of interface.</p> <p>Returns:     tuple: (start, stop) in seconds. Can be None</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getStartStop(self):\n\"\"\"Get current start stop of interface.\n\n    Returns:\n        tuple: (start, stop) in seconds. Can be None\n    \"\"\"\n    return self._startSec, self._stopSec\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getStat","title":"<code>getStat(stat, getFullList=False)</code>","text":"<p>Convenianece function to get a stat from underling sanpy.bAnalysis.</p> <p>Parameters:</p> Name Type Description Default <code>stat</code> <code>str</code> <p>Stat to get, corresponds to a column in sanpy.bAnalysis</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getStat(self, stat: str, getFullList : bool = False) -&gt; list:\n\"\"\"Convenianece function to get a stat from underling sanpy.bAnalysis.\n\n    Parameters\n    ----------\n    stat : str\n        Stat to get, corresponds to a column in sanpy.bAnalysis\n    \"\"\"\n    return self.ba.getStat(\n        stat, sweepNumber=self.sweepNumber,\n        epochNumber=self.epochNumber,\n        getFullList=getFullList\n    )\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getSweep","title":"<code>getSweep(type)</code>","text":"<p>Get the raw data from a sweep.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>The sweep type from ('X', 'Y', 'C', 'filteredDeriv', 'filteredVm')</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getSweep(self, type: str):\n\"\"\"Get the raw data from a sweep.\n\n    Parameters\n    ----------\n    type : str\n        The sweep type from ('X', 'Y', 'C', 'filteredDeriv', 'filteredVm')\n    \"\"\"\n    theRet = None\n    type = type.upper()\n    if self.ba is None:\n        return theRet\n    if type == \"X\":\n        theRet = self.ba.fileLoader.sweepX\n    elif type == \"Y\":\n        theRet = self.ba.fileLoader.sweepY\n    elif type == \"C\":\n        theRet = self.ba.fileLoader.sweepC\n    elif type == \"filteredDeriv\":\n        theRet = self.ba.fileLoader.filteredDeriv\n    elif type == \"filteredVm\":\n        theRet = self.ba.fileLoader.sweepY_filtered\n    else:\n        logger.error(f'Did not understand type: \"{type}\"')\n\n    return theRet\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getVBoxLayout","title":"<code>getVBoxLayout()</code>","text":"<p>Get the main PyQt.QWidgets.QVBoxLayout</p> <p>Derived plugins can add to this with addWidget() and addLayout()</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getVBoxLayout(self):\n\"\"\"Get the main PyQt.QWidgets.QVBoxLayout\n\n    Derived plugins can add to this with addWidget() and addLayout()\n    \"\"\"\n    return self._vBoxLayout\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getWidget","title":"<code>getWidget()</code>","text":"<p>Over-ride if plugin makes its own PyQt widget.</p> <p>By default, all plugins inherit from PyQt.QWidgets.QWidget</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getWidget(self):\n\"\"\"Over-ride if plugin makes its own PyQt widget.\n\n    By default, all plugins inherit from PyQt.QWidgets.QWidget\n    \"\"\"\n    return self\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.getWindowGeometry","title":"<code>getWindowGeometry()</code>","text":"<p>Get the current window position.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def getWindowGeometry(self):\n\"\"\"Get the current window position.\"\"\"\n    myRect = self.geometry()\n    left = myRect.left()\n    top = myRect.top()\n    width = myRect.width()\n    height = myRect.height()\n    return left, top, width, height\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.get_bPlugins","title":"<code>get_bPlugins()</code>","text":"<p>Get the SanPy app bPlugin object.</p> <p>Returns:</p> Type Description <code>sanpy.interface.bPlugins</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def get_bPlugins(self) -&gt; \"sanpy.interface.bPlugins\":\n\"\"\"Get the SanPy app bPlugin object.\n\n    Returns\n    -------\n    sanpy.interface.bPlugins\n    \"\"\"\n    return self._bPlugins\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.handleContextMenu","title":"<code>handleContextMenu(action)</code>","text":"<p>Derived plugins need to define this to handle right-click contect menu actions.</p> <p>Only needed if <code>prependMenus</code> is used.</p> <p>Parameters:</p> Name Type Description Default <code>action</code> <code>QtGui.QAction</code> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def handleContextMenu(self, action: \"QtGui.QAction\"):\n\"\"\"Derived plugins need to define this to handle right-click contect menu actions.\n\n    Only needed if `prependMenus` is used.\n\n    Parameters\n    ----------\n    action : QtGui.QAction\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.keyPressEvent","title":"<code>keyPressEvent(event)</code>","text":"<p>Handle key press events.</p> <p>On 'ctrl+c' will copy-to-clipboard.</p> <p>On 'esc' emits signalSelectSpikeList.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Union[QtGui.QKeyEvent, matplotlib.backend_bases.KeyEvent]</code> <p>Either a PyQt or matplotlib key press event.</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def keyPressEvent(self, event):\n\"\"\"Handle key press events.\n\n    On 'ctrl+c' will copy-to-clipboard.\n\n    On 'esc' emits signalSelectSpikeList.\n\n    Parameters\n    ----------\n    event : Union[QtGui.QKeyEvent, matplotlib.backend_bases.KeyEvent]\n        Either a PyQt or matplotlib key press event.\n    \"\"\"\n    isQt = isinstance(event, QtGui.QKeyEvent)\n    isMpl = isinstance(event, mpl.backend_bases.KeyEvent)\n\n    key = None\n    text = None\n    doCopy = False\n    doClose = False\n    if isQt:\n        key = event.key()\n        text = event.text()\n        doCopy = event.matches(QtGui.QKeySequence.Copy)\n        doClose = event.matches(QtGui.QKeySequence.Close)\n    elif isMpl:\n        # q will quit !!!!\n        text = event.key\n        doCopy = text in [\"ctrl+c\", \"cmd+c\"]\n        doClose = text in [\"ctrl+w\", \"cmd+w\"]\n        logger.info(f'mpl key: \"{text}\"')\n    else:\n        logger.warning(f\"Unknown event type: {type(event)}\")\n        return\n\n    self.keyIsDown = text\n\n    if doCopy:\n        self.copyToClipboard()\n    elif doClose:\n        self.close()\n    elif key == QtCore.Qt.Key_Escape or text == \"esc\" or text == \"escape\":\n        # single spike\n        # sDict = {\n        #     'spikeNumber': None,\n        #     'doZoom': False,\n        #     'ba': self.ba,\n\n        # }\n        # self.signalSelectSpike.emit(sDict)\n        # spike list\n        sDict = {\n            \"spikeList\": [],\n            \"doZoom\": False,\n            \"ba\": self.ba,\n        }\n        self.signalSelectSpikeList.emit(sDict)\n    elif key == QtCore.Qt.Key_T or text == \"t\":\n        self.toggleTopToobar()\n    elif text == \"\":\n        pass\n\n    # critical difference between mpl and qt\n    if isMpl:\n        return text\n    else:\n        # return event\n        return\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.makeVLayout","title":"<code>makeVLayout()</code>","text":"<p>Make a PyQt QVBoxLayout.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def makeVLayout(self):\n\"\"\"Make a PyQt QVBoxLayout.\"\"\"\n    vBoxLayout = QtWidgets.QVBoxLayout()\n    self.setLayout(vBoxLayout)\n    return vBoxLayout\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.mplWindow2","title":"<code>mplWindow2(numRow=1, numCol=1, addToLayout=True)</code>","text":"<p>Make a matplotlib figure, canvas, and axis.</p> <p>Parameters:</p> Name Type Description Default <code>numRow</code> <code>int</code> <code>1</code> <code>numCol</code> <code>int</code> <code>1</code> <code>addToLayout</code> <code>bool</code> <p>If true then add widget to main <code>getVBoxLayou()</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>self.static_canvas, self.mplToolbar</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def mplWindow2(self, numRow=1, numCol=1, addToLayout: bool = True):\n\"\"\"Make a matplotlib figure, canvas, and axis.\n\n    Parameters\n    ----------\n    numRow : int\n    numCol : int\n    addToLayout : bool\n        If true then add widget to main `getVBoxLayou()`.\n\n    Returns\n    -------\n    self.static_canvas, self.mplToolbar\n\n    \"\"\"\n    # plt.style.use('dark_background')\n    if self.darkTheme:\n        plt.style.use(\"dark_background\")\n    else:\n        plt.rcParams.update(plt.rcParamsDefault)\n\n    # this is dangerous, collides with self.mplWindow()\n    # these are causing really freaking annoying failures on GitHub !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n    # self.fig : \"matplotlib.figure.Figure\" = mpl.figure.Figure()\n    self.fig = mpl.figure.Figure()\n\n    # not working\n    # self.fig.canvas.mpl_connect('key_press_event', self.keyPressEvent)\n\n    self.static_canvas = backend_qt5agg.FigureCanvas(self.fig)\n    self.static_canvas.setFocusPolicy(\n        QtCore.Qt.ClickFocus\n    )  # this is really triccky and annoying\n    self.static_canvas.setFocus()\n    self.fig.canvas.mpl_connect(\"key_press_event\", self.keyPressEvent)\n\n    self.axs = [None] * numRow  # empty list\n    if numRow == 1 and numCol == 1:\n        _static_ax = self.static_canvas.figure.subplots()\n        self.axs = _static_ax\n        # print('self.axs:', type(self.axs))\n    else:\n        for idx in range(numRow):\n            plotNum = idx + 1\n            # print('mplWindow2()', idx)\n            self.axs[idx] = self.static_canvas.figure.add_subplot(\n                numRow, 1, plotNum\n            )\n\n    # does not work\n    # self.static_canvas.mpl_connect('key_press_event', self.keyPressEvent)\n\n    # pick_event assumes 'picker=5' in any .plot()\n    # does this need to be a member? I think so?\n    self._cid = self.static_canvas.mpl_connect(\"pick_event\", self.spike_pick_event)\n\n    # matplotlib plot tools toolbar (zoom, pan, save, etc)\n    # from matplotlib.backends.backend_qt5agg import NavigationToolbar2QT as NavigationToolbar\n    self.mplToolbar = mpl.backends.backend_qt5agg.NavigationToolbar2QT(\n        self.static_canvas, self.static_canvas\n    )\n\n    # layout = QtWidgets.QVBoxLayout()\n    if addToLayout:\n        layout = self.getVBoxLayout()\n        layout.addWidget(self.static_canvas)\n        layout.addWidget(self.mplToolbar)\n    else:\n        return self.static_canvas, self.mplToolbar\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.old_selectSpike","title":"<code>old_selectSpike(sDict=None)</code>","text":"<p>Derived class adds code to select spike from sDict.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def old_selectSpike(self, sDict=None):\n\"\"\"Derived class adds code to select spike from sDict.\"\"\"\n    pass\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.old_slot_selectSpike","title":"<code>old_slot_selectSpike(eDict)</code>","text":"<p>Respond to spike selection.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def old_slot_selectSpike(self, eDict):\n\"\"\"Respond to spike selection.\"\"\"\n\n    # don't respond if user/code has turned this off\n    if not self._getResponseOption(self.responseTypes.selectSpike):\n        return\n\n    # don't respond if we are showing a different ba (bAnalysis)\n    ba = eDict[\"ba\"]\n    if self.ba != ba:\n        return\n\n    self.selectedSpike = eDict[\"spikeNumber\"]\n\n    self.old_selectSpike(eDict)\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.plot","title":"<code>plot()</code>","text":"<p>Derived class adds code to plot.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def plot(self):\n\"\"\"Derived class adds code to plot.\"\"\"\n    pass\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.prependMenus","title":"<code>prependMenus(contextMenu)</code>","text":"<p>Prepend menus to mouse right-click contect menu.</p> <p>Parameters:</p> Name Type Description Default <code>contextMenu</code> <code>QtWidgets.QMenu</code> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def prependMenus(self, contextMenu: \"QtWidgets.QMenu\"):\n\"\"\"Prepend menus to mouse right-click contect menu.\n\n    Parameters\n    ----------\n    contextMenu : QtWidgets.QMenu\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.replot","title":"<code>replot()</code>","text":"<p>Derived class adds code to replot.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def replot(self):\n\"\"\"Derived class adds code to replot.\"\"\"\n    pass\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.saveResultsFigure","title":"<code>saveResultsFigure(pgPlot=None)</code>","text":"<p>In derived, add code to save main figure to file.</p> <p>In derived, pass in a pg plot from a view and we will save it.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def saveResultsFigure(self, pgPlot=None):\n\"\"\"In derived, add code to save main figure to file.\n\n    In derived, pass in a pg plot from a view and we will save it.\n    \"\"\"\n    if pgPlot is None:\n        return\n\n    exporter = pg.exporters.ImageExporter(pgPlot)\n    # print(f'exporter: {type(exporter)}')\n    # print('getSupportedImageFormats:', exporter.getSupportedImageFormats())\n    # set export parameters if needed\n\n    # (width, height, antialias, background, invertvalue)\n    exporter.parameters()[\n        \"width\"\n    ] = 1000  # (note this also affects height parameter)\n\n    # ask user for file\n    fileName = self.ba.fileLoader.filename\n    fileName += \".png\"\n    savePath = fileName\n    options = QtWidgets.QFileDialog.Options()\n    fileName, _ = QtWidgets.QFileDialog.getSaveFileName(\n        self, \"Save .png file\", savePath, \"CSV Files (*.png)\", options=options\n    )\n    if not fileName:\n        return\n\n    # save to file\n    logger.info(f\"Saving to: {fileName}\")\n    exporter.export(fileName)\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.selectSpikeList","title":"<code>selectSpikeList()</code>","text":"<p>Derived class adds code to select spike from sDict.</p> <p>Get selected spike list with getSelectedSpikes()</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def selectSpikeList(self):\n\"\"\"Derived class adds code to select spike from sDict.\n\n    Get selected spike list with getSelectedSpikes()\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.setAxis","title":"<code>setAxis()</code>","text":"<p>Respond to set axis.</p> <p>Some plugins want to replot() when x-axis changes.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def setAxis(self):\n\"\"\"Respond to set axis.\n\n    Some plugins want to replot() when x-axis changes.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.setSelectedSpikes","title":"<code>setSelectedSpikes(spikes)</code>","text":"<p>Set the currently selected spikes.</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>list of int</code> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def setSelectedSpikes(self, spikes: List[int]):\n\"\"\"Set the currently selected spikes.\n\n    Parameters\n    ----------\n    spikes : list of int\n    \"\"\"\n    self._selectedSpikeList = spikes\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.slot_selectSpikeList","title":"<code>slot_selectSpikeList(eDict)</code>","text":"<p>Respond to spike selection.</p> <p>TODO: convert dict to class spikeSelection</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def slot_selectSpikeList(self, eDict: dict):\n\"\"\"Respond to spike selection.\n\n    TODO: convert dict to class spikeSelection\n    \"\"\"\n\n    if self._blockSlots:\n        return\n\n    logger.info(f\"{self._myClassName()} num spikes:{len(eDict['spikeList'])}\")\n\n    # don't respond if we are showing a different ba (bAnalysis)\n    ba = eDict[\"ba\"]\n    if self.ba != ba:\n        return\n\n    spikeList = eDict[\"spikeList\"]\n    self._selectedSpikeList = spikeList  # [] on no selection\n\n    self.selectSpikeList()\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.slot_setSweep","title":"<code>slot_setSweep(ba, sweepNumber)</code>","text":"<p>Respond to user selecting a sweep.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def slot_setSweep(self, ba: sanpy.bAnalysis, sweepNumber: int):\n\"\"\"Respond to user selecting a sweep.\"\"\"\n\n    if not self._getResponseOption(self.responseTypes.setSweep):\n        return\n\n    logger.info(f\"{self._myClassName()}\")\n\n    if ba is None:\n        return\n\n    # don't respond if we are showing different ba\n    if self._ba != ba:\n        return\n\n    self._sweepNumber = sweepNumber\n\n    # reset selection\n    self._selectedSpikeList = []\n    self.selectedSpike = None\n\n    # update toolbar\n    self._updateTopToolbar()\n\n    self.replot()\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.slot_set_x_axis","title":"<code>slot_set_x_axis(startStopList)</code>","text":"<p>Respond to changes in x-axis.</p> <p>Parameters:</p> Name Type Description Default <code>startStopList</code> <code>list(float)</code> <p>Two element list with [start, stop] in seconds</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def slot_set_x_axis(self, startStopList: List[float]):\n\"\"\"Respond to changes in x-axis.\n\n    Parameters\n    ----------\n    startStopList : list(float)\n        Two element list with [start, stop] in seconds\n    \"\"\"\n    if not self._getResponseOption(self.responseTypes.setAxis):\n        return\n\n    # don't set axis if we are showing different ba\n    app = self.getSanPyApp()\n    if app is not None:\n        ba = app.get_bAnalysis()\n        if self._ba != ba:\n            return\n\n    if startStopList is None:\n        self._startSec = None\n        self._stopSec = None\n    else:\n        self._startSec = startStopList[0]\n        self._stopSec = startStopList[1]\n    #\n    # we do not always want to replot on set axis\n    self.setAxis()\n    self.replot()\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.slot_switchFile","title":"<code>slot_switchFile(ba, rowDict=None, replot=True)</code>","text":"<p>Respond to switch file.</p> <p>Parameters:</p> Name Type Description Default <code>rowDict</code> <code>dict</code> <p>Optional, assumes rowDict has keys ['Start(s)', 'Stop(s)']</p> <code>None</code> <code>ba</code> <code>sanpy.bAnalysis</code> <p>The new bAnalysis file to switch to</p> required <code>replot</code> <code>bool</code> <p>If true then call replot()</p> <code>True</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def slot_switchFile(\n    self, ba: sanpy.bAnalysis, rowDict: Optional[dict] = None, replot: bool = True\n):\n\"\"\"Respond to switch file.\n\n    Parameters\n    ----------\n    rowDict : dict\n        Optional, assumes rowDict has keys ['Start(s)', 'Stop(s)']\n    ba : sanpy.bAnalysis\n        The new bAnalysis file to switch to\n    replot : bool\n        If true then call replot()\n    \"\"\"\n    if not self._getResponseOption(self.responseTypes.switchFile):\n        return\n\n    if ba is None:\n        return\n\n    # don't respond if we are already using ba\n    if self._ba == ba:\n        return\n\n    self._ba = ba\n    # self.fileRowDict = rowDict  # for detectionParams plugin\n\n    # rest sweep and epoch\n    self._sweepNumber = 0\n    self._epochNumber = 'All'\n\n    # reset start/stop\n    startSec = None\n    stopSec = None\n    if rowDict is not None:\n        startSec = rowDict[\"Start(s)\"]\n        stopSec = rowDict[\"Stop(s)\"]\n        if math.isnan(startSec):\n            startSec = None\n        if math.isnan(stopSec):\n            stopSec = None\n    self._startSec = startSec\n    self._stopSec = stopSec\n\n    # reset spike and spike list selection\n    self._selectedSpikeList = []\n    self.selectedSpike = None\n\n    # inform derived classes of change\n    # self.old_selectSpike()\n    self.selectSpikeList()\n\n    # set pyqt window title\n    self._mySetWindowTitle()\n\n    self._updateTopToolbar()\n\n    if replot:\n        self.replot()\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.slot_updateAnalysis","title":"<code>slot_updateAnalysis(sDict)</code>","text":"<p>Respond to new spike detection.</p> <p>Parameters:</p> Name Type Description Default <code>sDict</code> <code>dict</code> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def slot_updateAnalysis(self, sDict : dict):\n\"\"\"Respond to new spike detection.\n\n    Parameters\n    ----------\n    sDict : dict\n    \"\"\"\n    logger.info(\"\")\n    if not self._getResponseOption(self.responseTypes.analysisChange):\n        return\n\n    ba = sDict['ba']\n\n    if ba is None:\n        return\n\n    # don't update analysis if we are showing different ba\n    if self._ba != ba:\n        return\n\n    self.replot()\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.spike_pick_event","title":"<code>spike_pick_event(event)</code>","text":"<p>Respond to user clicks in mpl plot</p> <p>Assumes plot(..., picker=5)</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>matplotlib.backend_bases.PickEvent</code> <p>PickEvent with plot indices in ind[]</p> required Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def spike_pick_event(self, event):\n\"\"\"Respond to user clicks in mpl plot\n\n    Assumes plot(..., picker=5)\n\n    Parameters\n    ----------\n    event : matplotlib.backend_bases.PickEvent\n        PickEvent with plot indices in ind[]\n    \"\"\"\n    if len(event.ind) &lt; 1:\n        return\n\n    # logger.info(f'{event.ind}')\n\n    spikeNumber = event.ind[0]\n\n    doZoom = False\n    modifiers = QtWidgets.QApplication.keyboardModifiers()\n    if modifiers == QtCore.Qt.ShiftModifier:\n        doZoom = True\n\n    logger.info(\n        f\"got {len(event.ind)} candidates, first is spike:{spikeNumber} doZoom:{doZoom}\"\n    )\n\n    # propagate a signal to parent\n    # TODO: use class SpikeSelectEvent()\n    sDict = {\n        \"spikeList\": [spikeNumber],\n        \"doZoom\": doZoom,\n        \"ba\": self.ba,\n    }\n    self.signalSelectSpikeList.emit(sDict)\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.toggleResponseOptions","title":"<code>toggleResponseOptions(thisOption, newValue=None)</code>","text":"<p>Set underlying responseOptions based on name of thisOption.</p> <p>Parameters:</p> Name Type Description Default <code>thisOption</code> <code>ResponseType</code> required <code>newValue</code> <code>Optional[bool]</code> <p>If boolean then set, if None then toggle.</p> <code>None</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def toggleResponseOptions(self, thisOption: ResponseType, newValue: bool = None):\n\"\"\"Set underlying responseOptions based on name of thisOption.\n\n    Parameters\n    ----------\n    thisOption : ResponseType\n    newValue : Optional[bool]\n        If boolean then set, if None then toggle.\n    \"\"\"\n    # logger.info(f'{thisOption} {newValue}')\n    if newValue is None:\n        newValue = not self.responseOptions[thisOption.name]\n    self.responseOptions[thisOption.name] = newValue\n</code></pre>"},{"location":"api/interface/plugins/sanpyPlugin/#sanpy.interface.plugins.sanpyPlugin.sanpyPlugin.toggleTopToobar","title":"<code>toggleTopToobar(visible=None)</code>","text":"<p>Toggle or set the top toolbar.</p> <p>Parameters:</p> Name Type Description Default <code>visible</code> <code>bool or None</code> <p>If None then toggle, otherwise set to <code>visible</code>.</p> <code>None</code> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/interface/plugins/sanpyPlugin.py</code> <pre><code>def toggleTopToobar(self, visible: bool = None):\n\"\"\"Toggle or set the top toolbar.\n\n    Parameters\n    ----------\n    visible : bool or None\n        If None then toggle, otherwise set to `visible`.\n    \"\"\"\n    if visible is None:\n        visible = not self._topToolbarWidget.isVisible()\n    self._topToolbarWidget.setVisible(visible)\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/","title":"baseUserAnalysis","text":""},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis-classes","title":"Classes","text":""},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis","title":"<code>baseUserAnalysis</code>","text":"<p>Create a userAnalysis object after bAnalysis has been analyzed with the core analysis results.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>class baseUserAnalysis:\n\"\"\"Create a userAnalysis object after bAnalysis has been analyzed with the core analysis results.\"\"\"\n\n    def __init__(self, ba: \"sanpy.bAnalysis\"):\n        self._myAnalysis: sanpy.bAnalysis = ba\n\n        self._userStatDict: dict = {}\n        # add to this with addUserStat()\n\n        self.defineUserStats()\n\n    def _getUserStatDict(self):\n\"\"\"Get dict of user defined stats, one key per stat.\"\"\"\n        return self._userStatDict\n\n    def defineUserStats(self):\n\"\"\"Derived classes add each stat with addUserStat().\n\n        See Also\n        --------\n        addUserStat\n        \"\"\"\n        pass\n\n    def addUserStat(self, humanName: str, internalName: str):\n\"\"\"Add a user stat. Derived classes do this in defineUserStats().\n\n        Parameters\n        ----------\n        humanName : str\n            Human readable name for the stat, like 'Threshold Potential (mV)'\n        internalName : str\n            Name to use for the variable name of the stat.\n            Should not contain special characters like space or '-'\n            Can contain '_'\n\n        Notes\n        -----\n        userStatDict = {\n            'User Time To Peak (ms)' : {\n                'name': 'user_timeToPeak_ms',\n                'units': 'ms',\n                'yStat': 'user_timeToPeak_ms',\n                'yStatUnits': 'ms',\n                'xStat': 'thresholdPnt',\n                'xStatUnits': 'Points'\n                }\n        }\n        \"\"\"\n        if humanName in self._userStatDict.keys():\n            logger.error(f'User stat with human name \"{humanName}\" already exists')\n            return\n        statDict = {\n            \"name\": internalName,\n            \"units\": None,\n            \"yStat\": None,\n            \"yStatUnits\": None,\n            \"xStat\": None,\n            \"xStatUnits\": None,\n        }\n        self._userStatDict[humanName] = statDict\n\n    @property\n    def ba(self):\n\"\"\"Get the underlying [sanpy.bAnalysis][sanpy.bAnalysis] object\"\"\"\n        return self._myAnalysis\n\n    def getSweepX(self):\n\"\"\"Get the x-axis of a recording.\"\"\"\n        return self.ba.fileLoader.sweepX\n\n    def getSweepY(self):\n\"\"\"Get the y-axis of a recording.\"\"\"\n        return self.ba.fileLoader.sweepY\n\n    def getSweepC(self):\n\"\"\"Get the DAC axis of a recording.\"\"\"\n        return self.ba.fileLoader.sweepC\n\n    def getFilteredVm(self):\n        return self.ba.fileLoader.sweepY_filtered\n\n    def setSpikeValue(self, spikeIdx, theKey, theVal):\n\"\"\"Set the value of a spike key.\n\n        Parameters\n        ----------\n        spikeIdx : int\n            The spike index , 0 based.\n        theKey : str\n            Name of the user defined internal name.\n        theVal :\n            The value for the key, can be almost any type like\n            (float, int, bool, dict, list)\n\n        Raises\n        ------\n        KeyError\n            If theKey is not a key in analysis results.\n        IndexError\n            If spikeIdx is beyond number of spikes -1.\n        \"\"\"\n        try:\n            self.ba.spikeDict[spikeIdx][theKey] = theVal\n        except KeyError as e:\n            logger.error(f'User internal stat does not exist \"{theKey}\"')\n        except IndexError as e:\n            logger.error(\n                f\"spikeIdx {spikeIdx} is out of range, max value is {self.ba.numSpikes}\"\n            )\n\n    def getSpikeValue(self, spikeIdx, theKey):\n\"\"\"Get a single spike analysis result from key.\n\n        Parameters\n        ----------\n        spikeIdx : int\n            The spike index, 0 based.\n        theKey : str\n            Name of the analysis result defined internal name.\n\n        Raises\n        ------\n        KeyError\n            If theKey is not a key in analysis results.\n        IndexError\n            If spikeIdx is beyond number of spikes -1.\n        \"\"\"\n        try:\n            theRet = self.ba.spikeDict[spikeIdx][theKey]\n            return theRet\n        except KeyError as e:\n            logger.error(f'User internal stat does not exist \"{theKey}\"')\n        except IndexError as e:\n            logger.error(\n                f\"spikeIdx {spikeIdx} is out of range, max value is {self.ba.numSpikes}\"\n            )\n\n    def run(self):\n\"\"\"Run user analysis. Calculate values for each new user stat.\"\"\"\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis-attributes","title":"Attributes","text":""},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.ba","title":"<code>ba</code>  <code>property</code>","text":"<p>Get the underlying sanpy.bAnalysis object</p>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis-functions","title":"Functions","text":""},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.addUserStat","title":"<code>addUserStat(humanName, internalName)</code>","text":"<p>Add a user stat. Derived classes do this in defineUserStats().</p> <p>Parameters:</p> Name Type Description Default <code>humanName</code> <code>str</code> <p>Human readable name for the stat, like 'Threshold Potential (mV)'</p> required <code>internalName</code> <code>str</code> <p>Name to use for the variable name of the stat. Should not contain special characters like space or '-' Can contain '_'</p> required"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.addUserStat--notes","title":"Notes","text":"<p>userStatDict = {     'User Time To Peak (ms)' : {         'name': 'user_timeToPeak_ms',         'units': 'ms',         'yStat': 'user_timeToPeak_ms',         'yStatUnits': 'ms',         'xStat': 'thresholdPnt',         'xStatUnits': 'Points'         } }</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def addUserStat(self, humanName: str, internalName: str):\n\"\"\"Add a user stat. Derived classes do this in defineUserStats().\n\n    Parameters\n    ----------\n    humanName : str\n        Human readable name for the stat, like 'Threshold Potential (mV)'\n    internalName : str\n        Name to use for the variable name of the stat.\n        Should not contain special characters like space or '-'\n        Can contain '_'\n\n    Notes\n    -----\n    userStatDict = {\n        'User Time To Peak (ms)' : {\n            'name': 'user_timeToPeak_ms',\n            'units': 'ms',\n            'yStat': 'user_timeToPeak_ms',\n            'yStatUnits': 'ms',\n            'xStat': 'thresholdPnt',\n            'xStatUnits': 'Points'\n            }\n    }\n    \"\"\"\n    if humanName in self._userStatDict.keys():\n        logger.error(f'User stat with human name \"{humanName}\" already exists')\n        return\n    statDict = {\n        \"name\": internalName,\n        \"units\": None,\n        \"yStat\": None,\n        \"yStatUnits\": None,\n        \"xStat\": None,\n        \"xStatUnits\": None,\n    }\n    self._userStatDict[humanName] = statDict\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.defineUserStats","title":"<code>defineUserStats()</code>","text":"<p>Derived classes add each stat with addUserStat().</p>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.defineUserStats--see-also","title":"See Also","text":"<p>addUserStat</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def defineUserStats(self):\n\"\"\"Derived classes add each stat with addUserStat().\n\n    See Also\n    --------\n    addUserStat\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.getSpikeValue","title":"<code>getSpikeValue(spikeIdx, theKey)</code>","text":"<p>Get a single spike analysis result from key.</p> <p>Parameters:</p> Name Type Description Default <code>spikeIdx</code> <code>int</code> <p>The spike index, 0 based.</p> required <code>theKey</code> <code>str</code> <p>Name of the analysis result defined internal name.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If theKey is not a key in analysis results.</p> <code>IndexError</code> <p>If spikeIdx is beyond number of spikes -1.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def getSpikeValue(self, spikeIdx, theKey):\n\"\"\"Get a single spike analysis result from key.\n\n    Parameters\n    ----------\n    spikeIdx : int\n        The spike index, 0 based.\n    theKey : str\n        Name of the analysis result defined internal name.\n\n    Raises\n    ------\n    KeyError\n        If theKey is not a key in analysis results.\n    IndexError\n        If spikeIdx is beyond number of spikes -1.\n    \"\"\"\n    try:\n        theRet = self.ba.spikeDict[spikeIdx][theKey]\n        return theRet\n    except KeyError as e:\n        logger.error(f'User internal stat does not exist \"{theKey}\"')\n    except IndexError as e:\n        logger.error(\n            f\"spikeIdx {spikeIdx} is out of range, max value is {self.ba.numSpikes}\"\n        )\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.getSweepC","title":"<code>getSweepC()</code>","text":"<p>Get the DAC axis of a recording.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def getSweepC(self):\n\"\"\"Get the DAC axis of a recording.\"\"\"\n    return self.ba.fileLoader.sweepC\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.getSweepX","title":"<code>getSweepX()</code>","text":"<p>Get the x-axis of a recording.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def getSweepX(self):\n\"\"\"Get the x-axis of a recording.\"\"\"\n    return self.ba.fileLoader.sweepX\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.getSweepY","title":"<code>getSweepY()</code>","text":"<p>Get the y-axis of a recording.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def getSweepY(self):\n\"\"\"Get the y-axis of a recording.\"\"\"\n    return self.ba.fileLoader.sweepY\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.run","title":"<code>run()</code>","text":"<p>Run user analysis. Calculate values for each new user stat.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def run(self):\n\"\"\"Run user analysis. Calculate values for each new user stat.\"\"\"\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.baseUserAnalysis.setSpikeValue","title":"<code>setSpikeValue(spikeIdx, theKey, theVal)</code>","text":"<p>Set the value of a spike key.</p> <p>Parameters:</p> Name Type Description Default <code>spikeIdx</code> <code>int</code> <p>The spike index , 0 based.</p> required <code>theKey</code> <code>str</code> <p>Name of the user defined internal name.</p> required <code>theVal</code> <p>The value for the key, can be almost any type like (float, int, bool, dict, list)</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If theKey is not a key in analysis results.</p> <code>IndexError</code> <p>If spikeIdx is beyond number of spikes -1.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def setSpikeValue(self, spikeIdx, theKey, theVal):\n\"\"\"Set the value of a spike key.\n\n    Parameters\n    ----------\n    spikeIdx : int\n        The spike index , 0 based.\n    theKey : str\n        Name of the user defined internal name.\n    theVal :\n        The value for the key, can be almost any type like\n        (float, int, bool, dict, list)\n\n    Raises\n    ------\n    KeyError\n        If theKey is not a key in analysis results.\n    IndexError\n        If spikeIdx is beyond number of spikes -1.\n    \"\"\"\n    try:\n        self.ba.spikeDict[spikeIdx][theKey] = theVal\n    except KeyError as e:\n        logger.error(f'User internal stat does not exist \"{theKey}\"')\n    except IndexError as e:\n        logger.error(\n            f\"spikeIdx {spikeIdx} is out of range, max value is {self.ba.numSpikes}\"\n        )\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis-functions","title":"Functions","text":""},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.findUserAnalysisStats","title":"<code>findUserAnalysisStats()</code>","text":"<p>Get the stat names of all user defined analysis.</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def findUserAnalysisStats() -&gt; List[dict]:\n\"\"\"Get the stat names of all user defined analysis.\"\"\"\n    userStatList: List[dict] = []\n    objList = _getObjectList()  # list of dict\n    for obj in objList:\n        # sanpy._util.pprint(obj)\n        # print('')\n\n        # instantiate the object\n        userObj = obj[\"constructor\"](ba=None)\n\n        userObjStatDict = userObj._getUserStatDict()\n\n        for k, v in userObjStatDict.items():\n            oneUserStatDict = {k: v}\n            userStatList.append(oneUserStatDict)\n\n    return userStatList\n</code></pre>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.runAllUserAnalysis","title":"<code>runAllUserAnalysis(ba, verbose=False)</code>","text":"<p>Run all user defined analysis.</p>"},{"location":"api/userAnalysis/baseUserAnalysis/#sanpy.user_analysis.baseUserAnalysis.runAllUserAnalysis--notes","title":"Notes","text":"<p>Called at end of sanpy.bAnalysis.detect()</p> Source code in <code>/Users/cudmore/opt/miniconda3/envs/sanpy-env/lib/python3.9/site-packages/sanpy/user_analysis/baseUserAnalysis.py</code> <pre><code>def runAllUserAnalysis(ba, verbose=False):\n\"\"\"Run all user defined analysis.\n\n    Notes\n    -----\n    Called at end of sanpy.bAnalysis.detect()\n    \"\"\"\n\n    # step through each\n    objList = _getObjectList()  # list of dict\n\n    if verbose:\n        logger.info(f\"objList: {objList}\")\n    for obj in objList:\n        # instantiate and call run (will add values for stats\n        # was this\n        # userObj = obj(ba)\n        # userObj.run()\n\n        try:\n            # instantiate a user object\n            userObj = obj[\"constructor\"](ba)\n\n            # run the analysis\n            userObj.run()  # run the analysis and append to actual ba object\n        except Exception as e:\n            logger.error(f\"Exception in running user defined analysis: {e}\")\n            logger.error(traceback.format_exc())\n</code></pre>"}]}